<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2005" href="../home/nips2005_home.html">nips2005</a> <a title="nips-2005-120" href="#">nips2005-120</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</h1>
<br/><p>Source: <a title="nips-2005-120-pdf" href="http://papers.nips.cc/paper/2827-learning-vehicular-dynamics-with-application-to-modeling-helicopters.pdf">pdf</a></p><p>Author: Pieter Abbeel, Varun Ganapathi, Andrew Y. Ng</p><p>Abstract: We consider the problem of modeling a helicopter‚Äôs dynamics based on state-action trajectories collected from it. The contribution of this paper is two-fold. First, we consider the linear models such as learned by CIFER (the industry standard in helicopter identiÔ¨Åcation), and show that the linear parameterization makes certain properties of dynamical systems, such as inertia, fundamentally difÔ¨Åcult to capture. We propose an alternative, acceleration based, parameterization that does not suffer from this deÔ¨Åciency, and that can be learned as efÔ¨Åciently from data. Second, a Markov decision process model of a helicopter‚Äôs dynamics would explicitly model only the one-step transitions, but we are often interested in a model‚Äôs predictive performance over longer timescales. In this paper, we present an efÔ¨Åcient algorithm for (approximately) minimizing the prediction error over long time scales. We present empirical results on two different helicopters. Although this work was motivated by the problem of modeling helicopters, the ideas presented here are general, and can be applied to modeling large classes of vehicular dynamics. 1</p><p>Reference: <a title="nips-2005-120-reference" href="../nips2005_reference/nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('helicopt', 0.695), ('accel', 0.281), ('veloc', 0.199), ('xb', 0.176), ('angul', 0.156), ('cif', 0.153), ('lag', 0.146), ('twin', 0.144), ('xcel', 0.144), ('tempest', 0.128), ('inert', 0.127), ('pitch', 0.118), ('coordin', 0.117), ('berg', 0.112), ('st', 0.098), ('rot', 0.097), ('indust', 0.095), ('ight', 0.089), ('sim', 0.069), ('ory', 0.066)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999946 <a title="120-tfidf-1" href="./nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters.html">120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</a></p>
<p>Author: Pieter Abbeel, Varun Ganapathi, Andrew Y. Ng</p><p>Abstract: We consider the problem of modeling a helicopter‚Äôs dynamics based on state-action trajectories collected from it. The contribution of this paper is two-fold. First, we consider the linear models such as learned by CIFER (the industry standard in helicopter identiÔ¨Åcation), and show that the linear parameterization makes certain properties of dynamical systems, such as inertia, fundamentally difÔ¨Åcult to capture. We propose an alternative, acceleration based, parameterization that does not suffer from this deÔ¨Åciency, and that can be learned as efÔ¨Åciently from data. Second, a Markov decision process model of a helicopter‚Äôs dynamics would explicitly model only the one-step transitions, but we are often interested in a model‚Äôs predictive performance over longer timescales. In this paper, we present an efÔ¨Åcient algorithm for (approximately) minimizing the prediction error over long time scales. We present empirical results on two different helicopters. Although this work was motivated by the problem of modeling helicopters, the ideas presented here are general, and can be applied to modeling large classes of vehicular dynamics. 1</p><p>2 0.26049837 <a title="120-tfidf-2" href="./nips-2005-Fast_Gaussian_Process_Regression_using_KD-Trees.html">69 nips-2005-Fast Gaussian Process Regression using KD-Trees</a></p>
<p>Author: Yirong Shen, Matthias Seeger, Andrew Y. Ng</p><p>Abstract: The computation required for Gaussian process regression with n training examples is about O(n3 ) during training and O(n) for each prediction. This makes Gaussian process regression too slow for large datasets. In this paper, we present a fast approximation method, based on kd-trees, that signiÔ¨Åcantly reduces both the prediction and the training times of Gaussian process regression.</p><p>3 0.080739997 <a title="120-tfidf-3" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>Author: Kristina Klinkner, Cosma Shalizi, Marcelo Camperi</p><p>Abstract: Most nervous systems encode information about stimuli in the responding activity of large neuronal networks. This activity often manifests itself as dynamically coordinated sequences of action potentials. Since multiple electrode recordings are now a standard tool in neuroscience research, it is important to have a measure of such network-wide behavioral coordination and information sharing, applicable to multiple neural spike train data. We propose a new statistic, informational coherence, which measures how much better one unit can be predicted by knowing the dynamical state of another. We argue informational coherence is a measure of association and shared information which is superior to traditional pairwise measures of synchronization and correlation. To Ô¨Ånd the dynamical states, we use a recently-introduced algorithm which reconstructs effective state spaces from stochastic time series. We then extend the pairwise measure to a multivariate analysis of the network by estimating the network multi-information. We illustrate our method by testing it on a detailed model of the transition from gamma to beta rhythms. Much of the most important information in neural systems is shared over multiple neurons or cortical areas, in such forms as population codes and distributed representations [1]. On behavioral time scales, neural information is stored in temporal patterns of activity as opposed to static markers; therefore, as information is shared between neurons or brain regions, it is physically instantiated as coordination between entire sequences of neural spikes. Furthermore, neural systems and regions of the brain often require coordinated neural activity to perform important functions; acting in concert requires multiple neurons or cortical areas to share information [2]. Thus, if we want to measure the dynamic network-wide behavior of neurons and test hypotheses about them, we need reliable, practical methods to detect and quantify behavioral coordination and the associated information sharing across multiple neural units. These would be especially useful in testing ideas about how particular forms of coordination relate to distributed coding (e.g., that of [3]). Current techniques to analyze relations among spike trains handle only pairs of neurons, so we further need a method which is extendible to analyze the coordination in the network, system, or region as a whole. Here we propose a new measure of behavioral coordination and information sharing, informational coherence, based on the notion of dynamical state. Section 1 argues that coordinated behavior in neural systems is often not captured by exist- ing measures of synchronization or correlation, and that something sensitive to nonlinear, stochastic, predictive relationships is needed. Section 2 deÔ¨Ånes informational coherence as the (normalized) mutual information between the dynamical states of two systems and explains how looking at the states, rather than just observables, fulÔ¨Ålls the needs laid out in Section 1. Since we rarely know the right states a prori, Section 2.1 brieÔ¨Çy describes how we reconstruct effective state spaces from data. Section 2.2 gives some details about how we calculate the informational coherence and approximate the global information stored in the network. Section 3 applies our method to a model system (a biophysically detailed conductance-based model) comparing our results to those of more familiar second-order statistics. In the interest of space, we omit proofs and a full discussion of the existing literature, giving only minimal references here; proofs and references will appear in a longer paper now in preparation. 1 Synchrony or Coherence? Most hypotheses which involve the idea that information sharing is reÔ¨Çected in coordinated activity across neural units invoke a very speciÔ¨Åc notion of coordinated activity, namely strict synchrony: the units should be doing exactly the same thing (e.g., spiking) at exactly the same time. Investigators then measure coordination by measuring how close the units come to being strictly synchronized (e.g., variance in spike times). From an informational point of view, there is no reason to favor strict synchrony over other kinds of coordination. One neuron consistently spiking 50 ms after another is just as informative a relationship as two simultaneously spiking, but such stable phase relations are missed by strict-synchrony approaches. Indeed, whatever the exact nature of the neural code, it uses temporally extended patterns of activity, and so information sharing should be reÔ¨Çected in coordination of those patterns, rather than just the instantaneous activity. There are three common ways of going beyond strict synchrony: cross-correlation and related second-order statistics, mutual information, and topological generalized synchrony. The cross-correlation function (the normalized covariance function; this includes, for present purposes, the joint peristimulus time histogram [2]), is one of the most widespread measures of synchronization. It can be efÔ¨Åciently calculated from observable series; it handles statistical as well as deterministic relationships between processes; by incorporating variable lags, it reduces the problem of phase locking. Fourier transformation of the covariance function Œ≥XY (h) yields the cross-spectrum FXY (ŒΩ), which in turn gives the 2 spectral coherence cXY (ŒΩ) = FXY (ŒΩ)/FX (ŒΩ)FY (ŒΩ), a normalized correlation between the Fourier components of X and Y . Integrated over frequencies, the spectral coherence measures, essentially, the degree of linear cross-predictability of the two series. ([4] applies spectral coherence to coordinated neural activity.) However, such second-order statistics only handle linear relationships. Since neural processes are known to be strongly nonlinear, there is little reason to think these statistics adequately measure coordination and synchrony in neural systems. Mutual information is attractive because it handles both nonlinear and stochastic relationships and has a very natural and appealing interpretation. Unfortunately, it often seems to fail in practice, being disappointingly small even between signals which are known to be tightly coupled [5]. The major reason is that the neural codes use distinct patterns of activity over time, rather than many different instantaneous actions, and the usual approach misses these extended patterns. Consider two neurons, one of which drives the other to spike 50 ms after it does, the driving neuron spiking once every 500 ms. These are very tightly coordinated, but whether the Ô¨Årst neuron spiked at time t conveys little information about what the second neuron is doing at t ‚Äî it‚Äôs not spiking, but it‚Äôs not spiking most of the time anyway. Mutual information calculated from the direct observations conÔ¨Çates the ‚Äúno spike‚Äù of the second neuron preparing to Ô¨Åre with its just-sitting-around ‚Äúno spike‚Äù. Here, mutual information could Ô¨Ånd the coordination if we used a 50 ms lag, but that won‚Äôt work in general. Take two rate-coding neurons with base-line Ô¨Åring rates of 1 Hz, and suppose that a stimulus excites one to 10 Hz and suppresses the other to 0.1 Hz. The spiking rates thus share a lot of information, but whether the one neuron spiked at t is uninformative about what the other neuron did then, and lagging won‚Äôt help. Generalized synchrony is based on the idea of establishing relationships between the states of the various units. ‚ÄúState‚Äù here is taken in the sense of physics, dynamics and control theory: the state at time t is a variable which Ô¨Åxes the distribution of observables at all times ‚â• t, rendering the past of the system irrelevant [6]. Knowing the state allows us to predict, as well as possible, how the system will evolve, and how it will respond to external forces [7]. Two coupled systems are said to exhibit generalized synchrony if the state of one system is given by a mapping from the state of the other. Applications to data employ statespace reconstruction [8]: if the state x ‚àà X evolves according to smooth, d-dimensional deterministic dynamics, and we observe a generic function y = f (x), then the space Y of time-delay vectors [y(t), y(t ‚àí œÑ ), ...y(t ‚àí (k ‚àí 1)œÑ )] is diffeomorphic to X if k > 2d, for generic choices of lag œÑ . The various versions of generalized synchrony differ on how, precisely, to quantify the mappings between reconstructed state spaces, but they all appear to be empirically equivalent to one another and to notions of phase synchronization based on Hilbert transforms [5]. Thus all of these measures accommodate nonlinear relationships, and are potentially very Ô¨Çexible. Unfortunately, there is essentially no reason to believe that neural systems have deterministic dynamics at experimentally-accessible levels of detail, much less that there are deterministic relationships among such states for different units. What we want, then, but none of these alternatives provides, is a quantity which measures predictive relationships among states, but allows those relationships to be nonlinear and stochastic. The next section introduces just such a measure, which we call ‚Äúinformational coherence‚Äù. 2 States and Informational Coherence There are alternatives to calculating the ‚Äúsurface‚Äù mutual information between the sequences of observations themselves (which, as described, fails to capture coordination). If we know that the units are phase oscillators, or rate coders, we can estimate their instantaneous phase or rate and, by calculating the mutual information between those variables, see how coordinated the units‚Äô patterns of activity are. However, phases and rates do not exhaust the repertoire of neural patterns and a more general, common scheme is desirable. The most general notion of ‚Äúpattern of activity‚Äù is simply that of the dynamical state of the system, in the sense mentioned above. We now formalize this. Assuming the usual notation for Shannon information [9], the information content of a state variable X is H[X] and the mutual information between X and Y is I[X; Y ]. As is well-known, I[X; Y ] ‚â§ min H[X], H[Y ]. We use this to normalize the mutual state information to a 0 ‚àí 1 scale, and this is the informational coherence (IC). œà(X, Y ) = I[X; Y ] , with 0/0 = 0 . min H[X], H[Y ] (1) œà can be interpreted as follows. I[X; Y ] is the Kullback-Leibler divergence between the joint distribution of X and Y , and the product of their marginal distributions [9], indicating the error involved in ignoring the dependence between X and Y . The mutual information between predictive, dynamical states thus gauges the error involved in assuming the two systems are independent, i.e., how much predictions could improve by taking into account the dependence. Hence it measures the amount of dynamically-relevant information shared between the two systems. œà simply normalizes this value, and indicates the degree to which two systems have coordinated patterns of behavior (cf. [10], although this only uses directly observable quantities). 2.1 Reconstruction and Estimation of Effective State Spaces As mentioned, the state space of a deterministic dynamical system can be reconstructed from a sequence of observations. This is the main tool of experimental nonlinear dynamics [8]; but the assumption of determinism is crucial and false, for almost any interesting neural system. While classical state-space reconstruction won‚Äôt work on stochastic processes, such processes do have state-space representations [11], and, in the special case of discretevalued, discrete-time series, there are ways to reconstruct the state space. Here we use the CSSR algorithm, introduced in [12] (code available at http://bactra.org/CSSR). This produces causal state models, which are stochastic automata capable of statistically-optimal nonlinear prediction; the state of the machine is a minimal sufÔ¨Åcient statistic for the future of the observable process[13].1 The basic idea is to form a set of states which should be (1) Markovian, (2) sufÔ¨Åcient statistics for the next observable, and (3) have deterministic transitions (in the automata-theory sense). The algorithm begins with a minimal, one-state, IID model, and checks whether these properties hold, by means of hypothesis tests. If they fail, the model is modiÔ¨Åed, generally but not always by adding more states, and the new model is checked again. Each state of the model corresponds to a distinct distribution over future events, i.e., to a statistical pattern of behavior. Under mild conditions, which do not involve prior knowledge of the state space, CSSR converges in probability to the unique causal state model of the data-generating process [12]. In practice, CSSR is quite fast (linear in the data size), and generalizes at least as well as training hidden Markov models with the EM algorithm and using cross-validation for selection, the standard heuristic [12]. One advantage of the causal state approach (which it shares with classical state-space reconstruction) is that state estimation is greatly simpliÔ¨Åed. In the general case of nonlinear state estimation, it is necessary to know not just the form of the stochastic dynamics in the state space and the observation function, but also their precise parametric values and the distribution of observation and driving noises. Estimating the state from the observable time series then becomes a computationally-intensive application of Bayes‚Äôs Rule [17]. Due to the way causal states are built as statistics of the data, with probability 1 there is a Ô¨Ånite time, t, at which the causal state at time t is certain. This is not just with some degree of belief or conÔ¨Ådence: because of the way the states are constructed, it is impossible for the process to be in any other state at that time. Once the causal state has been established, it can be updated recursively, i.e., the causal state at time t + 1 is an explicit function of the causal state at time t and the observation at t + 1. The causal state model can be automatically converted, therefore, into a Ô¨Ånite-state transducer which reads in an observation time series and outputs the corresponding series of states [18, 13]. (Our implementation of CSSR Ô¨Ålters its training data automatically.) The result is a new time series of states, from which all non-predictive components have been Ô¨Åltered out. 2.2 Estimating the Coherence Our algorithm for estimating the matrix of informational coherences is as follows. For each unit, we reconstruct the causal state model, and Ô¨Ålter the observable time series to produce a series of causal states. Then, for each pair of neurons, we construct a joint histogram of 1 Causal state models have the same expressive power as observable operator models [14] or predictive state representations [7], and greater power than variable-length Markov models [15, 16]. a b Figure 1: Rastergrams of neuronal spike-times in the network. Excitatory, pyramidal neurons (numbers 1 to 1000) are shown in green, inhibitory interneurons (numbers 1001 to 1300) in red. During the Ô¨Årst 10 seconds (a), the current connections among the pyramidal cells are suppressed and a gamma rhythm emerges (left). At t = 10s, those connections become active, leading to a beta rhythm (b, right). the state distribution, estimate the mutual information between the states, and normalize by the single-unit state informations. This gives a symmetric matrix of œà values. Even if two systems are independent, their estimated IC will, on average, be positive, because, while they should have zero mutual information, the empirical estimate of mutual information is non-negative. Thus, the signiÔ¨Åcance of IC values must be assessed against the null hypothesis of system independence. The easiest way to do so is to take the reconstructed state models for the two systems and run them forward, independently of one another, to generate a large number of simulated state sequences; from these calculate values of the IC. This procedure will approximate the sampling distribution of the IC under a null model which preserves the dynamics of each system, but not their interaction. We can then Ô¨Ånd p-values as usual. We omit them here to save space. 2.3 Approximating the Network Multi-Information There is broad agreement [2] that analyses of networks should not just be an analysis of pairs of neurons, averaged over pairs. Ideally, an analysis of information sharing in a network would look at the over-all structure of statistical dependence between the various units, reÔ¨Çected in the complete joint probability distribution P of the states. This would then allow us, for instance, to calculate the n-fold multi-information, I[X1 , X2 , . . . Xn ] ‚â° D(P ||Q), the Kullback-Leibler divergence between the joint distribution P and the product of marginal distributions Q, analogous to the pairwise mutual information [19]. Calculated over the predictive states, the multi-information would give the total amount of shared dynamical information in the system. Just as we normalized the mutual information I[X1 , X2 ] by its maximum possible value, min H[X1 ], H[X2 ], we normalize the multiinformation by its maximum, which is the smallest sum of n ‚àí 1 marginal entropies: I[X1 ; X2 ; . . . Xn ] ‚â§ min k H[Xn ] i=k Unfortunately, P is a distribution over a very high dimensional space and so, hard to estimate well without strong parametric constraints. We thus consider approximations. The lowest-order approximation treats all the units as independent; this is the distribution Q. One step up are tree distributions, where the global distribution is a function of the joint distributions of pairs of units. Not every pair of units needs to enter into such a distribution, though every unit must be part of some pair. Graphically, a tree distribution corresponds to a spanning tree, with edges linking units whose interactions enter into the global probability, and conversely spanning trees determine tree distributions. Writing ET for the set of pairs (i, j) and abbreviating X1 = x1 , X2 = x2 , . . . Xn = xn by X = x, one has n T (X = x) = (i,j)‚ààET T (Xi = xi , Xj = xj ) T (Xi = xi ) T (Xi = xi )T (Xj = xj ) i=1 (2) where the marginal distributions T (Xi ) and the pair distributions T (Xi , Xj ) are estimated by the empirical marginal and pair distributions. We must now pick edges ET so that T best approximates the true global distribution P . A natural approach is to minimize D(P ||T ), the divergence between P and its tree approximation. Chow and Liu [20] showed that the maximum-weight spanning tree gives the divergence-minimizing distribution, taking an edge‚Äôs weight to be the mutual information between the variables it links. There are three advantages to using the Chow-Liu approximation. (1) Estimating T from empirical probabilities gives a consistent maximum likelihood estimator of the ideal ChowLiu tree [20], with reasonable rates of convergence, so T can be reliably known even if P cannot. (2) There are efÔ¨Åcient algorithms for constructing maximum-weight spanning trees, such as Prim‚Äôs algorithm [21, sec. 23.2], which runs in time O(n2 + n log n). Thus, the approximation is computationally tractable. (3) The KL divergence of the Chow-Liu distribution from Q gives a lower bound on the network multi-information; that bound is just the sum of the mutual informations along the edges in the tree: I[X1 ; X2 ; . . . Xn ] ‚â• D(T ||Q) = I[Xi ; Xj ] (3) (i,j)‚ààET Even if we knew P exactly, Eq. 3 would be useful as an alternative to calculating D(P ||Q) directly, evaluating log P (x)/Q(x) for all the exponentially-many conÔ¨Ågurations x. It is natural to seek higher-order approximations to P , e.g., using three-way interactions not decomposable into pairwise interactions [22, 19]. But it is hard to do so effectively, because Ô¨Ånding the optimal approximation to P when such interactions are allowed is NP [23], and analytical formulas like Eq. 3 generally do not exist [19]. We therefore conÔ¨Åne ourselves to the Chow-Liu approximation here. 3 Example: A Model of Gamma and Beta Rhythms We use simulated data as a test case, instead of empirical multiple electrode recordings, which allows us to try the method on a system of over 1000 neurons and compare the measure against expected results. The model, taken from [24], was originally designed to study episodes of gamma (30‚Äì80Hz) and beta (12‚Äì30Hz) oscillations in the mammalian nervous system, which often occur successively with a spontaneous transition between them. More concretely, the rhythms studied were those displayed by in vitro hippocampal (CA1) slice preparations and by in vivo neocortical EEGs. The model contains two neuron populations: excitatory (AMPA) pyramidal neurons and inhibitory (GABAA ) interneurons, deÔ¨Åned by conductance-based Hodgkin-Huxley-style equations. Simulations were carried out in a network of 1000 pyramidal cells and 300 interneurons. Each cell was modeled as a one-compartment neuron with all-to-all coupling, endowed with the basic sodium and potassium spiking currents, an external applied current, and some Gaussian input noise. The Ô¨Årst 10 seconds of the simulation correspond to the gamma rhythm, in which only a group of neurons is made to spike via a linearly increasing applied current. The beta rhythm a b c d Figure 2: Heat-maps of coordination for the network, as measured by zero-lag cross-correlation (top row) and informational coherence (bottom), contrasting the gamma rhythm (left column) with the beta (right). Colors run from red (no coordination) through yellow to pale cream (maximum). (subsequent 10 seconds) is obtained by activating pyramidal-pyramidal recurrent connections (potentiated by Hebbian preprocessing as a result of synchrony during the gamma rhythm) and a slow outward after-hyper-polarization (AHP) current (the M-current), suppressed during gamma due to the metabotropic activation used in the generation of the rhythm. During the beta rhythm, pyramidal cells, silent during gamma rhythm, Ô¨Åre on a subset of interneurons cycles (Fig. 1). Fig. 2 compares zero-lag cross-correlation, a second-order method of quantifying coordination, with the informational coherence calculated from the reconstructed states. (In this simulation, we could have calculated the actual states of the model neurons directly, rather than reconstructing them, but for purposes of testing our method we did not.) Crosscorrelation Ô¨Ånds some of the relationships visible in Fig. 1, but is confused by, for instance, the phase shifts between pyramidal cells. (Surface mutual information, not shown, gives similar results.) Informational coherence, however, has no trouble recognizing the two populations as effectively coordinated blocks. The presence of dynamical noise, problematic for ordinary state reconstruction, is not an issue. The average IC is 0.411 (or 0.797 if the inactive, low-numbered neurons are excluded). The tree estimate of the global informational multi-information is 3243.7 bits, with a global coherence of 0.777. The right half of Fig. 2 repeats this analysis for the beta rhythm; in this stage, the average IC is 0.614, and the tree estimate of the global multi-information is 7377.7 bits, though the estimated global coherence falls very slightly to 0.742. This is because low-numbered neurons which were quiescent before are now active, contributing to the global information, but the over-all pattern is somewhat weaker and more noisy (as can be seen from Fig. 1b.) So, as expected, the total information content is higher, but the overall coordination across the network is lower. 4 Conclusion Informational coherence provides a measure of neural information sharing and coordinated activity which accommodates nonlinear, stochastic relationships between extended patterns of spiking. It is robust to dynamical noise and leads to a genuinely multivariate measure of global coordination across networks or regions. Applied to data from multi-electrode recordings, it should be a valuable tool in evaluating hypotheses about distributed neural representation and function. Acknowledgments Thanks to R. Haslinger, E. Ionides and S. Page; and for support to the Santa Fe Institute (under grants from Intel, the NSF and the MacArthur Foundation, and DARPA agreement F30602-00-2-0583), the Clare Booth Luce Foundation (KLK) and the James S. McDonnell Foundation (CRS). References [1] L. F. Abbott and T. J. Sejnowski, eds. Neural Codes and Distributed Representations. MIT Press, 1998. [2] E. N. Brown, R. E. Kass, and P. P. Mitra. Nature Neuroscience, 7:456‚Äì461, 2004. [3] D. H. Ballard, Z. Zhang, and R. P. N. Rao. In R. P. N. Rao, B. A. Olshausen, and M. S. Lewicki, eds., Probabilistic Models of the Brain, pp. 273‚Äì284, MIT Press, 2002. [4] D. R. Brillinger and A. E. P. Villa. In D. R. Brillinger, L. T. Fernholz, and S. Morgenthaler, eds., The Practice of Data Analysis, pp. 77‚Äì92. Princeton U.P., 1997. [5] R. Quian Quiroga et al. Physical Review E, 65:041903, 2002. [6] R. F. Streater. Statistical Dynamics. Imperial College Press, London. [7] M. L. Littman, R. S. Sutton, and S. Singh. In T. G. Dietterich, S. Becker, and Z. Ghahramani, eds., Advances in Neural Information Processing Systems 14, pp. 1555‚Äì1561. MIT Press, 2002. [8] H. Kantz and T. Schreiber. Nonlinear Time Series Analysis. Cambridge U.P., 1997. [9] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley, 1991. [10] M. Palus et al. Physical Review E, 63:046211, 2001. [11] F. B. Knight. Annals of Probability, 3:573‚Äì596, 1975. [12] C. R. Shalizi and K. L. Shalizi. In M. Chickering and J. Halpern, eds., Uncertainty in ArtiÔ¨Åcial Intelligence: Proceedings of the Twentieth Conference, pp. 504‚Äì511. AUAI Press, 2004. [13] C. R. Shalizi and J. P. CrutchÔ¨Åeld. Journal of Statistical Physics, 104:817‚Äì819, 2001. [14] H. Jaeger. Neural Computation, 12:1371‚Äì1398, 2000. [15] D. Ron, Y. Singer, and N. Tishby. Machine Learning, 25:117‚Äì149, 1996. [16] P. B¬® hlmann and A. J. Wyner. Annals of Statistics, 27:480‚Äì513, 1999. u [17] N. U. Ahmed. Linear and Nonlinear Filtering for Scientists and Engineers. World ScientiÔ¨Åc, 1998. [18] D. R. Upper. PhD thesis, University of California, Berkeley, 1997. [19] E. Schneidman, S. Still, M. J. Berry, and W. Bialek. Physical Review Letters, 91:238701, 2003. [20] C. K. Chow and C. N. Liu. IEEE Transactions on Information Theory, IT-14:462‚Äì467, 1968. [21] T. H. Cormen et al. Introduction to Algorithms. 2nd ed. MIT Press, 2001. [22] S. Amari. IEEE Transacttions on Information Theory, 47:1701‚Äì1711, 2001. [23] S. Kirshner, P. Smyth, and A. Robertson. Tech. Rep. 04-04, UC Irvine, Information and Computer Science, 2004. [24] M. S. Olufsen et al. Journal of Computational Neuroscience, 14:33‚Äì54, 2003.</p><p>4 0.06094455 <a title="120-tfidf-4" href="./nips-2005-Conditional_Visual_Tracking_in_Kernel_Space.html">45 nips-2005-Conditional Visual Tracking in Kernel Space</a></p>
<p>Author: Cristian Sminchisescu, Atul Kanujia, Zhiguo Li, Dimitris Metaxas</p><p>Abstract: We present a conditional temporal probabilistic framework for reconstructing 3D human motion in monocular video based on descriptors encoding image silhouette observations. For computational ef√Ñ?ƒπ≈° ciency we restrict visual inference to low-dimensional kernel induced non-linear state spaces. Our methodology (kBME) combines kernel PCA-based non-linear dimensionality reduction (kPCA) and Conditional Bayesian Mixture of Experts (BME) in order to learn complex multivalued predictors between observations and model hidden states. This is necessary for accurate, inverse, visual perception inferences, where several probable, distant 3D solutions exist due to noise or the uncertainty of monocular perspective projection. Low-dimensional models are appropriate because many visual processes exhibit strong non-linear correlations in both the image observations and the target, hidden state variables. The learned predictors are temporally combined within a conditional graphical model in order to allow a principled propagation of uncertainty. We study several predictors and empirically show that the proposed algorithm positively compares with techniques based on regression, Kernel Dependency Estimation (KDE) or PCA alone, and gives results competitive to those of high-dimensional mixture predictors at a fraction of their computational cost. We show that the method successfully reconstructs the complex 3D motion of humans in real monocular video sequences. 1 Introduction and Related Work We consider the problem of inferring 3D articulated human motion from monocular video. This research topic has applications for scene understanding including human-computer interfaces, markerless human motion capture, entertainment and surveillance. A monocular approach is relevant because in real-world settings the human body parts are rarely completely observed even when using multiple cameras. This is due to occlusions form other people or objects in the scene. A robust system has to necessarily deal with incomplete, ambiguous and uncertain measurements. Methods for 3D human motion reconstruction can be classi√Ñ?ƒπ≈° ed as generative and discriminative. They both require a state representation, namely a 3D human model with kinematics (joint angles) or shape (surfaces or joint positions) and they both use a set of image features as observations for state inference. The computational goal in both cases is the conditional distribution for the model state given image observations. Generative model-based approaches [6, 16, 14, 13] have been demonstrated to √Ñ?ƒπ≈°&sbquo;exibly reconstruct complex unknown human motions and to naturally handle problem constraints. However it is dif√Ñ?ƒπ≈° cult to construct reliable observation likelihoods due to the complexity of modeling human appearance. This varies widely due to different clothing and deformation, body proportions or lighting conditions. Besides being somewhat indirect, the generative approach further imposes strict conditional independence assumptions on the temporal observations given the states in order to ensure computational tractability. Due to these factors inference is expensive and produces highly multimodal state distributions [6, 16, 13]. Generative inference algorithms require complex annealing schedules [6, 13] or systematic non-linear search for local optima [16] in order to ensure continuing tracking. These dif√Ñ?ƒπ≈° culties motivate the advent of a complementary class of discriminative algorithms [10, 12, 18, 2], that approximate the state conditional directly, in order to simplify inference. However, inverse, observation-to-state multivalued mappings are dif√Ñ?ƒπ≈° cult to learn (see e.g. √Ñ?ƒπ≈° g. 1a) and a probabilistic temporal setting is necessary. In an earlier paper [15] we introduced a probabilistic discriminative framework for human motion reconstruction. Because the method operates in the originally selected state and observation spaces that can be task generic, therefore redundant and often high-dimensional, inference is more expensive and can be less robust. To summarize, reconstructing 3D human motion in a Figure 1: (a, Left) Example of 180o ambiguity in predicting 3D human poses from silhouette image features (center). It is essential that multiple plausible solutions (e.g. F 1 and F2 ) are correctly represented and tracked over time. A single state predictor will either average the distant solutions or zig-zag between them, see also tables 1 and 2. (b, Right) A conditional chain model. The local distributions p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ) or p(yt |zt ) are learned as in √Ñ?ƒπ≈° g. 2. For inference, the predicted local state conditional is recursively combined with the √Ñ?ƒπ≈° ltered prior c.f . (1). conditional temporal framework poses the following dif√Ñ?ƒπ≈° culties: (i) The mapping between temporal observations and states is multivalued (i.e. the local conditional distributions to be learned are multimodal), therefore it cannot be accurately represented using global function approximations. (ii) Human models have multivariate, high-dimensional continuous states of 50 or more human joint angles. The temporal state conditionals are multimodal which makes ef√Ñ?ƒπ≈° cient Kalman √Ñ?ƒπ≈° ltering algorithms inapplicable. General inference methods (particle √Ñ?ƒπ≈° lters, mixtures) have to be used instead, but these are expensive for high-dimensional models (e.g. when reconstructing the motion of several people that operate in a joint state space). (iii) The components of the human state and of the silhouette observation vector exhibit strong correlations, because many repetitive human activities like walking or running have low intrinsic dimensionality. It appears wasteful to work with high-dimensional states of 50+ joint angles. Even if the space were truly high-dimensional, predicting correlated state dimensions independently may still be suboptimal. In this paper we present a conditional temporal estimation algorithm that restricts visual inference to low-dimensional, kernel induced state spaces. To exploit correlations among observations and among state variables, we model the local, temporal conditional distributions using ideas from Kernel PCA [11, 19] and conditional mixture modeling [7, 5], here adapted to produce multiple probabilistic predictions. The corresponding predictor is referred to as a Conditional Bayesian Mixture of Low-dimensional Kernel-Induced Experts (kBME). By integrating it within a conditional graphical model framework (√Ñ?ƒπ≈° g. 1b), we can exploit temporal constraints probabilistically. We demonstrate that this methodology is effective for reconstructing the 3D motion of multiple people in monocular video. Our contribution w.r.t. [15] is a probabilistic conditional inference framework that operates over a non-linear, kernel-induced low-dimensional state spaces, and a set of experiments (on both real and arti√Ñ?ƒπ≈° cial image sequences) that show how the proposed framework positively compares with powerful predictors based on KDE, PCA, or with the high-dimensional models of [15] at a fraction of their cost. 2 Probabilistic Inference in a Kernel Induced State Space We work with conditional graphical models with a chain structure [9], as shown in √Ñ?ƒπ≈° g. 1b, These have continuous temporal states yt , t = 1 . . . T , observations zt . For compactness, we denote joint states Yt = (y1 , y2 , . . . , yt ) or joint observations Zt = (z1 , . . . , zt ). Learning and inference are based on local conditionals: p(yt |zt ) and p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ), with yt and zt being low-dimensional, kernel induced representations of some initial model having state xt and observation rt . We obtain zt , yt from rt , xt using kernel PCA [11, 19]. Inference is performed in a low-dimensional, non-linear, kernel induced latent state space (see √Ñ?ƒπ≈° g. 1b and √Ñ?ƒπ≈° g. 2 and (1)). For display or error reporting, we compute the original conditional p(x|r), or a temporally √Ñ?ƒπ≈° ltered version p(xt |Rt ), Rt = (r1 , r2 , . . . , rt ), using a learned pre-image state map [3]. 2.1 Density Propagation for Continuous Conditional Chains For online √Ñ?ƒπ≈° ltering, we compute the optimal distribution p(yt |Zt ) for the state yt , conditioned by observations Zt up to time t. The √Ñ?ƒπ≈° ltered density can be recursively derived as: p(yt |Zt ) = p(yt |ytƒÇÀò&circ;&rsquo;1 , zt )p(ytƒÇÀò&circ;&rsquo;1 |ZtƒÇÀò&circ;&rsquo;1 ) (1) ytƒÇÀò&circ;&rsquo;1 We compute using a conditional mixture for p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ) (a Bayesian mixture of experts c.f . ƒÇ&sbquo;√Ç¬ß2.2) and the prior p(ytƒÇÀò&circ;&rsquo;1 |ZtƒÇÀò&circ;&rsquo;1 ), each having, say M components. We integrate M 2 pairwise products of Gaussians analytically. The means of the expanded posterior are clustered and the centers are used to initialize a reduced M -component Kullback-Leibler approximation that is re√Ñ?ƒπ≈° ned using gradient descent [15]. The propagation rule (1) is similar to the one used for discrete state labels [9], but here we work with multivariate continuous state spaces and represent the local multimodal state conditionals using kBME (√Ñ?ƒπ≈° g. 2), and not log-linear models [9] (these would require intractable normalization). This complex continuous model rules out inference based on Kalman √Ñ?ƒπ≈° ltering or dynamic programming [9]. 2.2 Learning Bayesian Mixtures over Kernel Induced State Spaces (kBME) In order to model conditional mappings between low-dimensional non-linear spaces we rely on kernel dimensionality reduction and conditional mixture predictors. The authors of KDE [19] propose a powerful structured unimodal predictor. This works by decorrelating the output using kernel PCA and learning a ridge regressor between the input and each decorrelated output dimension. Our procedure is also based on kernel PCA but takes into account the structure of the studied visual problem where both inputs and outputs are likely to be low-dimensional and the mapping between them multivalued. The output variables xi are projected onto the column vectors of the principal space in order to obtain their principal coordinates y i . A z ƒÇÀò&circ;&circ; P(Fr ) O p(y|z) kP CA ƒÇ≈Ωƒπ&scaron;r (r) ƒÇÀò&Scaron;&sbquo; Fr O / y ƒÇÀò&circ;&circ; P(Fx ) O QQQ QQQ QQQ kP CA QQQ Q( ƒÇ≈Ωƒπ&scaron;x (x) ƒÇÀò&Scaron;&sbquo; Fx x ƒÇÀò&permil;&circ; PreImage(y) O ƒÇ≈Ωƒπ&scaron;r ƒÇ≈Ωƒπ&scaron;x r ƒÇÀò&circ;&circ; R ƒÇÀò&Scaron;&sbquo; Rr x ƒÇÀò&circ;&circ; X ƒÇÀò&Scaron;&sbquo; Rx  p(x|r) ƒÇÀò&permil;&circ; p(x|y) Figure 2: The learned low-dimensional predictor, kBME, for computing p(x|r) ƒÇÀò&permil;√Ñ&bdquo; p(xt |rt ), ƒÇÀò&circ;&euro;t. (We similarly learn p(xt |xtƒÇÀò&circ;&rsquo;1 , rt ), with input (x, r) instead of r ƒÇÀò&euro;&ldquo; here we illustrate only p(x|r) for clarity.) The input r and the output x are decorrelated using Kernel PCA to obtain z and y respectively. The kernels used for the input and output are ƒÇ≈Ωƒπ&scaron; r and ƒÇ≈Ωƒπ&scaron;x , with induced feature spaces Fr and Fx , respectively. Their principal subspaces obtained by kernel PCA are denoted by P(Fr ) and P(Fx ), respectively. A conditional Bayesian mixture of experts p(y|z) is learned using the low-dimensional representation (z, y). Using learned local conditionals of the form p(yt |zt ) or p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ), temporal inference can be ef√Ñ?ƒπ≈° ciently performed in a low-dimensional kernel induced state space (see e.g. (1) and √Ñ?ƒπ≈° g. 1b). For visualization and error measurement, the √Ñ?ƒπ≈° ltered density, e.g. p(yt |Zt ), can be mapped back to p(xt |Rt ) using the pre-image c.f . (3). similar procedure is performed on the inputs ri to obtain zi . In order to relate the reduced feature spaces of z and y (P(Fr ) and P(Fx )), we estimate a probability distribution over mappings from training pairs (zi , yi ). We use a conditional Bayesian mixture of experts (BME) [7, 5] in order to account for ambiguity when mapping similar, possibly identical reduced feature inputs to very different feature outputs, as common in our problem (√Ñ?ƒπ≈° g. 1a). This gives a model that is a conditional mixture of low-dimensional kernel-induced experts (kBME): M g(z|ƒÇ≈Ω√Ç¬¥ j )N (y|Wj z, ƒÇ≈Ωƒπ j ) p(y|z) = (2) j=1 where g(z|ƒÇ≈Ω√Ç¬¥ j ) is a softmax function parameterized by ƒÇ≈Ω√Ç¬¥ j and (Wj , ƒÇ≈Ωƒπ j ) are the parameters and the output covariance of expert j, here a linear regressor. As in many Bayesian settings [17, 5], the weights of the experts and of the gates, Wj and ƒÇ≈Ω√Ç¬¥ j , are controlled by hierarchical priors, typically Gaussians with 0 mean, and having inverse variance hyperparameters controlled by a second level of Gamma distributions. We learn this model using a double-loop EM and employ ML-II type approximations [8, 17] with greedy (weight) subset selection [17, 15]. Finally, the kBME algorithm requires the computation of pre-images in order to recover the state distribution x from itƒÇÀò&euro;&trade;s image y ƒÇÀò&circ;&circ; P(Fx ). This is a closed form computation for polynomial kernels of odd degree. For more general kernels optimization or learning (regression based) methods are necessary [3]. Following [3, 19], we use a sparse Bayesian kernel regressor to learn the pre-image. This is based on training data (xi , yi ): p(x|y) = N (x|AƒÇ≈Ωƒπ&scaron;y (y), ƒÇÀò&bdquo;ƒπ&scaron;) (3) with parameters and covariances (A, ƒÇÀò&bdquo;ƒπ&scaron;). Since temporal inference is performed in the low-dimensional kernel induced state space, the pre-image function needs to be calculated only for visualizing results or for the purpose of error reporting. Propagating the result from the reduced feature space P(Fx ) to the output space X pro- duces a Gaussian mixture with M elements, having coef√Ñ?ƒπ≈° cients g(z|ƒÇ≈Ω√Ç¬¥ j ) and components N (x|AƒÇ≈Ωƒπ&scaron;y (Wj z), AJƒÇ≈Ωƒπ&scaron;y ƒÇ≈Ωƒπ j JƒÇ≈Ωƒπ&scaron;y A + ƒÇÀò&bdquo;ƒπ&scaron;), where JƒÇ≈Ωƒπ&scaron;y is the Jacobian of the mapping ƒÇ≈Ωƒπ&scaron;y . 3 Experiments We run experiments on both real image sequences (√Ñ?ƒπ≈° g. 5 and √Ñ?ƒπ≈° g. 6) and on sequences where silhouettes were arti√Ñ?ƒπ≈° cially rendered. The prediction error is reported in degrees (for mixture of experts, this is w.r.t. the most probable one, but see also √Ñ?ƒπ≈° g. 4a), and normalized per joint angle, per frame. The models are learned using standard cross-validation. Pre-images are learned using kernel regressors and have average error 1.7o . Training Set and Model State Representation: For training we gather pairs of 3D human poses together with their image projections, here silhouettes, using the graphics package Maya. We use realistically rendered computer graphics human surface models which we animate using human motion capture [1]. Our original human representation (x) is based on articulated skeletons with spherical joints and has 56 skeletal d.o.f. including global translation. The database consists of 8000 samples of human activities including walking, running, turns, jumps, gestures in conversations, quarreling and pantomime. Image Descriptors: We work with image silhouettes obtained using statistical background subtraction (with foreground and background models). Silhouettes are informative for pose estimation although prone to ambiguities (e.g. the left / right limb assignment in side views) or occasional lack of observability of some of the d.o.f. (e.g. 180o ambiguities in the global azimuthal orientation for frontal views, e.g. √Ñ?ƒπ≈° g. 1a). These are multiplied by intrinsic forward / backward monocular ambiguities [16]. As observations r, we use shape contexts extracted on the silhouette [4] (5 radial, 12 angular bins, size range 1/8 to 3 on log scale). The features are computed at different scales and sizes for points sampled on the silhouette. To work in a common coordinate system, we cluster all features in the training set into K = 50 clusters. To compute the representation of a new shape feature (a point on the silhouette), we ƒÇÀò&euro;&tilde;projectƒÇÀò&euro;&trade; onto the common basis by (inverse distance) weighted voting into the cluster centers. To obtain the representation (r) for a new silhouette we regularly sample 200 points on it and add all their feature vectors into a feature histogram. Because the representation uses overlapping features of the observation the elements of the descriptor are not independent. However, a conditional temporal framework (√Ñ?ƒπ≈° g. 1b) √Ñ?ƒπ≈°&sbquo;exibly accommodates this. For experiments, we use Gaussian kernels for the joint angle feature space and dot product kernels for the observation feature space. We learn state conditionals for p(yt |zt ) and p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ) using 6 dimensions for the joint angle kernel induced state space and 25 dimensions for the observation induced feature space, respectively. In √Ñ?ƒπ≈° g. 3b) we show an evaluation of the ef√Ñ?ƒπ≈° cacy of our kBME predictor for different dimensions in the joint angle kernel induced state space (the observation feature space dimension is here 50). On the analyzed dancing sequence, that involves complex motions of the arms and the legs, the non-linear model signi√Ñ?ƒπ≈° cantly outperforms alternative PCA methods and gives good predictions for compact, low-dimensional models.1 In tables 1 and 2, as well as √Ñ?ƒπ≈° g. 4, we perform quantitative experiments on arti√Ñ?ƒπ≈° cially rendered silhouettes. 3D ground truth joint angles are available and this allows a more 1 Running times: On a Pentium 4 PC (3 GHz, 2 GB RAM), a full dimensional BME model with 5 experts takes 802s to train p(xt |xtƒÇÀò&circ;&rsquo;1 , rt ), whereas a kBME (including the pre-image) takes 95s to train p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ). The prediction time is 13.7s for BME and 8.7s (including the pre-image cost 1.04s) for kBME. The integration in (1) takes 2.67s for BME and 0.31s for kBME. The speed-up for kBME is signi√Ñ?ƒπ≈° cant and likely to increase with original models having higher dimensionality. Prediction Error Number of Clusters 100 1000 100 10 1 1 2 3 4 5 6 7 8 Degree of Multimodality kBME KDE_RVM PCA_BME PCA_RVM 10 1 0 20 40 Number of Dimensions 60 Figure 3: (a, Left) Analysis of ƒÇÀò&euro;&tilde;multimodalityƒÇÀò&euro;&trade; for a training set. The input zt dimension is 25, the output yt dimension is 6, both reduced using kPCA. We cluster independently in (ytƒÇÀò&circ;&rsquo;1 , zt ) and yt using many clusters (2100) to simulate small input perturbations and we histogram the yt clusters falling within each cluster in (ytƒÇÀò&circ;&rsquo;1 , zt ). This gives intuition on the degree of ambiguity in modeling p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ), for small perturbations in the input. (b, Right) Evaluation of dimensionality reduction methods for an arti√Ñ?ƒπ≈° cial dancing sequence (models trained on 300 samples). The kBME is our model ƒÇ&sbquo;√Ç¬ß2.2, whereas the KDE-RVM is a KDE model learned with a Relevance Vector Machine (RVM) [17] feature space map. PCA-BME and PCA-RVM are models where the mappings between feature spaces (obtained using PCA) is learned using a BME and a RVM. The non-linearity is signi√Ñ?ƒπ≈° cant. Kernel-based methods outperform PCA and give low prediction error for 5-6d models. systematic evaluation. Notice that the kernelized low-dimensional models generally outperform the PCA ones. At the same time, they give results competitive to the ones of high-dimensional BME predictors, while being lower-dimensional and therefore signi√Ñ?ƒπ≈° cantly less expensive for inference, e.g. the integral in (1). In √Ñ?ƒπ≈° g. 5 and √Ñ?ƒπ≈° g. 6 we show human motion reconstruction results for two real image sequences. Fig. 5 shows the good quality reconstruction of a person performing an agile jump. (Given the missing observations in a side view, 3D inference for the occluded body parts would not be possible without using prior knowledge!) For this sequence we do inference using conditionals having 5 modes and reduced 6d states. We initialize tracking using p(yt |zt ), whereas for inference we use p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ) within (1). In the second sequence in √Ñ?ƒπ≈° g. 6, we simultaneously reconstruct the motion of two people mimicking domestic activities, namely washing a window and picking an object. Here we do inference over a product, 12-dimensional state space consisting of the joint 6d state of each person. We obtain good 3D reconstruction results, using only 5 hypotheses. Notice however, that the results are not perfect, there are small errors in the elbow and the bending of the knee for the subject at the l.h.s., and in the different wrist orientations for the subject at the r.h.s. This re√Ñ?ƒπ≈°&sbquo;ects the bias of our training set. Walk and turn Conversation Run and turn left KDE-RR 10.46 7.95 5.22 RVM 4.95 4.96 5.02 KDE-RVM 7.57 6.31 6.25 BME 4.27 4.15 5.01 kBME 4.69 4.79 4.92 Table 1: Comparison of average joint angle prediction error for different models. All kPCA-based models use 6 output dimensions. Testing is done on 100 video frames for each sequence, the inputs are arti√Ñ?ƒπ≈° cially generated silhouettes, not in the training set. 3D joint angle ground truth is used for evaluation. KDE-RR is a KDE model with ridge regression (RR) for the feature space mapping, KDE-RVM uses an RVM. BME uses a Bayesian mixture of experts with no dimensionality reduction. kBME is our proposed model. kPCAbased methods use kernel regressors to compute pre-images. Expert Prediction Frequency ƒÇÀò&circ;&rsquo; Closest to Ground truth Frequency ƒÇÀò&circ;&rsquo; Close to ground truth 30 25 20 15 10 5 0 1 2 3 4 Expert Number 14 10 8 6 4 2 0 5 1st Probable Prev Output 2nd Probable Prev Output 3rd Probable Prev Output 4th Probable Prev Output 5th Probable Prev Output 12 1 2 3 4 Current Expert 5 Figure 4: (a, Left) Histogram showing the accuracy of various expert predictors: how many times the expert ranked as the k-th most probable by the model (horizontal axis) is closest to the ground truth. The model is consistent (the most probable expert indeed is the most accurate most frequently), but occasionally less probable experts are better. (b, Right) Histograms show the dynamics of p(yt |ytƒÇÀò&circ;&rsquo;1 , zt ), i.e. how the probability mass is redistributed among experts between two successive time steps, in a conversation sequence. Walk and turn back Run and turn KDE-RR 7.59 17.7 RVM 6.9 16.8 KDE-RVM 7.15 16.08 BME 3.6 8.2 kBME 3.72 8.01 Table 2: Joint angle prediction error computed for two complex sequences with walks, runs and turns, thus more ambiguity (100 frames). Models have 6 state dimensions. Unimodal predictors average competing solutions. kBME has signi√Ñ?ƒπ≈° cantly lower error. Figure 5: Reconstruction of a jump (selected frames). Top: original image sequence. Middle: extracted silhouettes. Bottom: 3D reconstruction seen from a synthetic viewpoint. 4 Conclusion We have presented a probabilistic framework for conditional inference in latent kernelinduced low-dimensional state spaces. Our approach has the following properties: (a) Figure 6: Reconstructing the activities of 2 people operating in an 12-d state space (each person has its own 6d state). Top: original image sequence. Bottom: 3D reconstruction seen from a synthetic viewpoint. Accounts for non-linear correlations among input or output variables, by using kernel nonlinear dimensionality reduction (kPCA); (b) Learns probability distributions over mappings between low-dimensional state spaces using conditional Bayesian mixture of experts, as required for accurate prediction. In the resulting low-dimensional kBME predictor ambiguities and multiple solutions common in visual, inverse perception problems are accurately represented. (c) Works in a continuous, conditional temporal probabilistic setting and offers a formal management of uncertainty. We show comparisons that demonstrate how the proposed approach outperforms regression, PCA or KDE alone for reconstructing the 3D human motion in monocular video. Future work we will investigate scaling aspects for large training sets and alternative structured prediction methods. References [1] CMU Human Motion DataBase. Online at http://mocap.cs.cmu.edu/search.html, 2003. [2] A. Agarwal and B. Triggs. 3d human pose from silhouettes by Relevance Vector Regression. In CVPR, 2004. [3] G. Bakir, J. Weston, and B. Scholkopf. Learning to √Ñ?ƒπ≈° nd pre-images. In NIPS, 2004. [4] S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. PAMI, 24, 2002. [5] C. Bishop and M. Svensen. Bayesian mixtures of experts. In UAI, 2003. [6] J. Deutscher, A. Blake, and I. Reid. Articulated Body Motion Capture by Annealed Particle Filtering. In CVPR, 2000. [7] M. Jordan and R. Jacobs. Hierarchical mixtures of experts and the EM algorithm. Neural Computation, (6):181ƒÇÀò&euro;&ldquo;214, 1994. [8] D. Mackay. Bayesian interpolation. Neural Computation, 4(5):720ƒÇÀò&euro;&ldquo;736, 1992. [9] A. McCallum, D. Freitag, and F. Pereira. Maximum entropy Markov models for information extraction and segmentation. In ICML, 2000. [10] R. Rosales and S. Sclaroff. Learning Body Pose Via Specialized Maps. In NIPS, 2002. [11] B. SchƒÇ&sbquo;√Ç¬® lkopf, A. Smola, and K. MƒÇ&sbquo;√Ç¬® ller. Nonlinear component analysis as a kernel eigenvalue o u problem. Neural Computation, 10:1299ƒÇÀò&euro;&ldquo;1319, 1998. [12] G. Shakhnarovich, P. Viola, and T. Darrell. Fast Pose Estimation with Parameter Sensitive Hashing. In ICCV, 2003. [13] L. Sigal, S. Bhatia, S. Roth, M. Black, and M. Isard. Tracking Loose-limbed People. In CVPR, 2004. [14] C. Sminchisescu and A. Jepson. Generative Modeling for Continuous Non-Linearly Embedded Visual Inference. In ICML, pages 759ƒÇÀò&euro;&ldquo;766, Banff, 2004. [15] C. Sminchisescu, A. Kanaujia, Z. Li, and D. Metaxas. Discriminative Density Propagation for 3D Human Motion Estimation. In CVPR, 2005. [16] C. Sminchisescu and B. Triggs. Kinematic Jump Processes for Monocular 3D Human Tracking. In CVPR, volume 1, pages 69ƒÇÀò&euro;&ldquo;76, Madison, 2003. [17] M. Tipping. Sparse Bayesian learning and the Relevance Vector Machine. JMLR, 2001. [18] C. Tomasi, S. Petrov, and A. Sastry. 3d tracking = classi√Ñ?ƒπ≈° cation + interpolation. In ICCV, 2003. [19] J. Weston, O. Chapelle, A. Elisseeff, B. Scholkopf, and V. Vapnik. Kernel dependency estimation. In NIPS, 2002.</p><p>5 0.060632672 <a title="120-tfidf-5" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>Author: Jack Wang, Aaron Hertzmann, David M. Blei</p><p>Abstract: This paper introduces Gaussian Process Dynamical Models (GPDM) for nonlinear time series analysis. A GPDM comprises a low-dimensional latent space with associated dynamics, and a map from the latent space to an observation space. We marginalize out the model parameters in closed-form, using Gaussian Process (GP) priors for both the dynamics and the observation mappings. This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach on human motion capture data in which each pose is 62-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces. Webpage: http://www.dgp.toronto.edu/‚àº jmwang/gpdm/ 1</p><p>6 0.057982333 <a title="120-tfidf-6" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>7 0.051955231 <a title="120-tfidf-7" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>8 0.048169527 <a title="120-tfidf-8" href="./nips-2005-Efficient_estimation_of_hidden_state_dynamics_from_spike_trains.html">64 nips-2005-Efficient estimation of hidden state dynamics from spike trains</a></p>
<p>9 0.047799136 <a title="120-tfidf-9" href="./nips-2005-Learning_Shared_Latent_Structure_for_Image_Synthesis_and_Robotic_Imitation.html">115 nips-2005-Learning Shared Latent Structure for Image Synthesis and Robotic Imitation</a></p>
<p>10 0.043943889 <a title="120-tfidf-10" href="./nips-2005-Generalization_Error_Bounds_for_Aggregation_by_Mirror_Descent_with_Averaging.html">82 nips-2005-Generalization Error Bounds for Aggregation by Mirror Descent with Averaging</a></p>
<p>11 0.042962544 <a title="120-tfidf-11" href="./nips-2005-Temporal_Abstraction_in_Temporal-difference_Networks.html">187 nips-2005-Temporal Abstraction in Temporal-difference Networks</a></p>
<p>12 0.041558031 <a title="120-tfidf-12" href="./nips-2005-On_Local_Rewards_and_Scaling_Distributed_Reinforcement_Learning.html">145 nips-2005-On Local Rewards and Scaling Distributed Reinforcement Learning</a></p>
<p>13 0.040067501 <a title="120-tfidf-13" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>14 0.039574008 <a title="120-tfidf-14" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>15 0.039344106 <a title="120-tfidf-15" href="./nips-2005-Off-Road_Obstacle_Avoidance_through_End-to-End_Learning.html">143 nips-2005-Off-Road Obstacle Avoidance through End-to-End Learning</a></p>
<p>16 0.038571611 <a title="120-tfidf-16" href="./nips-2005-A_Criterion_for_the_Convergence_of_Learning_with_Spike_Timing_Dependent_Plasticity.html">8 nips-2005-A Criterion for the Convergence of Learning with Spike Timing Dependent Plasticity</a></p>
<p>17 0.038508214 <a title="120-tfidf-17" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>18 0.038210988 <a title="120-tfidf-18" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>19 0.0370785 <a title="120-tfidf-19" href="./nips-2005-Estimating_the_wrong_Markov_random_field%3A_Benefits_in_the_computation-limited_setting.html">65 nips-2005-Estimating the wrong Markov random field: Benefits in the computation-limited setting</a></p>
<p>20 0.036503982 <a title="120-tfidf-20" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2005_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.118), (1, -0.0), (2, 0.073), (3, -0.003), (4, -0.015), (5, 0.009), (6, 0.055), (7, -0.036), (8, -0.002), (9, 0.014), (10, 0.119), (11, -0.084), (12, 0.038), (13, -0.031), (14, -0.053), (15, -0.02), (16, 0.157), (17, -0.009), (18, 0.001), (19, -0.018), (20, 0.071), (21, -0.11), (22, -0.071), (23, 0.137), (24, 0.01), (25, -0.015), (26, 0.05), (27, 0.079), (28, -0.078), (29, 0.033), (30, -0.078), (31, 0.025), (32, 0.004), (33, 0.109), (34, -0.178), (35, 0.04), (36, -0.02), (37, 0.324), (38, -0.191), (39, 0.075), (40, -0.132), (41, 0.011), (42, -0.094), (43, -0.087), (44, -0.013), (45, -0.114), (46, -0.249), (47, 0.138), (48, -0.138), (49, 0.188)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.89882749 <a title="120-lsi-1" href="./nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters.html">120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</a></p>
<p>Author: Pieter Abbeel, Varun Ganapathi, Andrew Y. Ng</p><p>Abstract: We consider the problem of modeling a helicopter‚Äôs dynamics based on state-action trajectories collected from it. The contribution of this paper is two-fold. First, we consider the linear models such as learned by CIFER (the industry standard in helicopter identiÔ¨Åcation), and show that the linear parameterization makes certain properties of dynamical systems, such as inertia, fundamentally difÔ¨Åcult to capture. We propose an alternative, acceleration based, parameterization that does not suffer from this deÔ¨Åciency, and that can be learned as efÔ¨Åciently from data. Second, a Markov decision process model of a helicopter‚Äôs dynamics would explicitly model only the one-step transitions, but we are often interested in a model‚Äôs predictive performance over longer timescales. In this paper, we present an efÔ¨Åcient algorithm for (approximately) minimizing the prediction error over long time scales. We present empirical results on two different helicopters. Although this work was motivated by the problem of modeling helicopters, the ideas presented here are general, and can be applied to modeling large classes of vehicular dynamics. 1</p><p>2 0.64917028 <a title="120-lsi-2" href="./nips-2005-Fast_Gaussian_Process_Regression_using_KD-Trees.html">69 nips-2005-Fast Gaussian Process Regression using KD-Trees</a></p>
<p>Author: Yirong Shen, Matthias Seeger, Andrew Y. Ng</p><p>Abstract: The computation required for Gaussian process regression with n training examples is about O(n3 ) during training and O(n) for each prediction. This makes Gaussian process regression too slow for large datasets. In this paper, we present a fast approximation method, based on kd-trees, that signiÔ¨Åcantly reduces both the prediction and the training times of Gaussian process regression.</p><p>3 0.36075401 <a title="120-lsi-3" href="./nips-2005-Fast_Krylov_Methods_for_N-Body_Learning.html">71 nips-2005-Fast Krylov Methods for N-Body Learning</a></p>
<p>Author: Nando D. Freitas, Yang Wang, Maryam Mahdaviani, Dustin Lang</p><p>Abstract: This paper addresses the issue of numerical computation in machine learning domains based on similarity metrics, such as kernel methods, spectral techniques and Gaussian processes. It presents a general solution strategy based on Krylov subspace iteration and fast N-body learning methods. The experiments show signiÔ¨Åcant gains in computation and storage on datasets arising in image segmentation, object detection and dimensionality reduction. The paper also presents theoretical bounds on the stability of these methods.</p><p>4 0.2734971 <a title="120-lsi-4" href="./nips-2005-Robust_design_of_biological_experiments.html">167 nips-2005-Robust design of biological experiments</a></p>
<p>Author: Patrick Flaherty, Adam Arkin, Michael I. Jordan</p><p>Abstract: We address the problem of robust, computationally-efÔ¨Åcient design of biological experiments. Classical optimal experiment design methods have not been widely adopted in biological practice, in part because the resulting designs can be very brittle if the nominal parameter estimates for the model are poor, and in part because of computational constraints. We present a method for robust experiment design based on a semideÔ¨Ånite programming relaxation. We present an application of this method to the design of experiments for a complex calcium signal transduction pathway, where we have found that the parameter estimates obtained from the robust design are better than those obtained from an ‚Äúoptimal‚Äù design. 1</p><p>5 0.26045379 <a title="120-lsi-5" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>Author: Jeremy Kubica, Joseph Masiero, Robert Jedicke, Andrew Connolly, Andrew W. Moore</p><p>Abstract: In this paper we consider the problem of Ô¨Ånding sets of points that conform to a given underlying model from within a dense, noisy set of observations. This problem is motivated by the task of efÔ¨Åciently linking faint asteroid detections, but is applicable to a range of spatial queries. We survey current tree-based approaches, showing a trade-off exists between single tree and multiple tree algorithms. To this end, we present a new type of multiple tree algorithm that uses a variable number of trees to exploit the advantages of both approaches. We empirically show that this algorithm performs well using both simulated and astronomical data.</p><p>6 0.25375733 <a title="120-lsi-6" href="./nips-2005-Learning_Influence_among_Interacting_Markov_Chains.html">111 nips-2005-Learning Influence among Interacting Markov Chains</a></p>
<p>7 0.22183082 <a title="120-lsi-7" href="./nips-2005-Measuring_Shared_Information_and_Coordinated_Activity_in_Neuronal_Networks.html">124 nips-2005-Measuring Shared Information and Coordinated Activity in Neuronal Networks</a></p>
<p>8 0.21359323 <a title="120-lsi-8" href="./nips-2005-Gaussian_Process_Dynamical_Models.html">80 nips-2005-Gaussian Process Dynamical Models</a></p>
<p>9 0.2105034 <a title="120-lsi-9" href="./nips-2005-Computing_the_Solution_Path_for_the_Regularized_Support_Vector_Regression.html">44 nips-2005-Computing the Solution Path for the Regularized Support Vector Regression</a></p>
<p>10 0.20757832 <a title="120-lsi-10" href="./nips-2005-Factorial_Switching_Kalman_Filters_for_Condition_Monitoring_in_Neonatal_Intensive_Care.html">68 nips-2005-Factorial Switching Kalman Filters for Condition Monitoring in Neonatal Intensive Care</a></p>
<p>11 0.20031738 <a title="120-lsi-11" href="./nips-2005-Efficient_estimation_of_hidden_state_dynamics_from_spike_trains.html">64 nips-2005-Efficient estimation of hidden state dynamics from spike trains</a></p>
<p>12 0.19904974 <a title="120-lsi-12" href="./nips-2005-Learning_to_Control_an_Octopus_Arm_with_Gaussian_Process_Temporal_Difference_Methods.html">119 nips-2005-Learning to Control an Octopus Arm with Gaussian Process Temporal Difference Methods</a></p>
<p>13 0.19840723 <a title="120-lsi-13" href="./nips-2005-Fast_biped_walking_with_a_reflexive_controller_and_real-time_policy_searching.html">73 nips-2005-Fast biped walking with a reflexive controller and real-time policy searching</a></p>
<p>14 0.19507439 <a title="120-lsi-14" href="./nips-2005-Predicting_EMG_Data_from_M1_Neurons_with_Variational_Bayesian_Least_Squares.html">155 nips-2005-Predicting EMG Data from M1 Neurons with Variational Bayesian Least Squares</a></p>
<p>15 0.19242537 <a title="120-lsi-15" href="./nips-2005-Modeling_Neuronal_Interactivity_using_Dynamic_Bayesian_Networks.html">130 nips-2005-Modeling Neuronal Interactivity using Dynamic Bayesian Networks</a></p>
<p>16 0.18925609 <a title="120-lsi-16" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>17 0.18468642 <a title="120-lsi-17" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>18 0.18333912 <a title="120-lsi-18" href="./nips-2005-Prediction_and_Change_Detection.html">156 nips-2005-Prediction and Change Detection</a></p>
<p>19 0.18237442 <a title="120-lsi-19" href="./nips-2005-Oblivious_Equilibrium%3A_A_Mean_Field_Approximation_for_Large-Scale_Dynamic_Games.html">142 nips-2005-Oblivious Equilibrium: A Mean Field Approximation for Large-Scale Dynamic Games</a></p>
<p>20 0.17925286 <a title="120-lsi-20" href="./nips-2005-Fast_Online_Policy_Gradient_Learning_with_SMD_Gain_Vector_Adaptation.html">72 nips-2005-Fast Online Policy Gradient Learning with SMD Gain Vector Adaptation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2005_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(2, 0.064), (9, 0.021), (12, 0.03), (17, 0.013), (21, 0.436), (54, 0.024), (71, 0.102), (74, 0.028), (88, 0.042), (89, 0.026), (92, 0.115)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.67477906 <a title="120-lda-1" href="./nips-2005-Learning_vehicular_dynamics%2C_with_application_to_modeling_helicopters.html">120 nips-2005-Learning vehicular dynamics, with application to modeling helicopters</a></p>
<p>Author: Pieter Abbeel, Varun Ganapathi, Andrew Y. Ng</p><p>Abstract: We consider the problem of modeling a helicopter‚Äôs dynamics based on state-action trajectories collected from it. The contribution of this paper is two-fold. First, we consider the linear models such as learned by CIFER (the industry standard in helicopter identiÔ¨Åcation), and show that the linear parameterization makes certain properties of dynamical systems, such as inertia, fundamentally difÔ¨Åcult to capture. We propose an alternative, acceleration based, parameterization that does not suffer from this deÔ¨Åciency, and that can be learned as efÔ¨Åciently from data. Second, a Markov decision process model of a helicopter‚Äôs dynamics would explicitly model only the one-step transitions, but we are often interested in a model‚Äôs predictive performance over longer timescales. In this paper, we present an efÔ¨Åcient algorithm for (approximately) minimizing the prediction error over long time scales. We present empirical results on two different helicopters. Although this work was motivated by the problem of modeling helicopters, the ideas presented here are general, and can be applied to modeling large classes of vehicular dynamics. 1</p><p>2 0.66759306 <a title="120-lda-2" href="./nips-2005-Bayesian_Sets.html">33 nips-2005-Bayesian Sets</a></p>
<p>Author: Zoubin Ghahramani, Katherine A. Heller</p><p>Abstract: Inspired by ‚ÄúGoogle‚Ñ¢ Sets‚Äù, we consider the problem of retrieving items from a concept or cluster, given a query consisting of a few items from that cluster. We formulate this as a Bayesian inference problem and describe a very simple algorithm for solving it. Our algorithm uses a modelbased concept of a cluster and ranks items using a score which evaluates the marginal probability that each item belongs to a cluster containing the query items. For exponential family models with conjugate priors this marginal probability is a simple function of sufÔ¨Åcient statistics. We focus on sparse binary data and show that our score can be evaluated exactly using a single sparse matrix multiplication, making it possible to apply our algorithm to very large datasets. We evaluate our algorithm on three datasets: retrieving movies from EachMovie, Ô¨Ånding completions of author sets from the NIPS dataset, and Ô¨Ånding completions of sets of words appearing in the Grolier encyclopedia. We compare to Google‚Ñ¢ Sets and show that Bayesian Sets gives very reasonable set completions. 1</p><p>3 0.66246617 <a title="120-lda-3" href="./nips-2005-Learning_in_Silicon%3A_Timing_is_Everything.html">118 nips-2005-Learning in Silicon: Timing is Everything</a></p>
<p>Author: John V. Arthur, Kwabena Boahen</p><p>Abstract: We describe a neuromorphic chip that uses binary synapses with spike timing-dependent plasticity (STDP) to learn stimulated patterns of activity and to compensate for variability in excitability. SpeciÔ¨Åcally, STDP preferentially potentiates (turns on) synapses that project from excitable neurons, which spike early, to lethargic neurons, which spike late. The additional excitatory synaptic current makes lethargic neurons spike earlier, thereby causing neurons that belong to the same pattern to spike in synchrony. Once learned, an entire pattern can be recalled by stimulating a subset. 1 Variability in Neural Systems Evidence suggests precise spike timing is important in neural coding, speciÔ¨Åcally, in the hippocampus. The hippocampus uses timing in the spike activity of place cells (in addition to rate) to encode location in space [1]. Place cells employ a phase code: the timing at which a neuron spikes relative to the phase of the inhibitory theta rhythm (5-12Hz) conveys information. As an animal approaches a place cell‚Äôs preferred location, the place cell not only increases its spike rate, but also spikes at earlier phases in the theta cycle. To implement a phase code, the theta rhythm is thought to prevent spiking until the input synaptic current exceeds the sum of the neuron threshold and the decreasing inhibition on the downward phase of the cycle [2]. However, even with identical inputs and common theta inhibition, neurons do not spike in synchrony. Variability in excitability spreads the activity in phase. Lethargic neurons (such as those with high thresholds) spike late in the theta cycle, since their input exceeds the sum of the neuron threshold and theta inhibition only after the theta inhibition has had time to decrease. Conversely, excitable neurons (such as those with low thresholds) spike early in the theta cycle. Consequently, variability in excitability translates into variability in timing. We hypothesize that the hippocampus achieves its precise spike timing (about 10ms) through plasticity enhanced phase-coding (PEP). The source of hippocampal timing precision in the presence of variability (and noise) remains unexplained. Synaptic plasticity can compensate for variability in excitability if it increases excitatory synaptic input to neurons in inverse proportion to their excitabilities. Recasting this in a phase-coding framework, we desire a learning rule that increases excitatory synaptic input to neurons directly related to their phases. Neurons that lag require additional synaptic input, whereas neurons that lead 120¬µm 190¬µm A B Figure 1: STDP Chip. A The chip has a 16-by-16 array of microcircuits; one microcircuit includes four principal neurons, each with 21 STDP circuits. B The STDP Chip is embedded in a circuit board including DACs, a CPLD, a RAM chip, and a USB chip, which communicates with a PC. require none. The spike timing-dependent plasticity (STDP) observed in the hippocampus satisÔ¨Åes this requirement [3]. It requires repeated pre-before-post spike pairings (within a time window) to potentiate and repeated post-before-pre pairings to depress a synapse. Here we validate our hypothesis with a model implemented in silicon, where variability is as ubiquitous as it is in biology [4]. Section 2 presents our silicon system, including the STDP Chip. Section 3 describes and characterizes the STDP circuit. Section 4 demonstrates that PEP compensates for variability and provides evidence that STDP is the compensation mechanism. Section 5 explores a desirable consequence of PEP: unconventional associative pattern recall. Section 6 discusses the implications of the PEP model, including its beneÔ¨Åts and applications in the engineering of neuromorphic systems and in the study of neurobiology. 2 Silicon System We have designed, submitted, and tested a silicon implementation of PEP. The STDP Chip was fabricated through MOSIS in a 1P5M 0.25¬µm CMOS process, with just under 750,000 transistors in just over 10mm2 of area. It has a 32 by 32 array of excitatory principal neurons commingled with a 16 by 16 array of inhibitory interneurons that are not used here (Figure 1A). Each principal neuron has 21 STDP synapses. The address-event representation (AER) [5] is used to transmit spikes off chip and to receive afferent and recurrent spike input. To conÔ¨Ågure the STDP Chip as a recurrent network, we embedded it in a circuit board (Figure 1B). The board has Ô¨Åve primary components: a CPLD (complex programmable logic device), the STDP Chip, a RAM chip, a USB interface chip, and DACs (digital-to-analog converters). The central component in the system is the CPLD. The CPLD handles AER trafÔ¨Åc, mediates communication between devices, and implements recurrent connections by accessing a lookup table, stored in the RAM chip. The USB interface chip provides a bidirectional link with a PC. The DACs control the analog biases in the system, including the leak current, which the PC varies in real-time to create the global inhibitory theta rhythm. The principal neuron consists of a refractory period and calcium-dependent potassium circuit (RCK), a synapse circuit, and a soma circuit (Figure 2A). RCK and the synapse are ISOMA Soma Synapse STDP Presyn. Spike PE LPF A Presyn. Spike Raster AH 0 0.1 Spike probability RCK Postsyn. Spike B 0.05 0.1 0.05 0.1 0.08 0.06 0.04 0.02 0 0 Time(s) Figure 2: Principal neuron. A A simpliÔ¨Åed schematic is shown, including: the synapse, refractory and calcium-dependent potassium channel (RCK), soma, and axon-hillock (AH) circuits, plus their constituent elements, the pulse extender (PE) and the low-pass Ô¨Ålter (LPF). B Spikes (dots) from 81 principal neurons are temporally dispersed, when excited by poisson-like inputs (58Hz) and inhibited by the common 8.3Hz theta rhythm (solid line). The histogram includes spikes from Ô¨Åve theta cycles. composed of two reusable blocks: the low-pass Ô¨Ålter (LPF) and the pulse extender (PE). The soma is a modiÔ¨Åed version of the LPF, which receives additional input from an axonhillock circuit (AH). RCK is inhibitory to the neuron. It consists of a PE, which models calcium inÔ¨Çux during a spike, and a LPF, which models calcium buffering. When AH Ô¨Åres a spike, a packet of charge is dumped onto a capacitor in the PE. The PE‚Äôs output activates until the charge decays away, which takes a few milliseconds. Also, while the PE is active, charge accumulates on the LPF‚Äôs capacitor, lowering the LPF‚Äôs output voltage. Once the PE deactivates, this charge leaks away as well, but this takes tens of milliseconds because the leak is smaller. The PE‚Äôs and the LPF‚Äôs inhibitory effects on the soma are both described below in terms of the sum (ISHUNT ) of the currents their output voltages produce in pMOS transistors whose sources are at Vdd (see Figure 2A). Note that, in the absence of spikes, these currents decay exponentially, with a time-constant determined by their respective leaks. The synapse circuit is excitatory to the neuron. It is composed of a PE, which represents the neurotransmitter released into the synaptic cleft, and a LPF, which represents the bound neurotransmitter. The synapse circuit is similar to RCK in structure but differs in function: It is activated not by the principal neuron itself but by the STDP circuits (or directly by afferent spikes that bypass these circuits, i.e., Ô¨Åxed synapses). The synapse‚Äôs effect on the soma is also described below in terms of the current (ISYN ) its output voltage produces in a pMOS transistor whose source is at Vdd. The soma circuit is a leaky integrator. It receives excitation from the synapse circuit and shunting inhibition from RCK and has a leak current as well. Its temporal behavior is described by: œÑ dISOMA ISYN I0 + ISOMA = dt ISHUNT where ISOMA is the current the capacitor‚Äôs voltage produces in a pMOS transistor whose source is at Vdd (see Figure 2A). ISHUNT is the sum of the leak, refractory, and calciumdependent potassium currents. These currents also determine the time constant: œÑ = C Ut Œ∫ISHUNT , where I0 and Œ∫ are transistor parameters and Ut is the thermal voltage. STDP circuit ~LTP SRAM Presynaptic spike A ~LTD Inverse number of pairings Integrator Decay Postsynaptic spike Potentiation 0.1 0.05 0 0.05 0.1 Depression -80 -40 0 Presynaptic spike Postsynaptic spike 40 Spike timing: t pre - t post (ms) 80 B Figure 3: STDP circuit design and characterization. A The circuit is composed of three subcircuits: decay, integrator, and SRAM. B The circuit potentiates when the presynaptic spike precedes the postsynaptic spike and depresses when the postsynaptic spike precedes the presynaptic spike. The soma circuit is connected to an AH, the locus of spike generation. The AH consists of model voltage-dependent sodium and potassium channel populations (modiÔ¨Åed from [6] by Kai Hynna). It initiates the AER signaling process required to send a spike off chip. To characterize principal neuron variability, we excited 81 neurons with poisson-like 58Hz spike trains (Figure 2B). We made these spike trains poisson-like by starting with a regular 200Hz spike train and dropping spikes randomly, with probability of 0.71. Thus spikes were delivered to neurons that won the coin toss in synchrony every 5ms. However, neurons did not lock onto the input synchrony due to Ô¨Åltering by the synaptic time constant (see Figure 2B). They also received a common inhibitory input at the theta frequency (8.3Hz), via their leak current. Each neuron was prevented from Ô¨Åring more than one spike in a theta cycle by its model calcium-dependent potassium channel population. The principal neurons‚Äô spike times were variable. To quantify the spike variability, we used timing precision, which we deÔ¨Åne as twice the standard deviation of spike times accumulated from Ô¨Åve theta cycles. With an input rate of 58Hz the timing precision was 34ms. 3 STDP Circuit The STDP circuit (related to [7]-[8]), for which the STDP Chip is named, is the most abundant, with 21,504 copies on the chip. This circuit is built from three subcircuits: decay, integrator, and SRAM (Figure 3A). The decay and integrator are used to implement potentiation, and depression, in a symmetric fashion. The SRAM holds the current binary state of the synapse, either potentiated or depressed. For potentiation, the decay remembers the last presynaptic spike. Its capacitor is charged when that spike occurs and discharges linearly thereafter. A postsynaptic spike samples the charge remaining on the capacitor, passes it through an exponential function, and dumps the resultant charge into the integrator. This charge decays linearly thereafter. At the time of the postsynaptic spike, the SRAM, a cross-coupled inverter pair, reads the voltage on the integrator‚Äôs capacitor. If it exceeds a threshold, the SRAM switches state from depressed to potentiated (‚àºLTD goes high and ‚àºLTP goes low). The depression side of the STDP circuit is exactly symmetric, except that it responds to postsynaptic activation followed by presynaptic activation and switches the SRAM‚Äôs state from potentiated to depressed (‚àºLTP goes high and ‚àºLTD goes low). When the SRAM is in the potentiated state, the presynaptic 50 After STDP 83 92 100 Timing precision(ms) Before STDP 75 B Before STDP After STDP 40 30 20 10 0 50 60 70 80 90 Input rate(Hz) 100 50 58 67 text A 0.2 0.4 Time(s) 0.6 0.2 0.4 Time(s) 0.6 C Figure 4: Plasticity enhanced phase-coding. A Spike rasters of 81 neurons (9 by 9 cluster) display synchrony over a two-fold range of input rates after STDP. B The degree of enhancement is quantiÔ¨Åed by timing precision. C Each neuron (center box) sends synapses to (dark gray) and receives synapses from (light gray) twenty-one randomly chosen neighbors up to Ô¨Åve nodes away (black indicates both connections). spike activates the principal neuron‚Äôs synapse; otherwise the spike has no effect. We characterized the STDP circuit by activating a plastic synapse and a Ô¨Åxed synapse‚Äì which elicits a spike at different relative times. We repeated this pairing at 16Hz. We counted the number of pairings required to potentiate (or depress) the synapse. Based on this count, we calculated the efÔ¨Åcacy of each pairing as the inverse number of pairings required (Figure 3B). For example, if twenty pairings were required to potentiate the synapse, the efÔ¨Åcacy of that pre-before-post time-interval was one twentieth. The efÔ¨Åcacy of both potentiation and depression are Ô¨Åt by exponentials with time constants of 11.4ms and 94.9ms, respectively. This behavior is similar to that observed in the hippocampus: potentiation has a shorter time constant and higher maximum efÔ¨Åcacy than depression [3]. 4 Recurrent Network We carried out an experiment designed to test the STDP circuit‚Äôs ability to compensate for variability in spike timing through PEP. Each neuron received recurrent connections from 21 randomly selected neurons within an 11 by 11 neighborhood centered on itself (see Figure 4C). Conversely, it made recurrent connections to randomly chosen neurons within the same neighborhood. These connections were mediated by STDP circuits, initialized to the depressed state. We chose a 9 by 9 cluster of neurons and delivered spikes at a mean rate of 50 to 100Hz to each one (dropping spikes with a probability of 0.75 to 0.5 from a regular 200Hz train) and provided common theta inhibition as before. We compared the variability in spike timing after Ô¨Åve seconds of learning with the initial distribution. Phase coding was enhanced after STDP (Figure 4A). Before STDP, spike timing among neurons was highly variable (except for the very highest input rate). After STDP, variability was virtually eliminated (except for the very lowest input rate). Initially, the variability, characterized by timing precision, was inversely related to the input rate, decreasing from 34 to 13ms. After Ô¨Åve seconds of STDP, variability decreased and was largely independent of input rate, remaining below 11ms. Potentiated synapses 25 A Synaptic state after STDP 20 15 10 5 0 B 50 100 150 200 Spiking order 250 Figure 5: Compensating for variability. A Some synapses (dots) become potentiated (light) while others remain depressed (dark) after STDP. B The number of potentiated synapses neurons make (pluses) and receive (circles) is negatively (r = -0.71) and positively (r = 0.76) correlated to their rank in the spiking order, respectively. Comparing the number of potentiated synapses each neuron made or received with its excitability conÔ¨Årmed the PEP hypothesis (i.e., leading neurons provide additional synaptic current to lagging neurons via potentiated recurrent synapses). In this experiment, to eliminate variability due to noise (as opposed to excitability), we provided a 17 by 17 cluster of neurons with a regular 200Hz excitatory input. Theta inhibition was present as before and all synapses were initialized to the depressed state. After 10 seconds of STDP, a large fraction of the synapses were potentiated (Figure 5A). When the number of potentiated synapses each neuron made or received was plotted versus its rank in spiking order (Figure 5B), a clear correlation emerged (r = -0.71 or 0.76, respectively). As expected, neurons that spiked early made more and received fewer potentiated synapses. In contrast, neurons that spiked late made fewer and received more potentiated synapses. 5 Pattern Completion After STDP, we found that the network could recall an entire pattern given a subset, thus the same mechanisms that compensated for variability and noise could also compensate for lack of information. We chose a 9 by 9 cluster of neurons as our pattern and delivered a poisson-like spike train with mean rate of 67Hz to each one as in the Ô¨Årst experiment. Theta inhibition was present as before and all synapses were initialized to the depressed state. Before STDP, we stimulated a subset of the pattern and only neurons in that subset spiked (Figure 6A). After Ô¨Åve seconds of STDP, we stimulated the same subset again. This time they recruited spikes from other neurons in the pattern, completing it (Figure 6B). Upon varying the fraction of the pattern presented, we found that the fraction recalled increased faster than the fraction presented. We selected subsets of the original pattern randomly, varying the fraction of neurons chosen from 0.1 to 1.0 (ten trials for each). We classiÔ¨Åed neurons as active if they spiked in the two second period over which we recorded. Thus, we characterized PEP‚Äôs pattern-recall performance as a function of the probability that the pattern in question‚Äôs neurons are activated (Figure 6C). At a fraction of 0.50 presented, nearly all of the neurons in the pattern are consistently activated (0.91¬±0.06), showing robust pattern completion. We Ô¨Åtted the recall performance with a sigmoid that reached 0.50 recall fraction with an input fraction of 0.30. No spurious neurons were activated during any trials. Rate(Hz) Rate(Hz) 8 7 7 6 6 5 5 0.6 0.4 2 0.2 0 0 3 3 2 1 1 A 0.8 4 4 Network activity before STDP 1 Fraction of pattern actived 8 0 B Network activity after STDP C 0 0.2 0.4 0.6 0.8 Fraction of pattern stimulated 1 Figure 6: Associative recall. A Before STDP, half of the neurons in a pattern are stimulated; only they are activated. B After STDP, half of the neurons in a pattern are stimulated, and all are activated. C The fraction of the pattern activated grows faster than the fraction stimulated. 6 Discussion Our results demonstrate that PEP successfully compensates for graded variations in our silicon recurrent network using binary (on‚Äìoff) synapses (in contrast with [8], where weights are graded). While our chip results are encouraging, variability was not eliminated in every case. In the case of the lowest input (50Hz), we see virtually no change (Figure 4A). We suspect the timing remains imprecise because, with such low input, neurons do not spike every theta cycle and, consequently, provide fewer opportunities for the STDP synapses to potentiate. This shortfall illustrates the system‚Äôs limits; it can only compensate for variability within certain bounds, and only for activity appropriate to the PEP model. As expected, STDP is the mechanism responsible for PEP. STDP potentiated recurrent synapses from leading neurons to lagging neurons, reducing the disparity among the diverse population of neurons. Even though the STDP circuits are themselves variable, with different efÔ¨Åcacies and time constants, when using timing the sign of the weight-change is always correct (data not shown). For this reason, we chose STDP over other more physiological implementations of plasticity, such as membrane-voltage-dependent plasticity (MVDP), which has the capability to learn with graded voltage signals [9], such as those found in active dendrites, providing more computational power [10]. Previously, we investigated a MVDP circuit, which modeled a voltage-dependent NMDAreceptor-gated synapse [11]. It potentiated when the calcium current analog exceeded a threshold, which was designed to occur only during a dendritic action potential. This circuit produced behavior similar to STDP, implying it could be used in PEP. However, it was sensitive to variability in the NMDA and potentiation thresholds, causing a fraction of the population to potentiate anytime the synapse received an input and another fraction to never potentiate, rendering both subpopulations useless. Therefore, the simpler, less biophysical STDP circuit won out over the MVDP circuit: In our system timing is everything. Associative storage and recall naturally emerge in the PEP network when synapses between neurons coactivated by a pattern are potentiated. These synapses allow neurons to recruit their peers when a subset of the pattern is presented, thereby completing the pattern. However, this form of pattern storage and completion differs from HopÔ¨Åeld‚Äôs attractor model [12] . Rather than forming symmetric, recurrent neuronal circuits, our recurrent network forms asymmetric circuits in which neurons make connections exclusively to less excitable neurons in the pattern. In both the poisson-like and regular cases (Figures 4 & 5), only about six percent of potentiated connections were reciprocated, as expected by chance. We plan to investigate the storage capacity of this asymmetric form of associative memory. Our system lends itself to modeling brain regions that use precise spike timing, such as the hippocampus. We plan to extend the work presented to store and recall sequences of patterns, as the hippocampus is hypothesized to do. Place cells that represent different locations spike at different phases of the theta cycle, in relation to the distance to their preferred locations. This sequential spiking will allow us to link patterns representing different locations in the order those locations are visited, thereby realizing episodic memory. We propose PEP as a candidate neural mechanism for information coding and storage in the hippocampal system. Observations from the CA1 region of the hippocampus suggest that basal dendrites (which primarily receive excitation from recurrent connections) support submillisecond timing precision, consistent with PEP [13]. We have shown, in a silicon model, PEP‚Äôs ability to exploit such fast recurrent connections to sharpen timing precision as well as to associatively store and recall patterns. Acknowledgments We thank Joe Lin for assistance with chip generation. The OfÔ¨Åce of Naval Research funded this work (Award No. N000140210468). References [1] O‚ÄôKeefe J. & Recce M.L. (1993). Phase relationship between hippocampal place units and the EEG theta rhythm. Hippocampus 3(3):317-330. [2] Mehta M.R., Lee A.K. & Wilson M.A. (2002) Role of experience and oscillations in transforming a rate code into a temporal code. Nature 417(6890):741-746. [3] Bi G.Q. & Wang H.X. (2002) Temporal asymmetry in spike timing-dependent synaptic plasticity. Physiology & Behavior 77:551-555. [4] Rodriguez-Vazquez, A., Linan, G., Espejo S. & Dominguez-Castro R. (2003) Mismatch-induced trade-offs and scalability of analog preprocessing visual microprocessor chips. Analog Integrated Circuits and Signal Processing 37:73-83. [5] Boahen K.A. (2000) Point-to-point connectivity between neuromorphic chips using address events. IEEE Transactions on Circuits and Systems II 47:416-434. [6] Culurciello E.R., Etienne-Cummings R. & Boahen K.A. (2003) A biomorphic digital image sensor. IEEE Journal of Solid State Circuits 38:281-294. [7] BoÔ¨Åll A., Murray A.F & Thompson D.P. (2005) Citcuits for VLSI Implementation of Temporally Asymmetric Hebbian Learning. In: Advances in Neural Information Processing Systems 14, MIT Press, 2002. [8] Cameron K., Boonsobhak V., Murray A. & Renshaw D. (2005) Spike timing dependent plasticity (STDP) can ameliorate process variations in neuromorphic VLSI. IEEE Transactions on Neural Networks 16(6):1626-1627. [9] Chicca E., Badoni D., Dante V., D‚ÄôAndreagiovanni M., Salina G., Carota L., Fusi S. & Del Giudice P. (2003) A VLSI recurrent network of integrate-and-Ô¨Åre neurons connected by plastic synapses with long-term memory. IEEE Transaction on Neural Networks 14(5):1297-1307. [10] Poirazi P., & Mel B.W. (2001) Impact of active dendrites and structural plasticity on the memory capacity of neural tissue. Neuron 29(3)779-796. [11] Arthur J.V. & Boahen K. (2004) Recurrently connected silicon neurons with active dendrites for one-shot learning. In: IEEE International Joint Conference on Neural Networks 3, pp.1699-1704. [12] HopÔ¨Åeld J.J. (1984) Neurons with graded response have collective computational properties like those of two-state neurons. Proceedings of the National Academy of Science 81(10):3088-3092. [13] Ariav G., Polsky A. & Schiller J. (2003) Submillisecond precision of the input-output transformation function mediated by fast sodium dendritic spikes in basal dendrites of CA1 pyramidal neurons. Journal of Neuroscience 23(21):7750-7758.</p><p>4 0.37362874 <a title="120-lda-4" href="./nips-2005-From_Weighted_Classification_to_Policy_Search.html">78 nips-2005-From Weighted Classification to Policy Search</a></p>
<p>Author: Doron Blatt, Alfred O. Hero</p><p>Abstract: This paper proposes an algorithm to convert a T -stage stochastic decision problem with a continuous state space to a sequence of supervised learning problems. The optimization problem associated with the trajectory tree and random trajectory methods of Kearns, Mansour, and Ng, 2000, is solved using the Gauss-Seidel method. The algorithm breaks a multistage reinforcement learning problem into a sequence of single-stage reinforcement learning subproblems, each of which is solved via an exact reduction to a weighted-classiÔ¨Åcation problem that can be solved using off-the-self methods. Thus the algorithm converts a reinforcement learning problem into simpler supervised learning subproblems. It is shown that the method converges in a Ô¨Ånite number of steps to a solution that cannot be further improved by componentwise optimization. The implication of the proposed algorithm is that a plethora of classiÔ¨Åcation methods can be applied to Ô¨Ånd policies in the reinforcement learning problem. 1</p><p>5 0.36819932 <a title="120-lda-5" href="./nips-2005-Inferring_Motor_Programs_from_Images_of_Handwritten_Digits.html">97 nips-2005-Inferring Motor Programs from Images of Handwritten Digits</a></p>
<p>Author: Vinod Nair, Geoffrey E. Hinton</p><p>Abstract: We describe a generative model for handwritten digits that uses two pairs of opposing springs whose stiffnesses are controlled by a motor program. We show how neural networks can be trained to infer the motor programs required to accurately reconstruct the MNIST digits. The inferred motor programs can be used directly for digit classiÔ¨Åcation, but they can also be used in other ways. By adding noise to the motor program inferred from an MNIST image we can generate a large set of very different images of the same class, thus enlarging the training set available to other methods. We can also use the motor programs as additional, highly informative outputs which reduce overÔ¨Åtting when training a feed-forward classiÔ¨Åer. 1 Overview The idea that patterns can be recognized by Ô¨Åguring out how they were generated has been around for at least half a century [1, 2] and one of the Ô¨Årst proposed applications was the recognition of handwriting using a generative model that involved pairs of opposing springs [3, 4]. The ‚Äúanalysis-by-synthesis‚Äù approach is attractive because the true generative model should provide the most natural way to characterize a class of patterns. The handwritten 2‚Äôs in Ô¨Ågure 1, for example, are very variable when viewed as pixels but they have very similar motor programs. Despite its obvious merits, analysis-by-synthesis has had few successes, partly because it is computationally expensive to invert non-linear generative models and partly because the underlying parameters of the generative model are unknown for most large data sets. For example, the only source of information about how the MNIST digits were drawn is the images themselves. We describe a simple generative model in which a pen is controlled by two pairs of opposing springs whose stiffnesses are speciÔ¨Åed by a motor program. If the sequence of stiffnesses is speciÔ¨Åed correctly, the model can produce images which look very like the MNIST digits. Using a separate network for each digit class, we show that backpropagation can be used to learn a ‚Äúrecognition‚Äù network that maps images to the motor programs required to produce them. An interesting aspect of this learning is that the network creates its own training data, so it does not require the training images to be labelled with motor programs. Each recognition network starts with a single example of a motor program and grows an ‚Äúisland of competence‚Äù around this example, progressively extending the region over which it can map small changes in the image to the corresponding small changes in the motor program (see Ô¨Ågure 2). Figure 1: An MNIST image of a 2 and the additional images that can be generated by inferring the motor program and then adding random noise to it. The pixels are very different, but they are all clearly twos. Fairly good digit recognition can be achieved by using the 10 recognition networks to Ô¨Ånd 10 motor programs for a test image and then scoring each motor program by its squared error in reconstructing the image. The 10 scores are then fed into a softmax classiÔ¨Åer. Recognition can be improved by using PCA to model the distribution of motor trajectories for each class and using the distance of a motor trajectory from the relevant PCA hyperplane as an additional score. Each recognition network is solving a difÔ¨Åcult global search problem in which the correct motor program must be found by a single, ‚Äúopen-loop‚Äù pass through the network. More accurate recognition can be achieved by using this open-loop global search to initialize an iterative, closed-loop local search which uses the error in the reconstructed image to revise the motor program. This requires reconstruction errors in pixel space to be mapped to corrections in the space of spring stiffnesses. We cannot backpropagate errors through the generative model because it is just a hand-coded computer program. So we learn ‚Äúgenerative‚Äù networks, one per digit class, that emulate the generator. After learning, backpropagation through these generative networks is used to convert pixel reconstruction errors into stiffness corrections. Our Ô¨Ånal system gives 1.82% error on the MNIST test set which is similar to the 1.7% achieved by a very different generative approach [5] but worse than the 1.53% produced by the best backpropagation networks or the 1.4% produced by support vector machines [6]. It is much worse than the 0.4% produced by convolutional neural networks that use cleverly enhanced training sets [7]. Recognition of test images is quite slow because it uses ten different recognition networks followed by iterative local search. There is, however, a much more efÔ¨Åcient way to make use of our ability to extract motor programs. They can be treated as additional output labels when using backpropagation to train a single, multilayer, discriminative neural network. These additional labels act as a very informative regularizer that reduces the error rate from 1.53% to 1.27% in a network with two hidden layers of 500 units each. This is a new method of improving performance that can be used in conjunction with other tricks such as preprocessing the images, enhancing the training set or using convolutional neural nets [8, 7]. 2 A simple generative model for drawing digits The generative model uses two pairs of opposing springs at right angles. One end of each spring is attached to a frictionless horizontal or vertical rail that is 39 pixels from the center of the image. The other end is attached to a ‚Äúpen‚Äù that has signiÔ¨Åcant mass. The springs themselves are weightless and have zero rest length. The pen starts at the equilibrium position deÔ¨Åned by the initial stiffnesses of the four springs. It then follows a trajectory that is determined by the stiffness of each spring at each of the 16 subsequent time steps in the motor program. The mass is large compared with the rate at which the stiffnesses change, so the system is typically far from equilibrium as it follows the smooth trajectory. On each time step, the momentum is multiplied by 0.9 to simulate viscosity. A coarse-grain trajectory is computed by using one step of forward integration for each time step in the motor program, so it contains 17 points. The code is at www.cs.toronto.edu/‚àº hinton/code. Figure 2: The training data for each class-speciÔ¨Åc recognition network is produced by adding noise to motor programs that are inferred from MNIST images using the current parameters of the recognition network. To initiate this process, the biases of the output units are set by hand so that they represent a prototypical motor program for the class. Given a coarse-grain trajectory, we need a way of assigning an intensity to each pixel. We tried various methods until we hand-evolved one that was able to reproduce the MNIST images fairly accurately, but we suspect that many other methods would be just as good. For each point on the coarse trajectory, we share two units of ink between the the four closest pixels using bilinear interpolation. We also use linear interpolation to add three Ô¨Åne-grain trajectory points between every pair of coarse-grain points. These Ô¨Åne-grain points also contribute ink to the pixels using bilinear interpolation, but the amount of ink they contribute is zero if they are less than one pixel apart and rises linearly to the same amount as the coarse-grain points if they are more than two pixels apart. This generates a thin skeleton with a fairly uniform ink density. To Ô¨Çesh-out the skeleton, we use two ‚Äúink parameters‚Äù, a a a a a, b, to specify a 3 √ó 3 kernel of the form b(1 + a)[ 12 , a , 12 ; a , 1 ‚àí a, a ; 12 , a , 12 ] which 6 6 6 6 is convolved with the image four times. Finally, the pixel intensities are clipped to lie in the interval [0,1]. The matlab code is at www.cs.toronto.edu/‚àº hinton/code. The values of 2a and b/1.5 are additional, logistic outputs of the recognition networks1 . 3 Training the recognition networks The obvious way to learn a recognition network is to use a training set in which the inputs are images and the target outputs are the motor programs that were used to generate those images. If we knew the distribution over motor programs for a given digit class, we could easily produce such a set by running the generator. Unfortunately, the distribution over motor programs is exactly what we want to learn from the data, so we need a way to train 1 We can add all sorts of parameters to the hand-coded generative model and then get the recognition networks to learn to extract the appropriate values for each image. The global mass and viscosity as well as the spacing of the rails that hold the springs can be learned. We can even implement afÔ¨Ånelike transformations by attaching the four springs to endpoints whose eight coordinates are given by the recognition networks. These extra parameters make the learning slower and, for the normalized digits, they do not improve discrimination, probably because they help the wrong digit models as much as the right one. the recognition network without knowing this distribution in advance. Generating scribbles from random motor programs will not work because the capacity of the network will be wasted on irrelevant images that are far from the real data. Figure 2 shows how a single, prototype motor program can be used to initialize a learning process that creates its own training data. The prototype consists of a sequence of 4 √ó 17 spring stiffnesses that are used to set the biases on 68 of the 70 logistic output units of the recognition net. If the weights coming from the 400 hidden units are initially very small, the recognition net will then output a motor program that is a close approximation to the prototype, whatever the input image. Some random noise is then added to this motor program and it is used to generate a training image. So initially, all of the generated training images are very similar to the one produced by the prototype. The recognition net will therefore devote its capacity to modeling the way in which small changes in these images map to small changes in the motor program. Images in the MNIST training set that are close to the prototype will then be given their correct motor programs. This will tend to stretch the distribution of motor programs produced by the network along the directions that correspond to the manifold on which the digits lie. As time goes by, the generated training set will expand along the manifold for that digit class until all of the MNIST training images of that class are well modelled by the recognition network. It takes about 10 hours in matlab on a 3 GHz Xeon to train each recognition network. We use minibatches of size 100, momentum of 0.9, and adaptive learning rates on each connection that increase additively when the sign of the gradient agrees with the sign of the previous weight change and decrease multiplicatively when the signs disagree [9]. The net is generating its own training data, so the objective function is always changing which makes it inadvisable to use optimization methods that go as far as they can in a carefully chosen direction. Figures 3 and 4 show some examples of how well the recognition nets perform after training. Nearly all models achieve an average squared pixel error of less than 15 per image on their validation set (pixel intensities are between 0 and 1 with a preponderance of extreme values). The inferred motor programs are clearly good enough to capture the diverse handwriting styles in the data. They are not good enough, however, to give classiÔ¨Åcation performance comparable to the state-of-the-art on the MNIST database. So we added a series of enhancements to the basic system to improve the classiÔ¨Åcation accuracy. 4 Enhancements to the basic system Extra strokes in ones and sevens. One limitation of the basic system is that it draws digits using only a single stroke (i.e. the trajectory is a single, unbroken curve). But when people draw digits, they often add extra strokes to them. Two of the most common examples are the dash at the bottom of ones, and the dash through the middle of sevens (see examples in Ô¨Ågure 5). About 2.2% of ones and 13% of sevens in the MNIST training set are dashed and not modelling the dashes reduces classiÔ¨Åcation accuracy signiÔ¨Åcantly. We model dashed ones and sevens by augmenting their basic motor programs with another motor program to draw the dash. For example, a dashed seven is generated by Ô¨Årst drawing an ordinary seven using the motor program computed by the seven model, and then drawing the dash with a motor program computed by a separate neural network that models only dashes. Dashes in ones and sevens are modeled with two different networks. Their training proceeds the same way as with the other models, except now there are only 50 hidden units and the training set contains only the dashed cases of the digit. (Separating these cases from the rest of the MNIST training set is easy because they can be quickly spotted by looking at the difference between the images and their reconstructions by the dashless digit model.) The net takes the entire image of a digit as input, and computes the motor program for just the dash. When reconstructing an unlabelled image as say, a seven, we compute both Figure 3: Examples of validation set images reconstructed by their corresponding model. In each case the original image is on the left and the reconstruction is on the right. Superimposed on the original image is the pen trajectory. the dashed and dashless versions of seven and pick the one with the lower squared pixel error to be that image‚Äôs reconstruction as a seven. Figure 5 shows examples of images reconstructed using the extra stroke. Local search. When reconstructing an image in its own class, a digit model often produces a sensible, overall approximation of the image. However, some of the Ô¨Åner details of the reconstruction may be slightly wrong and need to be Ô¨Åxed up by an iterative local search that adjusts the motor program to reduce the reconstruction error. We Ô¨Årst approximate the graphics model with a neural network that contains a single hidden layer of 500 logistic units. We train one such generative network for each of the ten digits and for the dashed version of ones and sevens (for a total of 12 nets). The motor programs used for training are obtained by adding noise to the motor programs inferred from the training data by the relevant, fully trained recognition network. The images produced from these motor programs by the graphics model are used as the targets for the supervised learning of each generative network. Given these targets, the weight updates are computed in the same way as for the recognition networks. Figure 4: To model 4‚Äôs we use a single smooth trajectory, but turn off the ink for timesteps 9 and 10. For images in which the pen does not need to leave the paper, the recognition net Ô¨Ånds a trajectory in which points 8 and 11 are close together so that points 9 and 10 are not needed. For 5‚Äôs we leave the top until last and turn off the ink for timesteps 13 and 14. Figure 5: Examples of dashed ones and sevens reconstructed using a second stroke. The pen trajectory for the dash is shown in blue, superimposed on the original image. Initial squared pixel error = 33.8 10 iterations, error = 15.2 20 iterations, error = 10.5 30 iterations, error = 9.3 Figure 6: An example of how local search improves the detailed registration of the trajectory found by the correct model. After 30 iterations, the squared pixel error is less than a third of its initial value. Once the generative network is trained, we can use it to iteratively improve the initial motor program computed by the recognition network for an image. The main steps in one iteration are: 1) compute the error between the image and the reconstruction generated from the current motor program by the graphics model; 2) backpropagate the reconstruction error through the generative network to calculate its gradient with respect to the motor program; 3) compute a new motor program by taking a step along the direction of steepest descent plus 0.5 times the previous step. Figure 6 shows an example of how local search improves the reconstruction by the correct model. Local search is usually less effective at improving the Ô¨Åts of the wrong models, so it eliminates about 20% of the classiÔ¨Åcation errors on the validation set. PCA model of the image residuals. The sum of squared pixel errors is not the best way of comparing an image with its reconstruction, because it treats the residual pixel errors as independent and zero-mean Gaussian distributed, which they are not. By modelling the structure in the residual vectors, we can get a better estimate of the conditional probability of the image given the motor program. For each digit class, we construct a PCA model of the image residual vectors for the training images. Then, given a test image, we project the image residual vector produced by each inferred motor program onto the relevant PCA hyperplane and compute the squared distance between the residual and its projection. This gives ten scores for the image that measure the quality of its reconstructions by the digit models. We don‚Äôt discard the old sum of squared pixel errors as they are still useful for classifying most images correctly. Instead, all twenty scores are used as inputs to the classiÔ¨Åer, which decides how to combine both types of scores to achieve high classiÔ¨Åcation accuracy. PCA model of trajectories. Classifying an image by comparing its reconstruction errors for the different digit models tacitly relies on the assumption that the incorrect models will reconstruct the image poorly. Since the models have only been trained on images in their Squared error = 24.9, Shape prior score = 31.5 Squared error = 15.0, Shape prior score = 104.2 Figure 7: Reconstruction of a two image by the two model (left box) and by the three model (right box), with the pen trajectory superimposed on the original image. The three model sharply bends the bottom of its trajectory to better explain the ink, but the trajectory prior for three penalizes it with a high score. The two model has a higher squared error, but a much lower prior score, which allows the classiÔ¨Åer to correctly label the image. own class, they often do reconstruct images from other classes poorly, but occasionally they Ô¨Åt an image from another class well. For example, Ô¨Ågure 7 shows how the three model reconstructs a two image better than the two model by generating a highly contorted three. This problem becomes even more pronounced with local search which sometimes contorts the wrong model to Ô¨Åt the image really well. The solution is to learn a PCA model of the trajectories that a digit model infers from images in its own class. Given a test image, the trajectory computed by each digit model is scored by its squared distance from the relevant PCA hyperplane. These 10 ‚Äúprior‚Äù scores are then given to the classiÔ¨Åer along with the 20 ‚Äúlikelihood‚Äù scores described above. The prior scores eliminate many classiÔ¨Åcation mistakes such as the one in Ô¨Ågure 7. 5 ClassiÔ¨Åcation results To classify a test image, we apply multinomial logistic regression to the 30 scores ‚Äì i.e. we use a neural network with no hidden units, 10 softmax output units and a cross-entropy error. The net is trained by gradient descent using the scores for the validation set images. To illustrate the gain in classiÔ¨Åcation accuracy achieved by the enhancements explained above, table 1 gives the percent error on the validation set as each enhancement is added to the system. Together, the enhancements almost halve the number of mistakes. Enhancements None 1 1, 2 1, 2, 3 1, 2, 3, 4 Validation set % error 4.43 3.84 3.01 2.67 2.28 Test set % error 1.82 Table 1: The gain in classiÔ¨Åcation accuracy on the validation set as the following enhancements are added: 1) extra stroke for dashed ones and sevens, 2) local search, 3) PCA model of image residual, and 4) PCA trajectory prior. To avoid using the test set for model selection, the performance on the ofÔ¨Åcial test set was only measured for the Ô¨Ånal system. 6 Discussion After training a single neural network to output both the class label and the motor program for all classes (as described in section 1) we tried ignoring the label output and classifying the test images by using the cost, under 10 different PCA models, of the trajectory deÔ¨Åned by the inferred motor program. Each PCA model was Ô¨Åtted to the trajectories extracted from the training images for a given class. This gave 1.80% errors which is as good as the 1.82% we got using the 10 separate recognition networks and local search. This is quite surprising because the motor programs produced by the single network were simpliÔ¨Åed to make them all have the same dimensionality and they produced signiÔ¨Åcantly poorer reconstructions. By only using the 10 digit-speciÔ¨Åc recognition nets to create the motor programs for the training data, we get much faster recognition of test data because at test time we can use a single recognition network for all classes. It also means we do not need to trade-off prior scores against image residual scores because there is only one image residual. The ability to extract motor programs could also be used to enhance the training set. [7] shows that error rates can be halved by using smooth vector distortion Ô¨Åelds to create extra training data. They argue that these Ô¨Åelds simulate ‚Äúuncontrolled oscillations of the hand muscles dampened by inertia‚Äù. Motor noise may be better modelled by adding noise to an actual motor program as shown in Ô¨Ågure 1. Notice that this produces a wide variety of non-blurry images and it can also change the topology. The techniques we have used for extracting motor programs from digit images may be applicable to speech. There are excellent generative models that can produce almost perfect speech if they are given the right formant parameters [10]. Using one of these generative models we may be able to train a large number of specialized recognition networks to extract formant parameters from speech without requiring labeled training data. Once this has been done, labeled data would be available for training a single feed-forward network that could recover accurate formant parameters which could be used for real-time recognition. Acknowledgements We thank Steve Isard, David MacKay and Allan Jepson for helpful discussions. This research was funded by NSERC, CFI and OIT. GEH is a fellow of the Canadian Institute for Advanced Research and holds a Canada Research Chair in machine learning. References [1] D. M. MacKay. Mindlike behaviour in artefacts. British Journal for Philosophy of Science, 2:105‚Äì121, 1951. [2] M. Halle and K. Stevens. Speech recognition: A model and a program for research. IRE Transactions on Information Theory, IT-8 (2):155‚Äì159, 1962. [3] Murray Eden. Handwriting and pattern recognition. IRE Transactions on Information Theory, IT-8 (2):160‚Äì166, 1962. [4] J.M. Hollerbach. An oscillation theory of handwriting. Biological Cybernetics, 39:139‚Äì156, 1981. [5] G. Mayraz and G. E. Hinton. Recognizing hand-written digits using hierarchical products of experts. IEEE Transactions on Pattern Analysis and Machine Intelligence, 24:189‚Äì197, 2001. [6] D. Decoste and B. Schoelkopf. Training invariant support vector machines. Machine Learning, 46:161‚Äì190, 2002. [7] Patrice Y. Simard, Dave Steinkraus, and John Platt. Best practice for convolutional neural networks applied to visual document analysis. In International Conference on Document Analysis and Recogntion (ICDAR), IEEE Computer Society, Los Alamitos, pages 958‚Äì962, 2003. [8] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278‚Äì2324, November 1998. [9] A. Jacobs R. Increased Rates of Convergence Through Learning Rate Adaptation. Technical Report: UM-CS-1987-117. University of Massachusetts, Amherst, MA, 1987. [10] W. Holmes, J. Holmes, and M. Judd. Extension of the bandwith of the jsru parallel-formant synthesizer for high quality synthesis of male and female speech. In Proceedings of ICASSP 90 (1), pages 313‚Äì316, 1990.</p><p>6 0.36814511 <a title="120-lda-6" href="./nips-2005-Size_Regularized_Cut_for_Data_Clustering.html">177 nips-2005-Size Regularized Cut for Data Clustering</a></p>
<p>7 0.3680602 <a title="120-lda-7" href="./nips-2005-Variable_KD-Tree_Algorithms_for_Spatial_Pattern_Search_and_Discovery.html">200 nips-2005-Variable KD-Tree Algorithms for Spatial Pattern Search and Discovery</a></p>
<p>8 0.36783373 <a title="120-lda-8" href="./nips-2005-Online_Discovery_and_Learning_of_Predictive_State_Representations.html">148 nips-2005-Online Discovery and Learning of Predictive State Representations</a></p>
<p>9 0.36735117 <a title="120-lda-9" href="./nips-2005-A_General_and_Efficient_Multiple_Kernel_Learning_Algorithm.html">10 nips-2005-A General and Efficient Multiple Kernel Learning Algorithm</a></p>
<p>10 0.36691028 <a title="120-lda-10" href="./nips-2005-Extracting_Dynamical_Structure_Embedded_in_Neural_Activity.html">67 nips-2005-Extracting Dynamical Structure Embedded in Neural Activity</a></p>
<p>11 0.36643529 <a title="120-lda-11" href="./nips-2005-Off-policy_Learning_with_Options_and_Recognizers.html">144 nips-2005-Off-policy Learning with Options and Recognizers</a></p>
<p>12 0.36504167 <a title="120-lda-12" href="./nips-2005-A_Hierarchical_Compositional_System_for_Rapid_Object_Detection.html">11 nips-2005-A Hierarchical Compositional System for Rapid Object Detection</a></p>
<p>13 0.36425564 <a title="120-lda-13" href="./nips-2005-Bayesian_models_of_human_action_understanding.html">36 nips-2005-Bayesian models of human action understanding</a></p>
<p>14 0.36377597 <a title="120-lda-14" href="./nips-2005-Noise_and_the_two-thirds_power_Law.html">136 nips-2005-Noise and the two-thirds power Law</a></p>
<p>15 0.36363596 <a title="120-lda-15" href="./nips-2005-A_Computational_Model_of_Eye_Movements_during_Object_Class_Detection.html">5 nips-2005-A Computational Model of Eye Movements during Object Class Detection</a></p>
<p>16 0.36321795 <a title="120-lda-16" href="./nips-2005-Dynamic_Social_Network_Analysis_using_Latent_Space_Models.html">60 nips-2005-Dynamic Social Network Analysis using Latent Space Models</a></p>
<p>17 0.36265635 <a title="120-lda-17" href="./nips-2005-Multiple_Instance_Boosting_for_Object_Detection.html">131 nips-2005-Multiple Instance Boosting for Object Detection</a></p>
<p>18 0.36255252 <a title="120-lda-18" href="./nips-2005-Q-Clustering.html">159 nips-2005-Q-Clustering</a></p>
<p>19 0.3622629 <a title="120-lda-19" href="./nips-2005-Structured_Prediction_via_the_Extragradient_Method.html">184 nips-2005-Structured Prediction via the Extragradient Method</a></p>
<p>20 0.36224055 <a title="120-lda-20" href="./nips-2005-Mixture_Modeling_by_Affinity_Propagation.html">127 nips-2005-Mixture Modeling by Affinity Propagation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
