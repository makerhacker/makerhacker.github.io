<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2010" href="../home/hunch_net-2010_home.html">hunch_net-2010</a> <a title="hunch_net-2010-390" href="#">hunch_net-2010-390</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2010-390-html" href="http://hunch.net/?p=1250">html</a></p><p>Introduction: Thesecond Netflix prize is canceleddue toprivacy problems. I continue to
believe my original assessment of this paper, that the privacy break was
somewhat overstated. I still haven't seen any serious privacy failures on the
scale of theAOL search log release.I expect privacy concerns to continue to be
a big issue when dealing with data releases by companies or governments. The
theory of maintaining privacy while using data is improving, but it is not yet
in a state where the limits of what's possible are clear let alone how to
achieve these limits in a manner friendly to a prediction competition.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 I continue to believe my original assessment of this paper, that the privacy break was somewhat overstated. [sent-2, score-1.509]
</p><p>2 I still haven't seen any serious privacy failures on the scale of theAOL search log release. [sent-3, score-1.335]
</p><p>3 I expect privacy concerns to continue to be a big issue when dealing with data releases by companies or governments. [sent-4, score-1.619]
</p><p>4 The theory of maintaining privacy while using data is improving, but it is not yet in a state where the limits of what's possible are clear let alone how to achieve these limits in a manner friendly to a prediction competition. [sent-5, score-2.383]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('privacy', 0.578), ('continue', 0.265), ('limits', 0.26), ('thesecond', 0.209), ('assessment', 0.209), ('maintaining', 0.174), ('alone', 0.167), ('failures', 0.162), ('break', 0.148), ('netflix', 0.148), ('prize', 0.141), ('concerns', 0.135), ('companies', 0.133), ('competition', 0.133), ('dealing', 0.133), ('manner', 0.128), ('original', 0.128), ('improving', 0.126), ('search', 0.113), ('data', 0.112), ('log', 0.104), ('somewhat', 0.104), ('let', 0.103), ('issue', 0.103), ('serious', 0.103), ('scale', 0.098), ('state', 0.098), ('achieve', 0.097), ('seen', 0.09), ('clear', 0.088), ('still', 0.087), ('expect', 0.081), ('big', 0.079), ('believe', 0.077), ('prediction', 0.068), ('yet', 0.067), ('possible', 0.065), ('theory', 0.064), ('paper', 0.055), ('using', 0.054)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="390-tfidf-1" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: Thesecond Netflix prize is canceleddue toprivacy problems. I continue to
believe my original assessment of this paper, that the privacy break was
somewhat overstated. I still haven't seen any serious privacy failures on the
scale of theAOL search log release.I expect privacy concerns to continue to be
a big issue when dealing with data releases by companies or governments. The
theory of maintaining privacy while using data is improving, but it is not yet
in a state where the limits of what's possible are clear let alone how to
achieve these limits in a manner friendly to a prediction competition.</p><p>2 0.28159538 <a title="390-tfidf-2" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>Introduction: Machine Learning is rising in importance because data is being collected for
all sorts of tasks where it either wasn't previously collected, or for tasks
that did not previously exist. While this is great for Machine Learning, it
has a downside--the massive data collection which is so useful can also lead
to substantial privacy problems.It's important to understand that this is a
much harder problem than many people appreciate. TheAOLdatareleaseis a good
example. To those doing machine learning, the following strategies might be
obvious:Just delete any names or other obviously personally identifiable
information. The logic here seems to be "if I can't easily find the person
then no one can". That doesn't work as demonstrated by the people who were
found circumstantially from the AOL data.… then just hash all the search
terms! The logic here is "if I can't read it, then no one can". It's also
trivially broken by a dictionary attack--just hash all the strings that might
be in the data an</p><p>3 0.16620427 <a title="390-tfidf-3" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>Introduction: I want to comment on the "Bing copies Google" discussionhere,here, andhere,
because there are data-related issues which the general public may not
understand, and some of the framing seems substantially misleading to me.As a
not-distant-outsider, let me mention the sources of bias I may have. I work
atYahoo!, which has started usingBing. This might predispose me towards Bing,
but on the other hand I'm still at Yahoo!, and have been usingLinuxexclusively
as an OS for many years, including even a couple minor kernel patches. And,on
the gripping hand, I've spent quite a bit of time thinking about the
basicprinciples of incorporating user feedback in machine learning. Also note,
this post is not related to official Yahoo! policy, it's just my personal
view.The issueGoogle engineers inserted synthetic responses to synthetic
queries on google.com, then executed the synthetic searches on google.com
using Internet Explorer with the Bing toolbar and later noticed some synthetic
responses from B</p><p>4 0.15865126 <a title="390-tfidf-4" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>Introduction: I attendedKDDthis year. The conference has always had a strong grounding in
what works based on theKDDcup, but it has developed a halo of workshops on
various subjects. It seems that KDD has become a place where the economy meets
machine learning in a stronger sense than many other conferences.There were
several papers that other people might like to take a look at.Yehuda
KorenCollaborative Filtering with Temporal Dynamics. This paper describes how
to incorporate temporal dynamics into a couple of collaborative filtering
approaches. This was also a best paper award.D. Sculley, Robert Malkin,Sugato
Basu,Roberto J. Bayardo,Predicting Bounce Rates in Sponsored Search
Advertisements. The basic claim of this paper is that the probability people
immediately leave ("bounce") after clicking on an advertisement is
predictable.Frank McSherryandIlya MironovDifferentially Private Recommender
Systems: Building Privacy into the Netflix Prize Contenders. The basic claim
here is that it is possible to</p><p>5 0.12109441 <a title="390-tfidf-5" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>Introduction: There were several papers that seemed fairly interesting atKDD this year. The
ones that caught my attention are:Xin Jin, Mingyang Zhang,Nan Zhang, andGautam
Das,Versatile Publishing For Privacy Preservation. This paper provides a
conservative method for safely determining which data is publishable from any
complete source of information (for example, a hospital) such that it does not
violate privacy rules in a natural language. It is not differentially private,
so no external sources of join information can exist. However, it is a
mechanism forpublishingdata rather than (say) the output of a learning
algorithm.Arik FriedmanAssaf Schuster,Data Mining with Differential Privacy.
This paper shows how to create effective differentially private decision
trees. Progress in differentially private datamining is pretty impressive, as
it wasdefined in 2006.David Chan, Rong Ge, Ori Gershony,Tim Hesterberg,Diane
Lambert,Evaluating Online Ad Campaigns in a Pipeline: Causal Models At
ScaleThis paper</p><p>6 0.091143481 <a title="390-tfidf-6" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>7 0.087357096 <a title="390-tfidf-7" href="../hunch_net-2006/hunch_net-2006-04-05-What_is_state%3F.html">169 hunch net-2006-04-05-What is state?</a></p>
<p>8 0.081750304 <a title="390-tfidf-8" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>9 0.079210669 <a title="390-tfidf-9" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>10 0.078600615 <a title="390-tfidf-10" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>11 0.078353092 <a title="390-tfidf-11" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>12 0.075807206 <a title="390-tfidf-12" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>13 0.072218314 <a title="390-tfidf-13" href="../hunch_net-2010/hunch_net-2010-02-26-Yahoo%21_ML_events.html">389 hunch net-2010-02-26-Yahoo! ML events</a></p>
<p>14 0.069762126 <a title="390-tfidf-14" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>15 0.068761259 <a title="390-tfidf-15" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>16 0.067992672 <a title="390-tfidf-16" href="../hunch_net-2007/hunch_net-2007-04-18-%2450K_Spock_Challenge.html">239 hunch net-2007-04-18-$50K Spock Challenge</a></p>
<p>17 0.067843199 <a title="390-tfidf-17" href="../hunch_net-2005/hunch_net-2005-06-28-The_cross_validation_problem%3A_cash_reward.html">86 hunch net-2005-06-28-The cross validation problem: cash reward</a></p>
<p>18 0.065524377 <a title="390-tfidf-18" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>19 0.06493926 <a title="390-tfidf-19" href="../hunch_net-2008/hunch_net-2008-04-30-Concerns_about_the_Large_Scale_Learning_Challenge.html">300 hunch net-2008-04-30-Concerns about the Large Scale Learning Challenge</a></p>
<p>20 0.064505182 <a title="390-tfidf-20" href="../hunch_net-2012/hunch_net-2012-05-03-Microsoft_Research%2C_New_York_City.html">464 hunch net-2012-05-03-Microsoft Research, New York City</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.114), (1, -0.009), (2, 0.02), (3, -0.005), (4, 0.008), (5, 0.087), (6, -0.007), (7, 0.011), (8, 0.127), (9, -0.047), (10, -0.191), (11, 0.085), (12, -0.034), (13, 0.076), (14, 0.141), (15, -0.005), (16, -0.008), (17, 0.036), (18, -0.046), (19, -0.035), (20, -0.085), (21, -0.07), (22, -0.079), (23, -0.13), (24, -0.063), (25, 0.003), (26, 0.021), (27, 0.109), (28, 0.11), (29, 0.073), (30, -0.138), (31, -0.074), (32, 0.005), (33, -0.009), (34, -0.045), (35, -0.109), (36, -0.07), (37, 0.007), (38, -0.01), (39, -0.009), (40, 0.08), (41, 0.008), (42, -0.037), (43, 0.056), (44, -0.099), (45, -0.003), (46, 0.041), (47, -0.046), (48, 0.077), (49, -0.089)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.9895404 <a title="390-lsi-1" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: Thesecond Netflix prize is canceleddue toprivacy problems. I continue to
believe my original assessment of this paper, that the privacy break was
somewhat overstated. I still haven't seen any serious privacy failures on the
scale of theAOL search log release.I expect privacy concerns to continue to be
a big issue when dealing with data releases by companies or governments. The
theory of maintaining privacy while using data is improving, but it is not yet
in a state where the limits of what's possible are clear let alone how to
achieve these limits in a manner friendly to a prediction competition.</p><p>2 0.68595403 <a title="390-lsi-2" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>Introduction: Machine Learning is rising in importance because data is being collected for
all sorts of tasks where it either wasn't previously collected, or for tasks
that did not previously exist. While this is great for Machine Learning, it
has a downside--the massive data collection which is so useful can also lead
to substantial privacy problems.It's important to understand that this is a
much harder problem than many people appreciate. TheAOLdatareleaseis a good
example. To those doing machine learning, the following strategies might be
obvious:Just delete any names or other obviously personally identifiable
information. The logic here seems to be "if I can't easily find the person
then no one can". That doesn't work as demonstrated by the people who were
found circumstantially from the AOL data.… then just hash all the search
terms! The logic here is "if I can't read it, then no one can". It's also
trivially broken by a dictionary attack--just hash all the strings that might
be in the data an</p><p>3 0.62551045 <a title="390-lsi-3" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<p>Introduction: I want to comment on the "Bing copies Google" discussionhere,here, andhere,
because there are data-related issues which the general public may not
understand, and some of the framing seems substantially misleading to me.As a
not-distant-outsider, let me mention the sources of bias I may have. I work
atYahoo!, which has started usingBing. This might predispose me towards Bing,
but on the other hand I'm still at Yahoo!, and have been usingLinuxexclusively
as an OS for many years, including even a couple minor kernel patches. And,on
the gripping hand, I've spent quite a bit of time thinking about the
basicprinciples of incorporating user feedback in machine learning. Also note,
this post is not related to official Yahoo! policy, it's just my personal
view.The issueGoogle engineers inserted synthetic responses to synthetic
queries on google.com, then executed the synthetic searches on google.com
using Internet Explorer with the Bing toolbar and later noticed some synthetic
responses from B</p><p>4 0.60684031 <a title="390-lsi-4" href="../hunch_net-2009/hunch_net-2009-07-11-Interesting_papers_at_KDD.html">364 hunch net-2009-07-11-Interesting papers at KDD</a></p>
<p>Introduction: I attendedKDDthis year. The conference has always had a strong grounding in
what works based on theKDDcup, but it has developed a halo of workshops on
various subjects. It seems that KDD has become a place where the economy meets
machine learning in a stronger sense than many other conferences.There were
several papers that other people might like to take a look at.Yehuda
KorenCollaborative Filtering with Temporal Dynamics. This paper describes how
to incorporate temporal dynamics into a couple of collaborative filtering
approaches. This was also a best paper award.D. Sculley, Robert Malkin,Sugato
Basu,Roberto J. Bayardo,Predicting Bounce Rates in Sponsored Search
Advertisements. The basic claim of this paper is that the probability people
immediately leave ("bounce") after clicking on an advertisement is
predictable.Frank McSherryandIlya MironovDifferentially Private Recommender
Systems: Building Privacy into the Netflix Prize Contenders. The basic claim
here is that it is possible to</p><p>5 0.5670504 <a title="390-lsi-5" href="../hunch_net-2006/hunch_net-2006-08-03-AOL%26%238217%3Bs_data_drop.html">200 hunch net-2006-08-03-AOL&#8217;s data drop</a></p>
<p>Introduction: AOL hasreleasedseveral large search engine related datasets. This looks like a
pretty impressive data release, and it is a big opportunity for people
everywhere to worry about search engine related learning problems, if they
want.</p><p>6 0.54735291 <a title="390-lsi-6" href="../hunch_net-2007/hunch_net-2007-11-29-The_Netflix_Crack.html">275 hunch net-2007-11-29-The Netflix Crack</a></p>
<p>7 0.49629462 <a title="390-lsi-7" href="../hunch_net-2005/hunch_net-2005-10-20-Machine_Learning_in_the_News.html">125 hunch net-2005-10-20-Machine Learning in the News</a></p>
<p>8 0.49611405 <a title="390-lsi-8" href="../hunch_net-2010/hunch_net-2010-08-24-Alex_Smola_starts_a_blog.html">408 hunch net-2010-08-24-Alex Smola starts a blog</a></p>
<p>9 0.46908313 <a title="390-lsi-9" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>10 0.46271297 <a title="390-lsi-10" href="../hunch_net-2011/hunch_net-2011-04-11-The_Heritage_Health_Prize.html">430 hunch net-2011-04-11-The Heritage Health Prize</a></p>
<p>11 0.42924359 <a title="390-lsi-11" href="../hunch_net-2009/hunch_net-2009-01-19-Netflix_prize_within_epsilon.html">336 hunch net-2009-01-19-Netflix prize within epsilon</a></p>
<p>12 0.41568986 <a title="390-lsi-12" href="../hunch_net-2006/hunch_net-2006-02-11-Yahoo%26%238217%3Bs_Learning_Problems..html">156 hunch net-2006-02-11-Yahoo&#8217;s Learning Problems.</a></p>
<p>13 0.40289435 <a title="390-lsi-13" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>14 0.40230027 <a title="390-lsi-14" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>15 0.38985091 <a title="390-lsi-15" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>16 0.36244881 <a title="390-lsi-16" href="../hunch_net-2009/hunch_net-2009-09-21-Netflix_finishes_%28and_starts%29.html">371 hunch net-2009-09-21-Netflix finishes (and starts)</a></p>
<p>17 0.35651225 <a title="390-lsi-17" href="../hunch_net-2006/hunch_net-2006-02-07-Pittsburgh_Mind_Reading_Competition.html">155 hunch net-2006-02-07-Pittsburgh Mind Reading Competition</a></p>
<p>18 0.3550691 <a title="390-lsi-18" href="../hunch_net-2007/hunch_net-2007-10-19-Second_Annual_Reinforcement_Learning_Competition.html">268 hunch net-2007-10-19-Second Annual Reinforcement Learning Competition</a></p>
<p>19 0.34842211 <a title="390-lsi-19" href="../hunch_net-2011/hunch_net-2011-09-07-KDD_and_MUCMD_2011.html">444 hunch net-2011-09-07-KDD and MUCMD 2011</a></p>
<p>20 0.34472498 <a title="390-lsi-20" href="../hunch_net-2007/hunch_net-2007-06-23-Machine_Learning_Jobs_are_Growing_on_Trees.html">250 hunch net-2007-06-23-Machine Learning Jobs are Growing on Trees</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(42, 0.154), (45, 0.6), (68, 0.034), (74, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97675663 <a title="390-lda-1" href="../hunch_net-2010/hunch_net-2010-03-12-Netflix_Challenge_2_Canceled.html">390 hunch net-2010-03-12-Netflix Challenge 2 Canceled</a></p>
<p>Introduction: Thesecond Netflix prize is canceleddue toprivacy problems. I continue to
believe my original assessment of this paper, that the privacy break was
somewhat overstated. I still haven't seen any serious privacy failures on the
scale of theAOL search log release.I expect privacy concerns to continue to be
a big issue when dealing with data releases by companies or governments. The
theory of maintaining privacy while using data is improving, but it is not yet
in a state where the limits of what's possible are clear let alone how to
achieve these limits in a manner friendly to a prediction competition.</p><p>2 0.97152567 <a title="390-lda-2" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>Introduction: I tweaked the site in a number of ways today, including:Updating
toWordPress1.5.Installing and heavily tweaking theGeeknichetheme. Update: I
switched back to a tweaked version of the old theme.Adding theCustomizable
Post Listingsplugin.Installing theStatTraqplugin.Updating some of the links. I
particularly recommend looking at thecomputer research
policyblog.Addingthreaded comments. This doesn't thread old comments
obviously, but the extra structure may be helpful for new ones.Overall, I
think this is an improvement, and it addresses a few of myearlier problems. If
you have any difficulties or anything seems "not quite right", please speak
up. A few other tweaks to the site may happen in the near future.</p><p>3 0.96618801 <a title="390-lda-3" href="../hunch_net-2010/hunch_net-2010-05-20-Google_Predict.html">399 hunch net-2010-05-20-Google Predict</a></p>
<p>Introduction: Slashdotpoints outGoogle Predict. I'm not privy to the details, but this has
the potential to be extremely useful, as in many applications simply having an
easy mechanism to apply existing learning algorithms can be extremely helpful.
This differs goalwise fromMLcomp--instead of public comparisons for research
purposes, it's about private utilization of good existing algorithms. It also
differs infrastructurally, since a system designed to do this is much less
awkward than using Amazon's cloud computing. The latter implies that datasets
several order of magnitude larger can be handled up to limits imposed by
network and storage.</p><p>4 0.93447 <a title="390-lda-4" href="../hunch_net-2010/hunch_net-2010-01-13-Sam_Roweis_died.html">386 hunch net-2010-01-13-Sam Roweis died</a></p>
<p>Introduction: and I can't help but remember him.I first metSamas an undergraduate
atCaltechwhere he was TA forHopfield's class, and again when I visitedGatsby,
when he invited me to visitToronto, and at too many conferences to recount.
His personality was a combination of enthusiastic and thoughtful, with a great
ability to phrase a problem so it's solution must be understood. With respect
to my own work, Sam was the one who advised me to makemy first tutorial,
leading to others, and to other things, all of which I'm grateful to him for.
In fact, my every interaction with Sam was positive, and that was his way.His
death isbeing called a suicidewhich is so incompatible with my understanding
of Sam that it strains my credibility. But we know that his many
responsibilities were great, and it is well understood that basically all sane
researchers have legions of inner doubts. Having been depressed now and then
myself, it's helpful to understand at least intellectually that the true
darkness of the now i</p><p>5 0.90757459 <a title="390-lda-5" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>Introduction: While everyone is silently working on ICML submissions, I found this
discussion about afast physics simulatorchip interesting from a learning
viewpoint. In many cases, learning attempts to predict the outcome of physical
processes. Access to a fast simulator for these processes might be quite
helpful in predicting the outcome. Bayesian learning in particular may
directly benefit while many other algorithms (like support vector machines)
might have their speed greatly increased.The biggest drawback is that writing
software for these odd architectures is always difficult and time consuming,
but a several-orders-of-magnitude speedup might make that worthwhile.</p><p>6 0.87094122 <a title="390-lda-6" href="../hunch_net-2005/hunch_net-2005-04-21-Dynamic_Programming_Generalizations_and_Their_Use.html">58 hunch net-2005-04-21-Dynamic Programming Generalizations and Their Use</a></p>
<p>7 0.86095631 <a title="390-lda-7" href="../hunch_net-2009/hunch_net-2009-03-18-Parallel_ML_primitives.html">346 hunch net-2009-03-18-Parallel ML primitives</a></p>
<p>8 0.81339037 <a title="390-lda-8" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>9 0.76571107 <a title="390-lda-9" href="../hunch_net-2009/hunch_net-2009-01-08-Predictive_Analytics_World.html">335 hunch net-2009-01-08-Predictive Analytics World</a></p>
<p>10 0.57457578 <a title="390-lda-10" href="../hunch_net-2007/hunch_net-2007-11-05-CMU_wins_DARPA_Urban_Challenge.html">271 hunch net-2007-11-05-CMU wins DARPA Urban Challenge</a></p>
<p>11 0.50121552 <a title="390-lda-11" href="../hunch_net-2011/hunch_net-2011-06-22-Ultra_LDA.html">436 hunch net-2011-06-22-Ultra LDA</a></p>
<p>12 0.49797595 <a title="390-lda-12" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>13 0.46911016 <a title="390-lda-13" href="../hunch_net-2007/hunch_net-2007-08-25-The_Privacy_Problem.html">260 hunch net-2007-08-25-The Privacy Problem</a></p>
<p>14 0.46559507 <a title="390-lda-14" href="../hunch_net-2007/hunch_net-2007-04-28-The_Coming_Patent_Apocalypse.html">241 hunch net-2007-04-28-The Coming Patent Apocalypse</a></p>
<p>15 0.46345311 <a title="390-lda-15" href="../hunch_net-2005/hunch_net-2005-06-18-Lower_Bounds_for_Learning_Reductions.html">83 hunch net-2005-06-18-Lower Bounds for Learning Reductions</a></p>
<p>16 0.45331764 <a title="390-lda-16" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>17 0.45226827 <a title="390-lda-17" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>18 0.45107806 <a title="390-lda-18" href="../hunch_net-2005/hunch_net-2005-12-07-Is_the_Google_way_the_way_for_machine_learning%3F.html">136 hunch net-2005-12-07-Is the Google way the way for machine learning?</a></p>
<p>19 0.44652089 <a title="390-lda-19" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>20 0.44341695 <a title="390-lda-20" href="../hunch_net-2011/hunch_net-2011-02-02-User_preferences_for_search_engines.html">423 hunch net-2011-02-02-User preferences for search engines</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
