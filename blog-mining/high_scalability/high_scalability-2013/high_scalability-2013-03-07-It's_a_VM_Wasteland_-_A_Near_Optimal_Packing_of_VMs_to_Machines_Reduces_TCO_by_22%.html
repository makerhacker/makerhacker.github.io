<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1419" href="#">high_scalability-2013-1419</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1419-html" href="http://highscalability.com//blog/2013/3/7/its-a-vm-wasteland-a-near-optimal-packing-of-vms-to-machines.html">html</a></p><p>Introduction: In Algorithm Design for Performance Aware VM Consolidation we learn some
shocking facts (gambling in Casablanca?):Average server utilization in many
data centers is low, estimated between 5% and 15%. This is wasteful because an
idle server often consumes more than 50% of peak power.Surely that's just for
old style datacenters? Nope. In Google data centers, workloads that are
consolidated use only 50% of the processor cores. Every other processor core
is left unused simply to ensure that performance does not degrade.It's a VM
wasteland. The goal is to reduce waste by packing VMs onto machines without
hurting performance or wasting resources. The idea is to select VMs that
interfere the least with each other and places them together on the same
server.It's a NP-Complete problem, but this paper describes a practical method
that performs provably close to the optimal. Interestingly they can optimize
for performance or power efficiency, so you can use different algorithms for
different work</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 In Algorithm Design for Performance Aware VM Consolidation we learn some shocking facts (gambling in Casablanca? [sent-1, score-0.247]
</p><p>2 ):Average server utilization in many data centers is low, estimated between 5% and 15%. [sent-2, score-0.411]
</p><p>3 This is wasteful because an idle server often consumes more than 50% of peak power. [sent-3, score-0.356]
</p><p>4 In Google data centers, workloads that are consolidated use only 50% of the processor cores. [sent-6, score-0.373]
</p><p>5 Every other processor core is left unused simply to ensure that performance does not degrade. [sent-7, score-0.46]
</p><p>6 The goal is to reduce waste by packing VMs onto machines without hurting performance or wasting resources. [sent-9, score-0.698]
</p><p>7 The idea is to select VMs that interfere the least with each other and places them together on the same server. [sent-10, score-0.225]
</p><p>8 It's a NP-Complete problem, but this paper describes a practical method that performs provably close to the optimal. [sent-11, score-0.391]
</p><p>9 Interestingly they can optimize for performance or power efficiency, so you can use different algorithms for different workloads. [sent-12, score-0.116]
</p><p>10 The result when optimizing for performance are utilizations between 75% and 80% compared to 50% from the na覺ve method. [sent-13, score-0.364]
</p><p>11 This gives a 22% reduction in TCO, a significant savings at scale:Experimental evaluations showed  that the proposed system performed well on realistic VM performance degradations, yielding over 30% savings in energy and up to 52% reduction in degradation. [sent-14, score-1.538]
</p><p>12 It's hard to get greater utilization from VMs because systems are structured in such large chunks. [sent-15, score-0.165]
</p><p>13 If we could decompose systems into smaller more modular pieces they could be much more efficiently scheduled over a server farm. [sent-16, score-0.404]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('vms', 0.284), ('vm', 0.255), ('reduction', 0.186), ('savings', 0.18), ('utilizations', 0.168), ('utilization', 0.165), ('evaluations', 0.157), ('gambling', 0.157), ('hurting', 0.15), ('processor', 0.149), ('provably', 0.145), ('packing', 0.145), ('shocking', 0.14), ('consolidated', 0.14), ('interfere', 0.14), ('yielding', 0.136), ('ve', 0.136), ('centers', 0.136), ('decompose', 0.13), ('tco', 0.13), ('wasteful', 0.13), ('na', 0.125), ('consumes', 0.125), ('consolidation', 0.119), ('wasting', 0.116), ('performance', 0.116), ('proposed', 0.114), ('unused', 0.113), ('interestingly', 0.111), ('realistic', 0.111), ('estimated', 0.11), ('facts', 0.107), ('experimental', 0.104), ('modular', 0.102), ('idle', 0.101), ('showed', 0.094), ('scheduled', 0.091), ('waste', 0.089), ('performs', 0.086), ('aware', 0.085), ('places', 0.085), ('workloads', 0.084), ('onto', 0.082), ('left', 0.082), ('pieces', 0.081), ('optimizing', 0.08), ('describes', 0.08), ('method', 0.08), ('efficiency', 0.078), ('performed', 0.078)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1419-tfidf-1" href="../high_scalability-2013/high_scalability-2013-03-07-It%27s_a_VM_Wasteland_-_A_Near_Optimal_Packing_of_VMs_to_Machines_Reduces_TCO_by_22%25.html">1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</a></p>
<p>Introduction: In Algorithm Design for Performance Aware VM Consolidation we learn some
shocking facts (gambling in Casablanca?):Average server utilization in many
data centers is low, estimated between 5% and 15%. This is wasteful because an
idle server often consumes more than 50% of peak power.Surely that's just for
old style datacenters? Nope. In Google data centers, workloads that are
consolidated use only 50% of the processor cores. Every other processor core
is left unused simply to ensure that performance does not degrade.It's a VM
wasteland. The goal is to reduce waste by packing VMs onto machines without
hurting performance or wasting resources. The idea is to select VMs that
interfere the least with each other and places them together on the same
server.It's a NP-Complete problem, but this paper describes a practical method
that performs provably close to the optimal. Interestingly they can optimize
for performance or power efficiency, so you can use different algorithms for
different work</p><p>2 0.19172223 <a title="1419-tfidf-2" href="../high_scalability-2012/high_scalability-2012-05-03-Snooze_-_Open-source%2C_Scalable%2C_Autonomic%2C_and_Energy-efficient_VM_Management_for_Private_Clouds.html">1238 high scalability-2012-05-03-Snooze - Open-source, Scalable, Autonomic, and Energy-efficient VM Management for Private Clouds</a></p>
<p>Introduction: Snoozeis an open-source, scalable, autonomic, and energy-efficient virtual
machine (VM) management framework for private clouds. Similarly to other VM
management frameworks such as Nimbus, OpenNebula, Eucalyptus, and OpenStack it
allows to build compute infrastructures from virtualized resources.
Particularly, once installed and configured users can submit and control the
life-cycle of a large number of VMs. However, contrary to existing frameworks
for scalability and fault tolerance, Snooze employs a self-organizing and
healing (based on Apache ZooKeeper) hierarchical architecture. Moreover, it
performs distributed VM management and is designed to be energy efficient.
Therefore, it implements features to monitor and estimate VM resource (CPU,
memory, network Rx, network Tx) demands, detect and resolve overload/underload
situations, perform dynamic VM consolidation through live migration, and
finally power management to save energy. Last but not least, it integrates a
generic scheduler</p><p>3 0.17763831 <a title="1419-tfidf-3" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>Introduction: Update:How do you design and handle peak load on the Cloud?by Cloudiquity.
Gives a formula to try and predict and plan for peak load and talks about how
GigaSpaces XAP, Scalr, RightScale and FreedomOSS can be used to handle peak
load within EC2.Theo Schlossnagle, with his usual insight, talks about
inDissecting today's surgeshow the nature of internet traffic has evolved over
time. Traffic now spikes like a heart attack, larger and more quickly than
ever from traffic inflow sources like Digg and The New York Times. Theo
relates howAt least eight times in the past month, we've experienced from 100%
to 1000% sudden increases in traffic across many of our clientsand those spike
can happen as quickly as 60 seconds. To me this sounds a lot likePunctuated
equilibriumin evolution, a force that accounts for much creative growth in
species...breakVMs don't spin up in less than 60 seconds so your ability to
respond to such massive quick spikes is limited. This assumes of course that
you've creat</p><p>4 0.1313204 <a title="1419-tfidf-4" href="../high_scalability-2008/high_scalability-2008-07-10-Can_cloud_computing_smite_down_evil_zombie_botnet_armies%3F.html">349 high scalability-2008-07-10-Can cloud computing smite down evil zombie botnet armies?</a></p>
<p>Introduction: In the more cool stuff I've never heard of before department is something
calledSelf Cleansing Intrusion Tolerance(SCIT).Botnetsare created when
vulnerable computers live long enough to become infected with the will to do
the evil bidding of their evil masters. Security is almost always about
removing vulnerabilities (a process which to outside observers often looks
like adog chasing its tail). SCIT takes a different approach, it works on the
availability angle. Something I never thought of before, but which makes a
great deal of sense once I thought about it.With SCIT you stop and restart VM
instances every minute (or whatever depending in your desired window
vulnerability)....breakThis short exposure window means worms and viri do not
have long enough to fully infect a machine and carry out a coordinated attack.
A machine is up for a while. Does work. And then is torn down again only to be
reborn as a clean VM with no possibility of infection (unless of course the VM
mechanisms becom</p><p>5 0.12619856 <a title="1419-tfidf-5" href="../high_scalability-2008/high_scalability-2008-04-07-Rumors_of_Signs_and_Portents_Concerning_Freeish_Google_Cloud.html">299 high scalability-2008-04-07-Rumors of Signs and Portents Concerning Freeish Google Cloud</a></p>
<p>Introduction: Update 2: Rumor no more.Google Jumps Head First Into Web Services With Google
App Engine. The quick and dirty of it: developers simply upload their Python
code to Google, launch the application, and can monitor usage and other
metrics via a multi-platform desktop application. There were 10,000 developer
slots open and of course I was too late. More as the cobra strikes.Update:
TechCrunch reportsGoogle To Launch BigTable As Web Servicenext week. It
competes with Amazon's SimpleDB. Though it won't be truly comparable until
they also release an EC2 and S3 equivalent. An internet hit for each data
access is a little painful. As Jimmy says in Goodfellas, "That's the way. You
don't take no sh*t from nobody. "FirstDave Winerhallucinates a pig on the mean
streets of Walnut Creek that told him Google's long foretold cloud offering
will be free for bloggers of "modest needs." GigaOM then says a free cloud
service is how Google could eatAmazon's bacon for lunch.The reason for this
free cloud buff</p><p>6 0.12399238 <a title="1419-tfidf-6" href="../high_scalability-2007/high_scalability-2007-11-09-Paper%3A_Container-based_Operating_System_Virtualization%3A_A_Scalable%2C_High-performance_Alternative_to_Hypervisors.html">147 high scalability-2007-11-09-Paper: Container-based Operating System Virtualization: A Scalable, High-performance Alternative to Hypervisors</a></p>
<p>7 0.12319579 <a title="1419-tfidf-7" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>8 0.094577529 <a title="1419-tfidf-8" href="../high_scalability-2013/high_scalability-2013-10-25-Stuff_The_Internet_Says_On_Scalability_For_October_25th%2C_2013.html">1537 high scalability-2013-10-25-Stuff The Internet Says On Scalability For October 25th, 2013</a></p>
<p>9 0.093814977 <a title="1419-tfidf-9" href="../high_scalability-2008/high_scalability-2008-12-01-Web_Consolidation_on_the_Sun_Fire_T1000_using_Solaris_Containers__.html">458 high scalability-2008-12-01-Web Consolidation on the Sun Fire T1000 using Solaris Containers  </a></p>
<p>10 0.092936426 <a title="1419-tfidf-10" href="../high_scalability-2012/high_scalability-2012-03-14-The_Azure_Outage%3A_Time_Is_a_SPOF%2C_Leap_Day_Doubly_So.html">1209 high scalability-2012-03-14-The Azure Outage: Time Is a SPOF, Leap Day Doubly So</a></p>
<p>11 0.090968043 <a title="1419-tfidf-11" href="../high_scalability-2011/high_scalability-2011-03-17-Are_long_VM_instance_spin-up_times_in_the_cloud_costing_you_money%3F.html">1006 high scalability-2011-03-17-Are long VM instance spin-up times in the cloud costing you money?</a></p>
<p>12 0.090432681 <a title="1419-tfidf-12" href="../high_scalability-2011/high_scalability-2011-04-14-Strategy%3A_Cache_Application_Start_State_to_Reduce_Spin-up_Times.html">1023 high scalability-2011-04-14-Strategy: Cache Application Start State to Reduce Spin-up Times</a></p>
<p>13 0.082669497 <a title="1419-tfidf-13" href="../high_scalability-2012/high_scalability-2012-08-16-Paper%3A_A_Provably_Correct_Scalable_Concurrent_Skip_List.html">1305 high scalability-2012-08-16-Paper: A Provably Correct Scalable Concurrent Skip List</a></p>
<p>14 0.080741629 <a title="1419-tfidf-14" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<p>15 0.080074891 <a title="1419-tfidf-15" href="../high_scalability-2010/high_scalability-2010-10-21-Machine_VM_%2B_Cloud_API_-_Rewriting_the_Cloud_from_Scratch.html">923 high scalability-2010-10-21-Machine VM + Cloud API - Rewriting the Cloud from Scratch</a></p>
<p>16 0.078611463 <a title="1419-tfidf-16" href="../high_scalability-2010/high_scalability-2010-09-16-Strategy%3A_Buy_New%2C_Don%27t_Fix_the_Old.html">902 high scalability-2010-09-16-Strategy: Buy New, Don't Fix the Old</a></p>
<p>17 0.077706486 <a title="1419-tfidf-17" href="../high_scalability-2013/high_scalability-2013-02-11-At_Scale_Even_Little_Wins_Pay_Off_Big_-_Google_and_Facebook_Examples.html">1404 high scalability-2013-02-11-At Scale Even Little Wins Pay Off Big - Google and Facebook Examples</a></p>
<p>18 0.077092804 <a title="1419-tfidf-18" href="../high_scalability-2008/high_scalability-2008-09-22-Paper%3A_On_Delivering_Embarrassingly_Distributed_Cloud_Services.html">387 high scalability-2008-09-22-Paper: On Delivering Embarrassingly Distributed Cloud Services</a></p>
<p>19 0.077050999 <a title="1419-tfidf-19" href="../high_scalability-2010/high_scalability-2010-05-10-Sify.com_Architecture_-_A_Portal_at_3900_Requests_Per_Second.html">825 high scalability-2010-05-10-Sify.com Architecture - A Portal at 3900 Requests Per Second</a></p>
<p>20 0.07557153 <a title="1419-tfidf-20" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.112), (1, 0.055), (2, 0.014), (3, 0.029), (4, -0.056), (5, 0.007), (6, 0.037), (7, 0.04), (8, -0.042), (9, 0.021), (10, -0.019), (11, -0.042), (12, 0.014), (13, 0.0), (14, 0.013), (15, -0.004), (16, 0.012), (17, -0.003), (18, 0.023), (19, 0.002), (20, 0.023), (21, -0.006), (22, -0.018), (23, -0.058), (24, -0.017), (25, 0.048), (26, -0.049), (27, -0.022), (28, -0.021), (29, 0.006), (30, -0.003), (31, -0.006), (32, -0.019), (33, 0.054), (34, -0.017), (35, 0.036), (36, 0.007), (37, 0.04), (38, -0.002), (39, 0.047), (40, -0.018), (41, 0.006), (42, 0.006), (43, -0.006), (44, -0.025), (45, -0.013), (46, -0.027), (47, 0.001), (48, 0.079), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92576241 <a title="1419-lsi-1" href="../high_scalability-2013/high_scalability-2013-03-07-It%27s_a_VM_Wasteland_-_A_Near_Optimal_Packing_of_VMs_to_Machines_Reduces_TCO_by_22%25.html">1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</a></p>
<p>Introduction: In Algorithm Design for Performance Aware VM Consolidation we learn some
shocking facts (gambling in Casablanca?):Average server utilization in many
data centers is low, estimated between 5% and 15%. This is wasteful because an
idle server often consumes more than 50% of peak power.Surely that's just for
old style datacenters? Nope. In Google data centers, workloads that are
consolidated use only 50% of the processor cores. Every other processor core
is left unused simply to ensure that performance does not degrade.It's a VM
wasteland. The goal is to reduce waste by packing VMs onto machines without
hurting performance or wasting resources. The idea is to select VMs that
interfere the least with each other and places them together on the same
server.It's a NP-Complete problem, but this paper describes a practical method
that performs provably close to the optimal. Interestingly they can optimize
for performance or power efficiency, so you can use different algorithms for
different work</p><p>2 0.74140424 <a title="1419-lsi-2" href="../high_scalability-2011/high_scalability-2011-05-12-Paper%3A_Mind_the_Gap%3A_Reconnecting_Architecture_and_OS_Research.html">1039 high scalability-2011-05-12-Paper: Mind the Gap: Reconnecting Architecture and OS Research</a></p>
<p>Introduction: Mind the Gap: Reconnecting Architecture and OS Research is a paper presented
atHotOS XIII, the place where researchers talk about making potential futures
happen. For a great overview of the conference take a look at this article by
Matt Welsh: Conference report: HotOS 2011 in Napa.In the VM/cloud age I
question the need of having an OS at all, programs can compile directly
against "raw" hardware, but the paper does a good job of trying to figure out
the new roll operating systems can play in the future. We've been in a long OS
holding pattern, so long that we've seen the rise of PaaS vendors skipping the
OS level abstraction completely, but there's room for a middle ground between
legacy time sharing systems of the past and service level APIs that are but
one possible future.Introduction:For too long, operating systems researchers
and developers have pretty much taken whatever computer architects have dished
out. With occasional exceptions (e.g., virtualization support), architecture</p><p>3 0.71214318 <a title="1419-lsi-3" href="../high_scalability-2012/high_scalability-2012-05-03-Snooze_-_Open-source%2C_Scalable%2C_Autonomic%2C_and_Energy-efficient_VM_Management_for_Private_Clouds.html">1238 high scalability-2012-05-03-Snooze - Open-source, Scalable, Autonomic, and Energy-efficient VM Management for Private Clouds</a></p>
<p>Introduction: Snoozeis an open-source, scalable, autonomic, and energy-efficient virtual
machine (VM) management framework for private clouds. Similarly to other VM
management frameworks such as Nimbus, OpenNebula, Eucalyptus, and OpenStack it
allows to build compute infrastructures from virtualized resources.
Particularly, once installed and configured users can submit and control the
life-cycle of a large number of VMs. However, contrary to existing frameworks
for scalability and fault tolerance, Snooze employs a self-organizing and
healing (based on Apache ZooKeeper) hierarchical architecture. Moreover, it
performs distributed VM management and is designed to be energy efficient.
Therefore, it implements features to monitor and estimate VM resource (CPU,
memory, network Rx, network Tx) demands, detect and resolve overload/underload
situations, perform dynamic VM consolidation through live migration, and
finally power management to save energy. Last but not least, it integrates a
generic scheduler</p><p>4 0.69896442 <a title="1419-lsi-4" href="../high_scalability-2014/high_scalability-2014-02-12-Paper%3A_Network_Stack_Specialization_for_Performance_.html">1594 high scalability-2014-02-12-Paper: Network Stack Specialization for Performance </a></p>
<p>Introduction: In the scalability is specialization department here is an interesting paper
presented atHotNets '13on high performance networking: Network Stack
Specialization for Performance.The idea is generalizing a service so it fits
in the kernel comes at a high performance cost. So move TCP into user space.
The result is a web server with ~3.5x the throughput of Nginx "while
experiencing low CPU utilization, linear scaling on multicore systems, and
saturating current NIC hardware."Here's a good description of the paper
publishedon Layer 9:Traditionally, servers and OSes have been built to be
general purpose. However now we have a high degree of specialization. In fact,
in a big web service, you might have thousands of machines dedicated to one
function. Therefore, there's scope for specialization. This paper looks at a
specific opportunity in that space. Network stacks today are good for high
throughput with large transfers, but not small files (which are common in web
browsing). For example on</p><p>5 0.6933614 <a title="1419-lsi-5" href="../high_scalability-2012/high_scalability-2012-07-02-C_is_for_Compute_-_Google_Compute_Engine_%28GCE%29.html">1275 high scalability-2012-07-02-C is for Compute - Google Compute Engine (GCE)</a></p>
<p>Introduction: After poking around theGoogle Compute Engine(GCE) documentation I had some
trouble creating a mental model of how GCE works. Is it like AWS, GAE,
Rackspace, just what is it? After watchingGoogle I/O 2012 - Introducing Google
Compute EngineandGoogle Compute Engine -- Technical Details, it turns out my
initial impression, that GCE is disarmingly straightforward, turns out to be
the point.The focus of GCE is on the C, which stands for Compute, and that's
what GCE is all about: deploying lots of servers to solve computationally hard
problems. What you get with GCE is a Super Datacenter on Google Steroids.If
you are wondering how you will run the next Instagram on GCE then that would
be missing the point. GAE is targeted at applications. GCE is targeted
at:Delivering a proven, pure, high performance, high scale compute
infrastructure using a utility pricing model, on top of an open, secure,
extensible Infrastructure-as-a-Service.Delivering an experience that feels
like you are in a datacent</p><p>6 0.6913439 <a title="1419-lsi-6" href="../high_scalability-2012/high_scalability-2012-03-22-Paper%3A_Revisiting_Network_I-O_APIs%3A_The_netmap_Framework.html">1213 high scalability-2012-03-22-Paper: Revisiting Network I-O APIs: The netmap Framework</a></p>
<p>7 0.68517685 <a title="1419-lsi-7" href="../high_scalability-2012/high_scalability-2012-01-19-Is_it_time_to_get_rid_of_the_Linux_OS_model_in_the_cloud%3F.html">1177 high scalability-2012-01-19-Is it time to get rid of the Linux OS model in the cloud?</a></p>
<p>8 0.67949533 <a title="1419-lsi-8" href="../high_scalability-2007/high_scalability-2007-11-09-Paper%3A_Container-based_Operating_System_Virtualization%3A_A_Scalable%2C_High-performance_Alternative_to_Hypervisors.html">147 high scalability-2007-11-09-Paper: Container-based Operating System Virtualization: A Scalable, High-performance Alternative to Hypervisors</a></p>
<p>9 0.66004336 <a title="1419-lsi-9" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>10 0.65826523 <a title="1419-lsi-10" href="../high_scalability-2012/high_scalability-2012-04-26-Akaros_-_an_open_source_operating_system_for_manycore_architectures.html">1234 high scalability-2012-04-26-Akaros - an open source operating system for manycore architectures</a></p>
<p>11 0.63762569 <a title="1419-lsi-11" href="../high_scalability-2011/high_scalability-2011-09-15-Paper%3A_It%27s_Time_for_Low_Latency_-_Inventing_the_1_Microsecond_Datacenter.html">1116 high scalability-2011-09-15-Paper: It's Time for Low Latency - Inventing the 1 Microsecond Datacenter</a></p>
<p>12 0.6329447 <a title="1419-lsi-12" href="../high_scalability-2013/high_scalability-2013-08-22-The_Datacenter_as_a_Computer%3A_An_Introduction_to_the_Design_of_Warehouse-Scale_Machines%2C_Second_edition.html">1505 high scalability-2013-08-22-The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines, Second edition</a></p>
<p>13 0.61824536 <a title="1419-lsi-13" href="../high_scalability-2009/high_scalability-2009-03-12-Paper%3A_Understanding_and_Designing_New_Server_Architectures_for_Emerging_Warehouse-Computing_Environments.html">535 high scalability-2009-03-12-Paper: Understanding and Designing New Server Architectures for Emerging Warehouse-Computing Environments</a></p>
<p>14 0.61676347 <a title="1419-lsi-14" href="../high_scalability-2011/high_scalability-2011-08-29-The_Three_Ages_of_Google_-_Batch%2C_Warehouse%2C_Instant.html">1107 high scalability-2011-08-29-The Three Ages of Google - Batch, Warehouse, Instant</a></p>
<p>15 0.61669862 <a title="1419-lsi-15" href="../high_scalability-2013/high_scalability-2013-10-30-Strategy%3A_Use_Your_Quantum_Computer_Lab_to_Tell_Intentional_Blinks_from_Involuntary_Blinks.html">1540 high scalability-2013-10-30-Strategy: Use Your Quantum Computer Lab to Tell Intentional Blinks from Involuntary Blinks</a></p>
<p>16 0.61536837 <a title="1419-lsi-16" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>17 0.61323667 <a title="1419-lsi-17" href="../high_scalability-2011/high_scalability-2011-02-10-Dispelling_the_New_SSL_Myth.html">987 high scalability-2011-02-10-Dispelling the New SSL Myth</a></p>
<p>18 0.61048907 <a title="1419-lsi-18" href="../high_scalability-2013/high_scalability-2013-10-25-Stuff_The_Internet_Says_On_Scalability_For_October_25th%2C_2013.html">1537 high scalability-2013-10-25-Stuff The Internet Says On Scalability For October 25th, 2013</a></p>
<p>19 0.60795337 <a title="1419-lsi-19" href="../high_scalability-2013/high_scalability-2013-04-08-NuoDB%27s_First_Experience%3A_Google_Compute_Engine_-_1.8_Million_Transactions_Per_Second.html">1437 high scalability-2013-04-08-NuoDB's First Experience: Google Compute Engine - 1.8 Million Transactions Per Second</a></p>
<p>20 0.60417539 <a title="1419-lsi-20" href="../high_scalability-2013/high_scalability-2013-03-22-Stuff_The_Internet_Says_On_Scalability_For_March_22%2C_2013.html">1428 high scalability-2013-03-22-Stuff The Internet Says On Scalability For March 22, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.065), (2, 0.191), (10, 0.035), (40, 0.428), (61, 0.056), (79, 0.101), (94, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.92335439 <a title="1419-lda-1" href="../high_scalability-2008/high_scalability-2008-10-05-Paper%3A_Scalability_Design_Patterns.html">402 high scalability-2008-10-05-Paper: Scalability Design Patterns</a></p>
<p>Introduction: I have introduced pattern languages in my earlier post onThe Pattern Bible for
Distributed Computing.Achieving highest possible scalability is a complex
combination of many factors. This PLoP 2007paperpresents a pattern language
that can be used to make a system highly scalable.The Scalability Pattern
Language introduced by Kanwardeep Singh Ahluwalia includes patterns
to:Introduce ScalabilityOptimize AlgorithmAdd HardwareAdd ParallelismAdd
Intra-Process ParallelismAdd Inter-Porcess ParallelismAdd Hybrid
ParallelismOptimize DecentralizationControl Shared ResourcesAutomate
Scalability</p><p>2 0.90115285 <a title="1419-lda-2" href="../high_scalability-2008/high_scalability-2008-06-02-Total_Cost_of_Ownership_for_different_web_development_frameworks.html">338 high scalability-2008-06-02-Total Cost of Ownership for different web development frameworks</a></p>
<p>Introduction: I would like to compile a comparison matrix on the total cost of ownership for
.Net, Java, Lamp & Rails. Where should I start? Has anyone seen or know of a
recent study on this subject?</p><p>same-blog 3 0.89014494 <a title="1419-lda-3" href="../high_scalability-2013/high_scalability-2013-03-07-It%27s_a_VM_Wasteland_-_A_Near_Optimal_Packing_of_VMs_to_Machines_Reduces_TCO_by_22%25.html">1419 high scalability-2013-03-07-It's a VM Wasteland - A Near Optimal Packing of VMs to Machines Reduces TCO by 22%</a></p>
<p>Introduction: In Algorithm Design for Performance Aware VM Consolidation we learn some
shocking facts (gambling in Casablanca?):Average server utilization in many
data centers is low, estimated between 5% and 15%. This is wasteful because an
idle server often consumes more than 50% of peak power.Surely that's just for
old style datacenters? Nope. In Google data centers, workloads that are
consolidated use only 50% of the processor cores. Every other processor core
is left unused simply to ensure that performance does not degrade.It's a VM
wasteland. The goal is to reduce waste by packing VMs onto machines without
hurting performance or wasting resources. The idea is to select VMs that
interfere the least with each other and places them together on the same
server.It's a NP-Complete problem, but this paper describes a practical method
that performs provably close to the optimal. Interestingly they can optimize
for performance or power efficiency, so you can use different algorithms for
different work</p><p>4 0.8577897 <a title="1419-lda-4" href="../high_scalability-2010/high_scalability-2010-07-17-Hot_Scalability_Links_for_July_17%2C_2010.html">860 high scalability-2010-07-17-Hot Scalability Links for July 17, 2010</a></p>
<p>Introduction: And by hot I also mean temperature. Summer has arrived. It's sizzling here in
Silicon Valley. Thank you air conditioning!Scale the web by appointing a
Crawler Czar? Tom Foremski has the idea thatGoogle should open up their
indexso sites wouldn't have to endure the constant pounding by ravenous
crawler bots. Don MacAskill of SmugMug estimates50% of our web server CPU
resourcesare spent serving crawlers. What a waste. How this would all work
with real-time feeds, paid  feeds (Twitter, movies, ...), etc. is unknown, but
does it make sense for all that money to be spent on extracting the same data
over and over again?Tweets of Gold:jamesurquhart:Key to applications is
architecture. Key for infrastructure supporting archs is configurability.
Configurability==features.tjake:  People who choose their datastore based oh
hearsay and not their own evaluation are doomed.b6n:No global lock ever goes
unpunished.MichaelSurtees:scalability, systems & process feed each other
right?jamesgolick: Stateme</p><p>5 0.84149069 <a title="1419-lda-5" href="../high_scalability-2013/high_scalability-2013-05-29-Amazon%3A_Creating_a_Customer_Utopia_One_Culture_Hack_at_a_Time.html">1466 high scalability-2013-05-29-Amazon: Creating a Customer Utopia One Culture Hack at a Time</a></p>
<p>Introduction: If you don't cannibalize yourself, someone else will. --Steve Jobs  America as
the New World has a long history of inspiring Utopian communities. Early
experiments were famously religious. But there have been many others as new
waves of thought have inspired people to organize and try something
different.In the 1840s Transcendentalists, believing the true path lay in the
perfection of the individual, created intentional communities likeBrook Farm.
We've also seensocialist, anarchist,hippy, and virtually every other kind of
Utopia in-between. Psychologist B.F. Skinner wrote an infamous book,Walden
Two, with a more "scientific" take on creating a Utopian community and Ayn
Rand inAtlas Shrugged had her free market version.I believe in startup
organizations we see the modern version of Utopian energy in action. We now
call it by names like "culture hacking", but the goal is the same: to create a
new form of human community to achieve a profound goal. You may think startups
are only about m</p><p>6 0.82724196 <a title="1419-lda-6" href="../high_scalability-2008/high_scalability-2008-05-27-Should_Twitter_be_an_All-You-Can-Eat_Buffet_or_a_Vending_Machine%3F.html">330 high scalability-2008-05-27-Should Twitter be an All-You-Can-Eat Buffet or a Vending Machine?</a></p>
<p>7 0.82281637 <a title="1419-lda-7" href="../high_scalability-2007/high_scalability-2007-07-25-Product%3A_3_PAR_REMOTE_COPY.html">27 high scalability-2007-07-25-Product: 3 PAR REMOTE COPY</a></p>
<p>8 0.81987697 <a title="1419-lda-8" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>9 0.81877649 <a title="1419-lda-9" href="../high_scalability-2009/high_scalability-2009-01-04-Alternative_Memcache_Usage%3A_A_Highly_Scalable%2C_Highly_Available%2C_In-Memory_Shard_Index.html">482 high scalability-2009-01-04-Alternative Memcache Usage: A Highly Scalable, Highly Available, In-Memory Shard Index</a></p>
<p>10 0.80483598 <a title="1419-lda-10" href="../high_scalability-2010/high_scalability-2010-02-15-The_Amazing_Collective_Compute_Power_of_the_Ambient_Cloud.html">778 high scalability-2010-02-15-The Amazing Collective Compute Power of the Ambient Cloud</a></p>
<p>11 0.75185174 <a title="1419-lda-11" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>12 0.74576825 <a title="1419-lda-12" href="../high_scalability-2013/high_scalability-2013-03-01-Stuff_The_Internet_Says_On_Scalability_For_February_29%2C_2013.html">1414 high scalability-2013-03-01-Stuff The Internet Says On Scalability For February 29, 2013</a></p>
<p>13 0.74491411 <a title="1419-lda-13" href="../high_scalability-2008/high_scalability-2008-03-17-Paper%3A_Consistent_Hashing_and_Random_Trees%3A_Distributed_Caching_Protocols_for_Relieving_Hot_Spots_on_the_World_Wide_Web.html">280 high scalability-2008-03-17-Paper: Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</a></p>
<p>14 0.74444407 <a title="1419-lda-14" href="../high_scalability-2010/high_scalability-2010-06-25-Hot_Scalability_Links_for_June_25%2C_2010.html">848 high scalability-2010-06-25-Hot Scalability Links for June 25, 2010</a></p>
<p>15 0.73064315 <a title="1419-lda-15" href="../high_scalability-2008/high_scalability-2008-04-07-Scalr_-_Open_Source_Auto-scaling_Hosting_on_Amazon_EC2.html">300 high scalability-2008-04-07-Scalr - Open Source Auto-scaling Hosting on Amazon EC2</a></p>
<p>16 0.71767163 <a title="1419-lda-16" href="../high_scalability-2010/high_scalability-2010-02-01-What_Will_Kill_the_Cloud%3F.html">768 high scalability-2010-02-01-What Will Kill the Cloud?</a></p>
<p>17 0.68706715 <a title="1419-lda-17" href="../high_scalability-2010/high_scalability-2010-01-04-11_Strategies_to_Rock_Your_Startup%E2%80%99s_Scalability_in_2010.html">757 high scalability-2010-01-04-11 Strategies to Rock Your Startup’s Scalability in 2010</a></p>
<p>18 0.68110192 <a title="1419-lda-18" href="../high_scalability-2013/high_scalability-2013-07-17-How_do_you_create_a_100th_Monkey_software_development_culture%3F.html">1492 high scalability-2013-07-17-How do you create a 100th Monkey software development culture?</a></p>
<p>19 0.64134479 <a title="1419-lda-19" href="../high_scalability-2007/high_scalability-2007-09-18-Session_management_in_highly_scalable_web_sites.html">97 high scalability-2007-09-18-Session management in highly scalable web sites</a></p>
<p>20 0.62308216 <a title="1419-lda-20" href="../high_scalability-2009/high_scalability-2009-04-10-counting_%23_of_views%2C_calculating_most-least_viewed.html">564 high scalability-2009-04-10-counting # of views, calculating most-least viewed</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
