<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2013" href="../home/high_scalability-2013_home.html">high_scalability-2013</a> <a title="high_scalability-2013-1551" href="#">high_scalability-2013-1551</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2013-1551-html" href="http://highscalability.com//blog/2013/11/20/how-twitter-improved-jvm-performance-by-reducing-gc-and-fast.html">html</a></p><p>Introduction: Nettyis a high-performance NIO(New IO) client server framework for Java that
Twitter uses internally as a protocol agonostic RPC system. Twitterfound some
problemswith Netty 3's memory management for buffer allocations beacause it
generated a lot of garbage during operation. When you send as many messages as
Twitter it creates a lot of GC pressure and the simple act of zero filling
newly allocated buffers consumed 50% of memory bandwidth. Netty 4 fixes this
situation with:Short-lived event objects, methods on long-lived channel
objects are used to handle I/O events.Secialized buffer allocator that uses
pool which implementsbuddy memory allocationandslab allocation.The result:5
times less frequent GC pauses: 45.5 vs. 9.2 times/min5 times less garbage
production: 207.11 vs 41.81 MiB/sThe buffer pool is much faster than JVM as
the size of the buffer increases. Some problems with smaller buffers.Given how
many services use the JVM in their messaging infrastructure and how many
services hav</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Nettyis a high-performance NIO(New IO) client server framework for Java that Twitter uses internally as a protocol agonostic RPC system. [sent-1, score-0.393]
</p><p>2 Twitterfound some problemswith Netty 3's memory management for buffer allocations beacause it generated a lot of garbage during operation. [sent-2, score-1.031]
</p><p>3 When you send as many messages as Twitter it creates a lot of GC pressure and the simple act of zero filling newly allocated buffers consumed 50% of memory bandwidth. [sent-3, score-1.415]
</p><p>4 Netty 4 fixes this situation with:Short-lived event objects, methods on long-lived channel objects are used to handle I/O events. [sent-4, score-0.569]
</p><p>5 Secialized buffer allocator that uses pool which implementsbuddy memory allocationandslab allocation. [sent-5, score-0.941]
</p><p>6 81 MiB/sThe buffer pool is much faster than JVM as the size of the buffer increases. [sent-11, score-0.991]
</p><p>7 Given how many services use the JVM in their messaging infrastructure and how many services have GC related performance problems, this is in impressive result others may want to consider. [sent-13, score-0.678]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('buffer', 0.412), ('gc', 0.358), ('netty', 0.299), ('garbage', 0.19), ('jvm', 0.184), ('pool', 0.167), ('allocations', 0.164), ('nio', 0.16), ('filling', 0.156), ('allocator', 0.156), ('pauses', 0.144), ('objects', 0.14), ('newly', 0.132), ('rpc', 0.125), ('consumed', 0.124), ('twitter', 0.122), ('buffers', 0.122), ('result', 0.118), ('fixes', 0.117), ('memory', 0.115), ('channel', 0.114), ('allocated', 0.112), ('zero', 0.111), ('frequent', 0.11), ('impressive', 0.105), ('pressure', 0.101), ('situation', 0.1), ('internally', 0.099), ('methods', 0.098), ('less', 0.097), ('act', 0.092), ('generated', 0.091), ('uses', 0.091), ('times', 0.089), ('protocol', 0.082), ('messaging', 0.08), ('services', 0.078), ('creates', 0.077), ('io', 0.075), ('many', 0.075), ('problems', 0.074), ('smaller', 0.074), ('vs', 0.072), ('messages', 0.072), ('others', 0.069), ('send', 0.067), ('consider', 0.065), ('framework', 0.064), ('lot', 0.059), ('client', 0.057)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="1551-tfidf-1" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>Introduction: Nettyis a high-performance NIO(New IO) client server framework for Java that
Twitter uses internally as a protocol agonostic RPC system. Twitterfound some
problemswith Netty 3's memory management for buffer allocations beacause it
generated a lot of garbage during operation. When you send as many messages as
Twitter it creates a lot of GC pressure and the simple act of zero filling
newly allocated buffers consumed 50% of memory bandwidth. Netty 4 fixes this
situation with:Short-lived event objects, methods on long-lived channel
objects are used to handle I/O events.Secialized buffer allocator that uses
pool which implementsbuddy memory allocationandslab allocation.The result:5
times less frequent GC pauses: 45.5 vs. 9.2 times/min5 times less garbage
production: 207.11 vs 41.81 MiB/sThe buffer pool is much faster than JVM as
the size of the buffer increases. Some problems with smaller buffers.Given how
many services use the JVM in their messaging infrastructure and how many
services hav</p><p>2 0.20672441 <a title="1551-tfidf-2" href="../high_scalability-2014/high_scalability-2014-01-20-8_Ways_Stardog_Made_its_Database_Insanely_Scalable.html">1582 high scalability-2014-01-20-8 Ways Stardog Made its Database Insanely Scalable</a></p>
<p>Introduction: Stardog makes a commercial graph database that is a great example of what can
be accomplished with a scale-up strategy on BigIron. In a recent article
StarDog described how they made their new 2.1 release insanely scalable,
improving query scalability by about 3 orders of magnitude and it can now
handle 50 billion triples on a $10,000 server with 32 cores and 256 GB RAM. It
can also load 20B datasets at 300,000 triples per second. What did they do
that you can also do?Avoid locks by using non-blocking algorithms and data
structures. For example, moving from BitSet to ConcurrentLinkedQueue.Use
ThreadLocal aggressively to reduce thread contention and avoid
synchronization.Batch LRU evictions in a single thread. Triggered by several
LRU caches becoming problematic when evictions were being swamped by
additions. Downside is batching increases memory pressure and GC times.Move to
SHA1 for hashing URIs, bnodes, and literal values. Making hash collisions
nearly impossible enable significant s</p><p>3 0.16692796 <a title="1551-tfidf-3" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>Introduction: This is a guest post by Greg Luck Founder and CTO,EhcacheTerracotta Inc.Note:
this article contains a bit too much of a product pitch, but the points are
still generally valid and useful.The legendary Moore's Law, which states that
the number of transistors that can be placed inexpensively on an integrated
circuit doubles approximately every two years, has held true since 1965. It
follows that integrated circuits will continue to get smaller, with chip
fabrication currently at a minuscule 22nm process (1). Users of big iron
hardware, or servers that are dense in terms of CPU power and memory capacity,
benefit from this trend as their hardware becomes cheaper and more powerful
over time. At some point soon, however, density limits imposed by quantum
mechanics will preclude further density increases.At the same time, low-cost
commodity hardware influences enterprise architects to scale their
applications horizontally, where processing is spread across clusters of low-
cost commodity serv</p><p>4 0.15402615 <a title="1551-tfidf-4" href="../high_scalability-2010/high_scalability-2010-02-19-Twitter%E2%80%99s_Plan_to_Analyze_100_Billion_Tweets.html">780 high scalability-2010-02-19-Twitter’s Plan to Analyze 100 Billion Tweets</a></p>
<p>Introduction: If Twitter is the "nervous system of the web" as some people think, then what
is the brain that makes sense of all those signals (tweets) from the nervous
system? That brain is the Twitter Analytics System and Kevin Weil, as
Analytics Lead at Twitter, is the homunculus within in charge of figuring out
what those over 100 billion tweets (approximately the number of neurons in the
human brain) mean.Twitter has only 10% of the expected 100 billion tweets now,
but a good brain always plans ahead. Kevin gave a talk,Hadoop and Protocol
Buffers at Twitter, at theHadoop Meetup, explaining how Twitter plans to use
all that data to an answer key business questions.What type of questions is
Twitter interested in answering? Questions that help them better understand
Twitter. Questions like:How many requests do we serve in a day?What is the
average latency?How many searches happen in day?How many unique queries, how
many unique users, what is their geographic distribution?What can we tell
about as</p><p>5 0.14861912 <a title="1551-tfidf-5" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>Introduction: As it is said in the recent article"Google: Taming the Long Latency Tail -
When More Machines Equals Worse Results" , latency variability has greater
impact in larger scale clusters where a typical request is composed of
multiple distributed/parallel requests. The overall response time dramatically
decreases if latency of each request is not consistent and low. In dynamically
scalable partitioned storage systems, whether it is a NoSQL database,
filesystem or in-memory data grid, changes in the cluster (adding or removing
a node) can lead to big data moves in the network to re-balance the cluster.
Re-balancing will be needed for both primary and backup data on those nodes.
If a node crashes for example, dead node's data has to be re-owned (become
primary) by other node(s) and also its backup has to be taken immediately to
be fail-safe again. Shuffling MBs of data around has a negative effect in the
cluster as it consumes your valuable resources such as network, CPU and RAM.
It might als</p><p>6 0.14450161 <a title="1551-tfidf-6" href="../high_scalability-2012/high_scalability-2012-11-29-Performance_data_for_LevelDB%2C_Berkley_DB_and_BangDB_for_Random_Operations.html">1364 high scalability-2012-11-29-Performance data for LevelDB, Berkley DB and BangDB for Random Operations</a></p>
<p>7 0.12783809 <a title="1551-tfidf-7" href="../high_scalability-2010/high_scalability-2010-07-14-DynaTrace%27s_Top_10_Performance_Problems_taken_from_Zappos%2C_Monster%2C_Thomson_and_Co.html">859 high scalability-2010-07-14-DynaTrace's Top 10 Performance Problems taken from Zappos, Monster, Thomson and Co</a></p>
<p>8 0.12525204 <a title="1551-tfidf-8" href="../high_scalability-2013/high_scalability-2013-12-16-22_Recommendations_for_Building_Effective_High_Traffic_Web_Software.html">1565 high scalability-2013-12-16-22 Recommendations for Building Effective High Traffic Web Software</a></p>
<p>9 0.12421716 <a title="1551-tfidf-9" href="../high_scalability-2012/high_scalability-2012-05-18-Stuff_The_Internet_Says_On_Scalability_For_May_18%2C_2012.html">1247 high scalability-2012-05-18-Stuff The Internet Says On Scalability For May 18, 2012</a></p>
<p>10 0.11587737 <a title="1551-tfidf-10" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>11 0.11309034 <a title="1551-tfidf-11" href="../high_scalability-2009/high_scalability-2009-06-27-Scaling_Twitter%3A_Making_Twitter_10000_Percent_Faster.html">639 high scalability-2009-06-27-Scaling Twitter: Making Twitter 10000 Percent Faster</a></p>
<p>12 0.10665554 <a title="1551-tfidf-12" href="../high_scalability-2008/high_scalability-2008-12-19-Gigaspaces_curbs_latency_outliers_with_Java_Real_Time.html">471 high scalability-2008-12-19-Gigaspaces curbs latency outliers with Java Real Time</a></p>
<p>13 0.10487144 <a title="1551-tfidf-13" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>14 0.1041225 <a title="1551-tfidf-14" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>15 0.10150443 <a title="1551-tfidf-15" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>16 0.10033196 <a title="1551-tfidf-16" href="../high_scalability-2012/high_scalability-2012-05-16-Big_List_of_20_Common_Bottlenecks.html">1246 high scalability-2012-05-16-Big List of 20 Common Bottlenecks</a></p>
<p>17 0.099111803 <a title="1551-tfidf-17" href="../high_scalability-2010/high_scalability-2010-06-07-Six_Ways_Twitter_May_Reach_its_Big_Hairy_Audacious_Goal_of_One_Billion_Users.html">837 high scalability-2010-06-07-Six Ways Twitter May Reach its Big Hairy Audacious Goal of One Billion Users</a></p>
<p>18 0.097527355 <a title="1551-tfidf-18" href="../high_scalability-2011/high_scalability-2011-03-14-6_Lessons_from_Dropbox_-_One_Million_Files_Saved_Every_15_minutes.html">1003 high scalability-2011-03-14-6 Lessons from Dropbox - One Million Files Saved Every 15 minutes</a></p>
<p>19 0.091947421 <a title="1551-tfidf-19" href="../high_scalability-2014/high_scalability-2014-03-20-Paper%3A_Log-structured_Memory_for_DRAM-based_Storage_-_High_Memory_Utilization_Plus_High_Performance.html">1616 high scalability-2014-03-20-Paper: Log-structured Memory for DRAM-based Storage - High Memory Utilization Plus High Performance</a></p>
<p>20 0.089869015 <a title="1551-tfidf-20" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.108), (1, 0.069), (2, -0.031), (3, -0.005), (4, 0.01), (5, 0.016), (6, 0.047), (7, 0.067), (8, -0.088), (9, -0.008), (10, 0.006), (11, 0.01), (12, 0.075), (13, 0.004), (14, -0.101), (15, -0.029), (16, 0.027), (17, -0.009), (18, -0.021), (19, -0.022), (20, -0.058), (21, -0.03), (22, 0.021), (23, 0.023), (24, -0.014), (25, 0.001), (26, 0.052), (27, -0.092), (28, 0.02), (29, 0.03), (30, 0.006), (31, -0.042), (32, -0.015), (33, -0.082), (34, -0.039), (35, 0.015), (36, -0.013), (37, 0.072), (38, -0.072), (39, 0.016), (40, 0.081), (41, 0.019), (42, 0.056), (43, 0.062), (44, -0.057), (45, -0.043), (46, 0.064), (47, 0.026), (48, 0.043), (49, 0.028)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98218685 <a title="1551-lsi-1" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>Introduction: Nettyis a high-performance NIO(New IO) client server framework for Java that
Twitter uses internally as a protocol agonostic RPC system. Twitterfound some
problemswith Netty 3's memory management for buffer allocations beacause it
generated a lot of garbage during operation. When you send as many messages as
Twitter it creates a lot of GC pressure and the simple act of zero filling
newly allocated buffers consumed 50% of memory bandwidth. Netty 4 fixes this
situation with:Short-lived event objects, methods on long-lived channel
objects are used to handle I/O events.Secialized buffer allocator that uses
pool which implementsbuddy memory allocationandslab allocation.The result:5
times less frequent GC pauses: 45.5 vs. 9.2 times/min5 times less garbage
production: 207.11 vs 41.81 MiB/sThe buffer pool is much faster than JVM as
the size of the buffer increases. Some problems with smaller buffers.Given how
many services use the JVM in their messaging infrastructure and how many
services hav</p><p>2 0.78179264 <a title="1551-lsi-2" href="../high_scalability-2014/high_scalability-2014-01-20-8_Ways_Stardog_Made_its_Database_Insanely_Scalable.html">1582 high scalability-2014-01-20-8 Ways Stardog Made its Database Insanely Scalable</a></p>
<p>Introduction: Stardog makes a commercial graph database that is a great example of what can
be accomplished with a scale-up strategy on BigIron. In a recent article
StarDog described how they made their new 2.1 release insanely scalable,
improving query scalability by about 3 orders of magnitude and it can now
handle 50 billion triples on a $10,000 server with 32 cores and 256 GB RAM. It
can also load 20B datasets at 300,000 triples per second. What did they do
that you can also do?Avoid locks by using non-blocking algorithms and data
structures. For example, moving from BitSet to ConcurrentLinkedQueue.Use
ThreadLocal aggressively to reduce thread contention and avoid
synchronization.Batch LRU evictions in a single thread. Triggered by several
LRU caches becoming problematic when evictions were being swamped by
additions. Downside is batching increases memory pressure and GC times.Move to
SHA1 for hashing URIs, bnodes, and literal values. Making hash collisions
nearly impossible enable significant s</p><p>3 0.74832773 <a title="1551-lsi-3" href="../high_scalability-2011/high_scalability-2011-03-14-6_Lessons_from_Dropbox_-_One_Million_Files_Saved_Every_15_minutes.html">1003 high scalability-2011-03-14-6 Lessons from Dropbox - One Million Files Saved Every 15 minutes</a></p>
<p>Introduction: Dropboxsaves one million files every 15 minutes,  more tweets than even
Twitterers tweet. That mind blowing statistic was revealed by Rian Hunter, a
Dropbox Engineer, in his presentation How Dropbox Did It and How Python Helped
at PyCon 2011.The first part of the presentation is some Dropbox lore, origin
stories and other foundational myths. We learn thatDropbox is a startup
company located in San Francisco that has probably one of the most popular
file synchronization and sharing tools in the world, shipping Python on the
desktop and supporting millions of users and growing every day. About half way
through the talk turns technical. Not a lot of info on how Dropbox handles
this massive scale was dropped, but there were a number of good lessons to
ponder:Use Python99.9 % of their code is in Python. Used on the server
backend; desktop client, website controller logic, API backend, and
analytics.Can't use Python on the Android due to memory constraints.Runs on a
single code base using Py</p><p>4 0.70118135 <a title="1551-lsi-4" href="../high_scalability-2011/high_scalability-2011-09-19-Big_Iron_Returns_with_BigMemory.html">1118 high scalability-2011-09-19-Big Iron Returns with BigMemory</a></p>
<p>Introduction: This is a guest post by Greg Luck Founder and CTO,EhcacheTerracotta Inc.Note:
this article contains a bit too much of a product pitch, but the points are
still generally valid and useful.The legendary Moore's Law, which states that
the number of transistors that can be placed inexpensively on an integrated
circuit doubles approximately every two years, has held true since 1965. It
follows that integrated circuits will continue to get smaller, with chip
fabrication currently at a minuscule 22nm process (1). Users of big iron
hardware, or servers that are dense in terms of CPU power and memory capacity,
benefit from this trend as their hardware becomes cheaper and more powerful
over time. At some point soon, however, density limits imposed by quantum
mechanics will preclude further density increases.At the same time, low-cost
commodity hardware influences enterprise architects to scale their
applications horizontally, where processing is spread across clusters of low-
cost commodity serv</p><p>5 0.68742269 <a title="1551-lsi-5" href="../high_scalability-2008/high_scalability-2008-08-14-Product%3A_Terracotta_-_Open_Source_Network-Attached_Memory.html">364 high scalability-2008-08-14-Product: Terracotta - Open Source Network-Attached Memory</a></p>
<p>Introduction: Update:Evaluating Terracottaby Piotr Woloszyn. Nice writeup that covers
resilience, failover, DB persistence, Distributed caching implementation,
OS/Platform restrictions, Ease of implementation, Hardware requirements,
Performance, Support package, Code stability, partitioning, Transactional,
Replication and consistency.Terracottais Network Attached Memory (NAM) for
Java VMs. It provides up to a terabyte of virtual heap for Java applications
that spans hundreds of connected JVMs.NAM is best suited for storing what they
call scratch data. Scratch data is defined as object oriented data that is
critical to the execution of a series of Java operations inside the JVM, but
may not be critical once a business transaction is complete.The Terracotta
Architecture has three components:Client Nodes - Each client node corresponds
to a client node in the cluster which runs on a standard JVMServer Cluster -
java process that provides the clustering intelligence. The current Terracotta
implementation</p><p>6 0.67778522 <a title="1551-lsi-6" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>7 0.67665982 <a title="1551-lsi-7" href="../high_scalability-2014/high_scalability-2014-03-20-Paper%3A_Log-structured_Memory_for_DRAM-based_Storage_-_High_Memory_Utilization_Plus_High_Performance.html">1616 high scalability-2014-03-20-Paper: Log-structured Memory for DRAM-based Storage - High Memory Utilization Plus High Performance</a></p>
<p>8 0.6565026 <a title="1551-lsi-8" href="../high_scalability-2008/high_scalability-2008-12-03-Java_World_Interview_on_Scalability_and_Other_Java_Scalability_Secrets.html">459 high scalability-2008-12-03-Java World Interview on Scalability and Other Java Scalability Secrets</a></p>
<p>9 0.65469384 <a title="1551-lsi-9" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>10 0.65378112 <a title="1551-lsi-10" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>11 0.64677131 <a title="1551-lsi-11" href="../high_scalability-2007/high_scalability-2007-09-15-The_Role_of_Memory_within_Web_2.0_Architectures_and_Deployments.html">92 high scalability-2007-09-15-The Role of Memory within Web 2.0 Architectures and Deployments</a></p>
<p>12 0.59144533 <a title="1551-lsi-12" href="../high_scalability-2012/high_scalability-2012-09-10-Russ%E2%80%99_10_Ingredient_Recipe_for_Making_1_Million_TPS_on_%245K_Hardware.html">1319 high scalability-2012-09-10-Russ’ 10 Ingredient Recipe for Making 1 Million TPS on $5K Hardware</a></p>
<p>13 0.57150692 <a title="1551-lsi-13" href="../high_scalability-2013/high_scalability-2013-12-11-Using_Node.js_PayPal_Doubles_RPS%2C_Lowers_Latency%2C_with_Fewer_Developers%2C_but_Where_Do_the_Improvements_Really_Come_From%3F.html">1563 high scalability-2013-12-11-Using Node.js PayPal Doubles RPS, Lowers Latency, with Fewer Developers, but Where Do the Improvements Really Come From?</a></p>
<p>14 0.56490678 <a title="1551-lsi-14" href="../high_scalability-2012/high_scalability-2012-08-30-Dramatically_Improving_Performance_by_Debugging_Brutally_Complex_Prolems.html">1314 high scalability-2012-08-30-Dramatically Improving Performance by Debugging Brutally Complex Prolems</a></p>
<p>15 0.56040716 <a title="1551-lsi-15" href="../high_scalability-2008/high_scalability-2008-12-19-Gigaspaces_curbs_latency_outliers_with_Java_Real_Time.html">471 high scalability-2008-12-19-Gigaspaces curbs latency outliers with Java Real Time</a></p>
<p>16 0.55950695 <a title="1551-lsi-16" href="../high_scalability-2009/high_scalability-2009-06-27-Scaling_Twitter%3A_Making_Twitter_10000_Percent_Faster.html">639 high scalability-2009-06-27-Scaling Twitter: Making Twitter 10000 Percent Faster</a></p>
<p>17 0.55916423 <a title="1551-lsi-17" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>18 0.55548334 <a title="1551-lsi-18" href="../high_scalability-2009/high_scalability-2009-09-10-When_optimizing_-_don%27t_forget_the_Java_Virtual_Machine_%28JVM%29_.html">701 high scalability-2009-09-10-When optimizing - don't forget the Java Virtual Machine (JVM) </a></p>
<p>19 0.55504584 <a title="1551-lsi-19" href="../high_scalability-2012/high_scalability-2012-05-16-Big_List_of_20_Common_Bottlenecks.html">1246 high scalability-2012-05-16-Big List of 20 Common Bottlenecks</a></p>
<p>20 0.55348563 <a title="1551-lsi-20" href="../high_scalability-2009/high_scalability-2009-04-05-At_Some_Point_the_Cost_of_Servers_Outweighs_the_Cost_of_Programmers.html">556 high scalability-2009-04-05-At Some Point the Cost of Servers Outweighs the Cost of Programmers</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.033), (2, 0.239), (10, 0.074), (58, 0.244), (61, 0.06), (77, 0.043), (79, 0.116), (94, 0.072)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.89555347 <a title="1551-lda-1" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>Introduction: Nettyis a high-performance NIO(New IO) client server framework for Java that
Twitter uses internally as a protocol agonostic RPC system. Twitterfound some
problemswith Netty 3's memory management for buffer allocations beacause it
generated a lot of garbage during operation. When you send as many messages as
Twitter it creates a lot of GC pressure and the simple act of zero filling
newly allocated buffers consumed 50% of memory bandwidth. Netty 4 fixes this
situation with:Short-lived event objects, methods on long-lived channel
objects are used to handle I/O events.Secialized buffer allocator that uses
pool which implementsbuddy memory allocationandslab allocation.The result:5
times less frequent GC pauses: 45.5 vs. 9.2 times/min5 times less garbage
production: 207.11 vs 41.81 MiB/sThe buffer pool is much faster than JVM as
the size of the buffer increases. Some problems with smaller buffers.Given how
many services use the JVM in their messaging infrastructure and how many
services hav</p><p>2 0.8453697 <a title="1551-lda-2" href="../high_scalability-2009/high_scalability-2009-05-01-FastBit%3A_An_Efficient_Compressed_Bitmap_Index_Technology.html">587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</a></p>
<p>Introduction: Data mining and fast queries are always in that bin of hard to do things where
doing something smarter can yield big results. Bloom Filters are one such do
it smarter strategy, compressed bitmap indexes are another. In one application
"FastBit outruns other search indexes by a factor of 10 to 100 and doesn't
require much more room than the original data size." The data size is an
interesting metric. Our old standard b-trees can be two to four times larger
than the original data. In a test searching an Enron email database FastBit
outran MySQL by 10 to 1,000 times.FastBit is a software tool for searching
large read-only datasets. It organizes user data in a column-oriented
structure which is efficient for on-line analytical processing (OLAP), and
utilizes compressed bitmap indices to further speed up query processing.
Analyses have proven the compressed bitmap index used in FastBit to be
theoretically optimal for one-dimensional queries. Compared with other optimal
indexing methods, bit</p><p>3 0.78260493 <a title="1551-lda-3" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>Introduction: In How to take advantage of Redis just adding it to your stack Salvatore
'antirez' Sanfilippo shows how to solve some common problems in Redis by
taking advantage of its unique data structure handling capabilities. Common
Redis primitives like LPUSH, and LTRIM, and LREM are used to accomplish tasks
programmers need to get done, but that can be hard or slow in more traditional
stores. A very useful and practical article. How would you accomplish these
tasks in your framework?Show latest items listings in your home page. This is
a live in-memory cache and is very fast.LPUSHis used to insert a content ID at
the head of the list stored at a key.LTRIMis used to limit the number of items
in the list to 5000. If the user needs to page beyond this cache only then are
they sent to the database.Deletion and filtering. If a cached article is
deleted it can be removed from the cache using LREM.Leaderboards and related
problems. A leader board is a set sorted by score. TheZADDcommands implements
th</p><p>4 0.76438785 <a title="1551-lda-4" href="../high_scalability-2010/high_scalability-2010-11-29-Stuff_the_Internet_Says_on_Scalability_For_November_29th%2C_2010.html">949 high scalability-2010-11-29-Stuff the Internet Says on Scalability For November 29th, 2010</a></p>
<p>Introduction: Eating turkey all weekend and wondering what you might have missed?James
Hamilton on why "all you have learned about disks so far is probably wrong" in
Availability in Globally Distributed Storage. It turns out for the same reason
our financial systems melt down:black swans. The world is predictably
unpredictable. Murat Demirbas also has agood poston the same Google research
paper.Stack OverflowHits10M UniquesVroom...Formula One racecarstreams 27
gigabytes of telemetrydata during a race weekend! 200 sensors "measuring
anything and everything that moves or gets warm. Quotable Quotes:@dmalenko:It
is cool to sit by the ocean, oversee the sunset and think about scalability
models for a web app@detroitpro: I have to admit; sometimes I think "This
would be easier with a SQL DB" #NoSQL #NotOften #ComplextRelationships
#FindingRootObjectsYou may have missed the Google App Enginecage match. First
GAE sucks and then it's great. Whatever your conclusion it's an informative
discussion. GAE is like</p><p>5 0.74315679 <a title="1551-lda-5" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: InTaming The Long Latency Tailwe coveredLuiz Barroso's exploration of the long
tail latency (some operations are really slow) problems generated by large
fanout architectures (a request is composed of potentially thousands of other
requests). You may have noticed there weren't a lot of solutions. That's where
a talk I attended,Achieving Rapid Response Times in Large Online
Services(slide deck), byJeff Dean, also of Google, comes in:In this talk, I'll
describe a collection of techniques and practices lowering response times in
large distributed systems whose components run on shared clusters of machines,
where pieces of these systems are subject to interference by other tasks, and
where unpredictable latency hiccups are the norm, not the exception.The goal
is to use software techniques to reduce variability given the increasing
variability in underlying hardware, the need to handle dynamic workloads on a
shared infrastructure, and the need to use large fanout architectures to
operate at</p><p>6 0.7427671 <a title="1551-lda-6" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>7 0.74007899 <a title="1551-lda-7" href="../high_scalability-2010/high_scalability-2010-07-20-Strategy%3A_Consider_When_a_Service_Starts_Billing_in_Your_Algorithm_Cost.html">862 high scalability-2010-07-20-Strategy: Consider When a Service Starts Billing in Your Algorithm Cost</a></p>
<p>8 0.73998386 <a title="1551-lda-8" href="../high_scalability-2008/high_scalability-2008-07-20-Strategy%3A_Front_S3_with_a_Caching_Proxy.html">353 high scalability-2008-07-20-Strategy: Front S3 with a Caching Proxy</a></p>
<p>9 0.73869532 <a title="1551-lda-9" href="../high_scalability-2008/high_scalability-2008-04-21-The_Search_for_the_Source_of_Data_-_How_SimpleDB_Differs_from_a_RDBMS.html">306 high scalability-2008-04-21-The Search for the Source of Data - How SimpleDB Differs from a RDBMS</a></p>
<p>10 0.73840237 <a title="1551-lda-10" href="../high_scalability-2009/high_scalability-2009-03-11-The_Implications_of_Punctuated_Scalabilium_for_Website_Architecture.html">533 high scalability-2009-03-11-The Implications of Punctuated Scalabilium for Website Architecture</a></p>
<p>11 0.73830611 <a title="1551-lda-11" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>12 0.7379232 <a title="1551-lda-12" href="../high_scalability-2007/high_scalability-2007-12-12-Report_from_OpenSocial_Meetup_at_Google.html">183 high scalability-2007-12-12-Report from OpenSocial Meetup at Google</a></p>
<p>13 0.73781836 <a title="1551-lda-13" href="../high_scalability-2007/high_scalability-2007-10-10-WAN_Accelerate_Your_Way_to_Lightening_Fast_Transfers_Between_Data_Centers.html">119 high scalability-2007-10-10-WAN Accelerate Your Way to Lightening Fast Transfers Between Data Centers</a></p>
<p>14 0.7352457 <a title="1551-lda-14" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<p>15 0.73508757 <a title="1551-lda-15" href="../high_scalability-2011/high_scalability-2011-09-07-What_Google_App_Engine_Price_Changes_Say_About_the_Future_of_Web_Architecture.html">1112 high scalability-2011-09-07-What Google App Engine Price Changes Say About the Future of Web Architecture</a></p>
<p>16 0.73445129 <a title="1551-lda-16" href="../high_scalability-2007/high_scalability-2007-08-29-Skype_Failed_the_Boot_Scalability_Test%3A_Is_P2P_fundamentally_flawed%3F.html">76 high scalability-2007-08-29-Skype Failed the Boot Scalability Test: Is P2P fundamentally flawed?</a></p>
<p>17 0.7340309 <a title="1551-lda-17" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>18 0.73302031 <a title="1551-lda-18" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>19 0.73279232 <a title="1551-lda-19" href="../high_scalability-2009/high_scalability-2009-04-05-At_Some_Point_the_Cost_of_Servers_Outweighs_the_Cost_of_Programmers.html">556 high scalability-2009-04-05-At Some Point the Cost of Servers Outweighs the Cost of Programmers</a></p>
<p>20 0.73266584 <a title="1551-lda-20" href="../high_scalability-2009/high_scalability-2009-03-05-Strategy%3A__In_Cloud_Computing_Systematically_Drive_Load_to_the_CPU.html">526 high scalability-2009-03-05-Strategy:  In Cloud Computing Systematically Drive Load to the CPU</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
