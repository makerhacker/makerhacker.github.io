<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1211" href="#">high_scalability-2012-1211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1211-html" href="http://highscalability.com//blog/2012/3/19/linkedin-creating-a-low-latency-change-data-capture-system-w.html">html</a></p><p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team.Over the past 3 years, I've had the good fortune
to work with many emerging NoSQL products in the context of supporting the
needs of a high-traffic, customer facing web site.In 2010, I helped Netflix to
successfullytransition its web scale use-cases from Oracle to SimpleDB, AWS'
hosted database service. On completion of that migration, we started a second
migration, this time from SimpleDB to Cassandra. The first transition was key
to our move from our own data center to AWS' cloud. The second was key to our
expansion from one AWS Region to multiple geographically-distributed Regions
-- today Netflix serves traffic out of two AWS Regions, one in Virginia, the
other in Ireland (F1). Both of these transitions have been successful, but
have involved integration pain points such as the creation of database
replication technology.In December 2011, I moved to LinkedIn's Distributed
Data System</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This is a guest post bySiddharth Anand, a senior member of LinkedIn's Distributed Data Systems team. [sent-1, score-0.142]
</p><p>2 DDS develops data infrastructure, including but not limited to, NoSQL databases and data replication systems. [sent-9, score-0.142]
</p><p>3 Often times, data is pulled off this primary data store, transformed, and then stored in a secondary data store, such as a data warehouse. [sent-17, score-0.443]
</p><p>4 This secondary store typically supports the data analytics that drive business insights and direction. [sent-18, score-0.231]
</p><p>5 In this scheme, the two stores are known as the OLTP store and the OLAP store, respectively. [sent-19, score-0.093]
</p><p>6 Increasingly, data from the primary store is used to feed more than just business decisions. [sent-21, score-0.256]
</p><p>7 If you have ever worked in the area of transferring data from the primary store to secondary stores, you are no doubt familiar with the options available to you. [sent-26, score-0.323]
</p><p>8 What do you do if you need a stream of near-real-time updates from your primary data store, as shown below for LinkedIn's near-real-time needs? [sent-37, score-0.163]
</p><p>9 ) and store the result in a circular in-memory buffer. [sent-51, score-0.093]
</p><p>10 Clients (subscribers) listening for events will pull recent online changes as they appear in the Relay (Step 2). [sent-52, score-0.149]
</p><p>11 A Bootstrap component is also listening to on-line changes as they appear in the Relay. [sent-53, score-0.22]
</p><p>12 This will return an efficient representation of all changes that have occurred since time T. [sent-55, score-0.084]
</p><p>13 The client library would then request Consolidated Deltas since that time T (Step 6). [sent-58, score-0.141]
</p><p>14 After the Subscriber applies the Consolidated Deltas, the client library would switch to listening for online changes from the Relay (Step 7). [sent-59, score-0.29]
</p><p>15 The client library helps the subscriber get all changes since time T, where T can be any arbitrary point in time, shielding the Subscriber from the details of where the changes are coming from. [sent-60, score-0.608]
</p><p>16 However, all of these systems put load on the primary data store when a consumer falls behind. [sent-65, score-0.311]
</p><p>17 restore the previous night's snapshot on a temporary Oracle instance, transform the data and transfer it to the consumer, then apply changes since the snapshot, etc. [sent-69, score-0.388]
</p><p>18 As shown earlier, the Bootstrap component listens for online changes as they occur in the Relay. [sent-76, score-0.155]
</p><p>19 Netflix published a tech blog aboutAegisthus, a system to transform an eventually- consistent set of data files into a time-line consistent stream. [sent-91, score-0.26]
</p><p>20 OLAP (Online Analytic Processing) : This differentiates between their uses -- OLTP for primary data serving, OLAP for analytic processing of a modified copy of the primary data. [sent-104, score-0.255]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('databus', 0.494), ('subscriber', 0.299), ('bootstrap', 0.241), ('snapshot', 0.17), ('deltas', 0.158), ('relay', 0.158), ('espresso', 0.156), ('consolidated', 0.148), ('linkedin', 0.122), ('dds', 0.117), ('shirshanka', 0.117), ('regions', 0.112), ('step', 0.097), ('das', 0.095), ('store', 0.093), ('primary', 0.092), ('changes', 0.084), ('client', 0.083), ('member', 0.079), ('agila', 0.078), ('botev', 0.078), ('chavdar', 0.078), ('devi', 0.078), ('kapil', 0.078), ('nishant', 0.078), ('pinto', 0.078), ('sai', 0.078), ('schulman', 0.078), ('sundar', 0.078), ('surlaker', 0.078), ('nosql', 0.077), ('data', 0.071), ('zhang', 0.071), ('ramana', 0.071), ('component', 0.071), ('log', 0.07), ('netflix', 0.069), ('secondary', 0.067), ('olap', 0.067), ('ramakrishnan', 0.066), ('listening', 0.065), ('transform', 0.063), ('consistent', 0.063), ('senior', 0.063), ('ireland', 0.061), ('capture', 0.059), ('oracle', 0.058), ('library', 0.058), ('anand', 0.057), ('consumer', 0.055)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999988 <a title="1211-tfidf-1" href="../high_scalability-2012/high_scalability-2012-03-19-LinkedIn%3A_Creating_a_Low_Latency_Change_Data_Capture_System_with_Databus.html">1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</a></p>
<p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team.Over the past 3 years, I've had the good fortune
to work with many emerging NoSQL products in the context of supporting the
needs of a high-traffic, customer facing web site.In 2010, I helped Netflix to
successfullytransition its web scale use-cases from Oracle to SimpleDB, AWS'
hosted database service. On completion of that migration, we started a second
migration, this time from SimpleDB to Cassandra. The first transition was key
to our move from our own data center to AWS' cloud. The second was key to our
expansion from one AWS Region to multiple geographically-distributed Regions
-- today Netflix serves traffic out of two AWS Regions, one in Virginia, the
other in Ireland (F1). Both of these transitions have been successful, but
have involved integration pain points such as the creation of database
replication technology.In December 2011, I moved to LinkedIn's Distributed
Data System</p><p>2 0.17314625 <a title="1211-tfidf-2" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team. Preamble RambleIf you've been working in the
online (e.g. internet) space over the past 3 years, you are no stranger to
terms like "the cloud" and "NoSQL".In 2007, Amazon published a paper onDynamo.
The paper detailed how Dynamo, employing a collection of techniques to solve
several problems in fault-tolerance, provided a resilient solution to the on-
line shopping cart problem. A few years go by while engineers at AWS toil in
relative obscurity at standing up their public cloud.It's December 2008 and I
am a member of Netflix's Software Infrastructure team. We've just been told
that there is something called the "CAP theorem" and because of it, we are to
abandon our datacenter in hopes of leveraging Cloud Computing.Huh?A month into
the investigation, we start wondering about our Oracle database. How are we
are going to move it into the cloud? That's when we are told that we are to
aband</p><p>3 0.16629894 <a title="1211-tfidf-3" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>Introduction: This is a guest post written byVictor Trac, Cloud Architect
atBazaarvoice.Bazaarvoice is a company that people interact with on a regular
basis but have probably never heard of. If you read customer reviews on sites
like bestbuy.com, nike.com, or walmart.com, you are using Bazaarvoice
services. These sites, along with thousands of others, rely on Bazaarvoice to
supply the software and technology to collect and display user conversations
about products and services. All of this means that Bazaarvoice processes a
lot of sentiment data on most of the products we all use daily.Bazaarvoice
helps our clients make better products by using a combination of machine
learning and natural language processing to extract useful information and
user sentiments from the millions of free-text reviews that go through our
platform. This data gets boiled down into reports that clients can use to
improve their products and services. We are also starting to look at how to
show personalized sortings of revie</p><p>4 0.11024888 <a title="1211-tfidf-4" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>Introduction: It's a truism that we should choose theright tool for the job. Everyone says
that. And who can disagree? The problem is this is not helpful advice without
being able to answer more specific questions like: What jobs are the tools
good at? Will they work on jobs like mine? Is it worth the risk to try
something new when all my people know something else and we have a deadline to
meet? How can I make all the tools work together?In the NoSQL space this kind
of real-world data is still a bit vague. When asked, vendors tend to give very
general answers like NoSQL is good for BigData or key-value access. What does
that mean for for the developer in the trenches faced with the task of solving
a specific problem and there are a dozen confusing choices and no obvious
winner? Not a lot. It's often hard to take that next step and imagine how
their specific problems could be solved in a way that's worth taking the
trouble and risk.Let's change that. What problems are you using NoSQL to
solve? Which</p><p>5 0.11020145 <a title="1211-tfidf-5" href="../high_scalability-2010/high_scalability-2010-10-22-Paper%3A_Netflix%E2%80%99s_Transition_to_High-Availability_Storage_Systems_.html">925 high scalability-2010-10-22-Paper: Netflix’s Transition to High-Availability Storage Systems </a></p>
<p>Introduction: In an audacious move for such an established property, Netflix is moving their
website out of the comfort of their own datacenter and into the wilds of the
Amazon cloud. This paper by Netflix's Siddharth "Sid" Anand,Netflix's
Transition to High-Availability Storage Systems, gives a detailed look at this
transition and does a deep dive on SimpleDB best practices, focussing
especially on techniques useful to those who are making the move from a
RDBMS.Sid is going to give a talk at QCon based on this paper and he would
appreciate your feedback. So if you have any comments or thoughts please
comment here or email Sid atr39132@hotmail.com or Twitter at @r39132 Here's
the introduction from the paper:Circa late 2008, Netflix had a single data
center. This single data center raised a few concerns. As a single-point-of-
failure (a.k.a. SPOF), it represented a liability - data center outages meant
interruptions to service and negative customer impact. Additionally, with
growth in both streaming</p><p>6 0.099813387 <a title="1211-tfidf-6" href="../high_scalability-2008/high_scalability-2008-06-04-LinkedIn_Architecture.html">339 high scalability-2008-06-04-LinkedIn Architecture</a></p>
<p>7 0.098872751 <a title="1211-tfidf-7" href="../high_scalability-2007/high_scalability-2007-11-11-Linkedin_architecture.html">148 high scalability-2007-11-11-Linkedin architecture</a></p>
<p>8 0.096141286 <a title="1211-tfidf-8" href="../high_scalability-2012/high_scalability-2012-12-11-Sponsored_Post%3A_Rumble_Games%2C_Duolingo%2C_Booking%2C_aiCache%2C_Teradata_Aster%2C_Hadapt%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1370 high scalability-2012-12-11-Sponsored Post: Rumble Games, Duolingo, Booking, aiCache, Teradata Aster, Hadapt, Aerospike, Percona, ScaleOut, New Relic, NetDNA, GigaSpaces, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>9 0.096141286 <a title="1211-tfidf-9" href="../high_scalability-2012/high_scalability-2012-12-25-Sponsored_Post%3A_Flurry%2C_Rumble_Games%2C_Duolingo%2C_Booking%2C_aiCache%2C_Teradata_Aster%2C_Hadapt%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1376 high scalability-2012-12-25-Sponsored Post: Flurry, Rumble Games, Duolingo, Booking, aiCache, Teradata Aster, Hadapt, Aerospike, Percona, ScaleOut, New Relic, NetDNA, GigaSpaces, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>10 0.094040975 <a title="1211-tfidf-10" href="../high_scalability-2012/high_scalability-2012-11-27-Sponsored_Post%3A__Akiban%2C_Booking%2C_Teradata_Aster%2C_Hadapt%2C_Zoosk%2C_Aerospike%2C_Server_Stack%2C_Wiredrive%2C_NY_Times%2C_CouchConf%2C_FiftyThree%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_AiCache%2C_Logic_Monitor%2C_AppDynamics.html">1363 high scalability-2012-11-27-Sponsored Post:  Akiban, Booking, Teradata Aster, Hadapt, Zoosk, Aerospike, Server Stack, Wiredrive, NY Times, CouchConf, FiftyThree, Percona, ScaleOut, New Relic, NetDNA, GigaSpaces, AiCache, Logic Monitor, AppDynamics</a></p>
<p>11 0.093542829 <a title="1211-tfidf-11" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>12 0.092635475 <a title="1211-tfidf-12" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>13 0.092462957 <a title="1211-tfidf-13" href="../high_scalability-2012/high_scalability-2012-05-07-Startups_are_Creating_a_New_System_of_the_World_for_IT.html">1240 high scalability-2012-05-07-Startups are Creating a New System of the World for IT</a></p>
<p>14 0.0912707 <a title="1211-tfidf-14" href="../high_scalability-2013/high_scalability-2013-02-19-Sponsored_Post%3A_OLO%2C_Amazon%2C_Zoosk%2C_aiCache%2C_Teradata_Aster%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1409 high scalability-2013-02-19-Sponsored Post: OLO, Amazon, Zoosk, aiCache, Teradata Aster, Aerospike, Percona, ScaleOut, New Relic, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>15 0.091089539 <a title="1211-tfidf-15" href="../high_scalability-2013/high_scalability-2013-01-08-Sponsored_Post%3A_Flurry%2C_Rumble_Games%2C_Booking%2C_aiCache%2C_Teradata_Aster%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_GigaSpaces%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1383 high scalability-2013-01-08-Sponsored Post: Flurry, Rumble Games, Booking, aiCache, Teradata Aster, Aerospike, Percona, ScaleOut, New Relic, NetDNA, GigaSpaces, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>16 0.090359449 <a title="1211-tfidf-16" href="../high_scalability-2010/high_scalability-2010-10-28-Notes_from_A_NOSQL_Evening_in_Palo_Alto_.html">931 high scalability-2010-10-28-Notes from A NOSQL Evening in Palo Alto </a></p>
<p>17 0.088426031 <a title="1211-tfidf-17" href="../high_scalability-2013/high_scalability-2013-02-05-Sponsored_Post%3A_Amazon%2C_Zoosk%2C_aiCache%2C_Teradata_Aster%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1400 high scalability-2013-02-05-Sponsored Post: Amazon, Zoosk, aiCache, Teradata Aster, Aerospike, Percona, ScaleOut, New Relic, NetDNA, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>18 0.086886361 <a title="1211-tfidf-18" href="../high_scalability-2013/high_scalability-2013-01-22-Sponsored_Post%3A_Amazon%2C_Zoosk%2C_Booking%2C_aiCache%2C_Teradata_Aster%2C_Aerospike%2C_Percona%2C_ScaleOut%2C_New_Relic%2C_NetDNA%2C_Logic_Monitor%2C_AppDynamics%2C_ManageEngine%2C_Site24x7.html">1391 high scalability-2013-01-22-Sponsored Post: Amazon, Zoosk, Booking, aiCache, Teradata Aster, Aerospike, Percona, ScaleOut, New Relic, NetDNA, Logic Monitor, AppDynamics, ManageEngine, Site24x7</a></p>
<p>19 0.084920123 <a title="1211-tfidf-19" href="../high_scalability-2011/high_scalability-2011-04-06-Netflix%3A_Run_Consistency_Checkers_All_the_time_to_Fixup_Transactions.html">1017 high scalability-2011-04-06-Netflix: Run Consistency Checkers All the time to Fixup Transactions</a></p>
<p>20 0.082225695 <a title="1211-tfidf-20" href="../high_scalability-2014/high_scalability-2014-03-24-Big%2C_Small%2C_Hot_or_Cold_-_Examples_of_Robust_Data_Pipelines_from_Stripe%2C_Tapad%2C_Etsy_and_Square.html">1618 high scalability-2014-03-24-Big, Small, Hot or Cold - Examples of Robust Data Pipelines from Stripe, Tapad, Etsy and Square</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.168), (1, 0.043), (2, -0.02), (3, 0.024), (4, 0.03), (5, 0.047), (6, 0.013), (7, -0.059), (8, 0.026), (9, -0.02), (10, 0.025), (11, 0.018), (12, -0.029), (13, -0.062), (14, 0.004), (15, 0.056), (16, 0.037), (17, -0.002), (18, 0.01), (19, -0.011), (20, 0.003), (21, -0.024), (22, 0.032), (23, 0.023), (24, 0.012), (25, -0.004), (26, -0.037), (27, 0.021), (28, 0.005), (29, -0.024), (30, -0.015), (31, -0.003), (32, -0.023), (33, -0.015), (34, -0.006), (35, 0.04), (36, 0.007), (37, -0.011), (38, -0.0), (39, -0.011), (40, 0.057), (41, -0.015), (42, 0.056), (43, 0.022), (44, 0.029), (45, -0.016), (46, -0.022), (47, -0.036), (48, -0.023), (49, 0.022)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.94818187 <a title="1211-lsi-1" href="../high_scalability-2012/high_scalability-2012-03-19-LinkedIn%3A_Creating_a_Low_Latency_Change_Data_Capture_System_with_Databus.html">1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</a></p>
<p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team.Over the past 3 years, I've had the good fortune
to work with many emerging NoSQL products in the context of supporting the
needs of a high-traffic, customer facing web site.In 2010, I helped Netflix to
successfullytransition its web scale use-cases from Oracle to SimpleDB, AWS'
hosted database service. On completion of that migration, we started a second
migration, this time from SimpleDB to Cassandra. The first transition was key
to our move from our own data center to AWS' cloud. The second was key to our
expansion from one AWS Region to multiple geographically-distributed Regions
-- today Netflix serves traffic out of two AWS Regions, one in Virginia, the
other in Ireland (F1). Both of these transitions have been successful, but
have involved integration pain points such as the creation of database
replication technology.In December 2011, I moved to LinkedIn's Distributed
Data System</p><p>2 0.77788508 <a title="1211-lsi-2" href="../high_scalability-2010/high_scalability-2010-10-22-Paper%3A_Netflix%E2%80%99s_Transition_to_High-Availability_Storage_Systems_.html">925 high scalability-2010-10-22-Paper: Netflix’s Transition to High-Availability Storage Systems </a></p>
<p>Introduction: In an audacious move for such an established property, Netflix is moving their
website out of the comfort of their own datacenter and into the wilds of the
Amazon cloud. This paper by Netflix's Siddharth "Sid" Anand,Netflix's
Transition to High-Availability Storage Systems, gives a detailed look at this
transition and does a deep dive on SimpleDB best practices, focussing
especially on techniques useful to those who are making the move from a
RDBMS.Sid is going to give a talk at QCon based on this paper and he would
appreciate your feedback. So if you have any comments or thoughts please
comment here or email Sid atr39132@hotmail.com or Twitter at @r39132 Here's
the introduction from the paper:Circa late 2008, Netflix had a single data
center. This single data center raised a few concerns. As a single-point-of-
failure (a.k.a. SPOF), it represented a liability - data center outages meant
interruptions to service and negative customer impact. Additionally, with
growth in both streaming</p><p>3 0.7720992 <a title="1211-lsi-3" href="../high_scalability-2010/high_scalability-2010-12-06-What_the_heck_are_you_actually_using_NoSQL_for%3F.html">954 high scalability-2010-12-06-What the heck are you actually using NoSQL for?</a></p>
<p>Introduction: It's a truism that we should choose theright tool for the job. Everyone says
that. And who can disagree? The problem is this is not helpful advice without
being able to answer more specific questions like: What jobs are the tools
good at? Will they work on jobs like mine? Is it worth the risk to try
something new when all my people know something else and we have a deadline to
meet? How can I make all the tools work together?In the NoSQL space this kind
of real-world data is still a bit vague. When asked, vendors tend to give very
general answers like NoSQL is good for BigData or key-value access. What does
that mean for for the developer in the trenches faced with the task of solving
a specific problem and there are a dozen confusing choices and no obvious
winner? Not a lot. It's often hard to take that next step and imagine how
their specific problems could be solved in a way that's worth taking the
trouble and risk.Let's change that. What problems are you using NoSQL to
solve? Which</p><p>4 0.75790757 <a title="1211-lsi-4" href="../high_scalability-2012/high_scalability-2012-05-14-DynamoDB_Talk_Notes_and_the_SSD_Hot_S3_Cold_Pattern.html">1245 high scalability-2012-05-14-DynamoDB Talk Notes and the SSD Hot S3 Cold Pattern</a></p>
<p>Introduction: My impression of DynamoDB before attending aAmazon DynamoDB for Developerstalk
is that it's the usual quality service produced by Amazon: simple, fast,
scalable, geographically redundant, expensive enough to make you think twice
about using it, and delightfully NoOp.After the talk my impression has become
more nuanced. The quality impression still stands. Look at theforumsand you'll
see the typical issues every product has, but no real surprises. And as a
SimpleDB++, DynamoDB seems to have avoided second system syndrome and produced
a more elegant design.What was surprising is how un-cloudy DynamoDB appears to
be. The cloud pillars of pay for what you use and quick elastic response to
bursty traffic have been abandoned, for some understandable reasons, but the
result is you really have to consider your use cases before making DynamoDB
the default choice.Here are some of my impressions from the talk...DynamoDB is
a clean well lighted place for key-value data. The interface is simple,
co</p><p>5 0.74069673 <a title="1211-lsi-5" href="../high_scalability-2014/high_scalability-2014-01-14-Ask_HS%3A_Design_and_Implementation_of_scalable_services%3F.html">1578 high scalability-2014-01-14-Ask HS: Design and Implementation of scalable services?</a></p>
<p>Introduction: We have written agents deployed/distributed across the network. Agents sends
data every 15 Secs may be even 5 secs. Working on a service/system to which
all agent can post data/tuples with marginal payload. Upto 5% drop rate is
acceptable. Ultimately the data will be segregated and stored into DBMS System
(currently we are using MSQL).Question(s) I am looking for answer1.
Client/Server Communication: Agent(s) can post data. Status of sending data is
not that important. But there is a remote where Agent(s) to be notified if the
server side system generates an event based on the data sent.- Lot of advices
from internet suggests using Message Bus (ActiveMQ) for async communication.
Multicast and UDP are the alternatives.2. Persistence: After some evaluation
data to be stored in DBMS System.- End of processing data is an aggregated
record for which MySql looks scalable. But on the volume of data is
exponential. Considering HBase as an option.Looking if there are any
alternatives for above</p><p>6 0.73880559 <a title="1211-lsi-6" href="../high_scalability-2012/high_scalability-2012-01-24-The_State_of_NoSQL_in_2012.html">1180 high scalability-2012-01-24-The State of NoSQL in 2012</a></p>
<p>7 0.73114055 <a title="1211-lsi-7" href="../high_scalability-2012/high_scalability-2012-11-30-Stuff_The_Internet_Says_On_Scalability_For_November_30%2C_2012.html">1365 high scalability-2012-11-30-Stuff The Internet Says On Scalability For November 30, 2012</a></p>
<p>8 0.729976 <a title="1211-lsi-8" href="../high_scalability-2010/high_scalability-2010-04-13-Strategy%3A_Saving_Your_Butt_With_Deferred_Deletes.html">809 high scalability-2010-04-13-Strategy: Saving Your Butt With Deferred Deletes</a></p>
<p>9 0.7199294 <a title="1211-lsi-9" href="../high_scalability-2014/high_scalability-2014-03-24-Big%2C_Small%2C_Hot_or_Cold_-_Examples_of_Robust_Data_Pipelines_from_Stripe%2C_Tapad%2C_Etsy_and_Square.html">1618 high scalability-2014-03-24-Big, Small, Hot or Cold - Examples of Robust Data Pipelines from Stripe, Tapad, Etsy and Square</a></p>
<p>10 0.71897465 <a title="1211-lsi-10" href="../high_scalability-2012/high_scalability-2012-07-27-Stuff_The_Internet_Says_On_Scalability_For_July_27%2C_2012.html">1292 high scalability-2012-07-27-Stuff The Internet Says On Scalability For July 27, 2012</a></p>
<p>11 0.71850604 <a title="1211-lsi-11" href="../high_scalability-2011/high_scalability-2011-11-11-Stuff_The_Internet_Says_On_Scalability_For_November_11%2C_2011.html">1141 high scalability-2011-11-11-Stuff The Internet Says On Scalability For November 11, 2011</a></p>
<p>12 0.71770149 <a title="1211-lsi-12" href="../high_scalability-2008/high_scalability-2008-12-17-Ringo_-_Distributed_key-value_storage_for_immutable_data.html">468 high scalability-2008-12-17-Ringo - Distributed key-value storage for immutable data</a></p>
<p>13 0.71692848 <a title="1211-lsi-13" href="../high_scalability-2011/high_scalability-2011-12-22-Architecting_Massively-Scalable_Near-Real-Time_Risk_Analysis_Solutions.html">1161 high scalability-2011-12-22-Architecting Massively-Scalable Near-Real-Time Risk Analysis Solutions</a></p>
<p>14 0.71224546 <a title="1211-lsi-14" href="../high_scalability-2011/high_scalability-2011-08-04-Jim_Starkey_is_Creating_a_Brave_New_World_by_Rethinking_Databases_for_the_Cloud.html">1092 high scalability-2011-08-04-Jim Starkey is Creating a Brave New World by Rethinking Databases for the Cloud</a></p>
<p>15 0.7106474 <a title="1211-lsi-15" href="../high_scalability-2013/high_scalability-2013-10-08-F1_and_Spanner_Holistically_Compared.html">1529 high scalability-2013-10-08-F1 and Spanner Holistically Compared</a></p>
<p>16 0.70964253 <a title="1211-lsi-16" href="../high_scalability-2012/high_scalability-2012-11-26-BigData_using_Erlang%2C_C_and_Lisp_to_Fight_the_Tsunami_of_Mobile_Data.html">1362 high scalability-2012-11-26-BigData using Erlang, C and Lisp to Fight the Tsunami of Mobile Data</a></p>
<p>17 0.70636845 <a title="1211-lsi-17" href="../high_scalability-2011/high_scalability-2011-04-06-Netflix%3A_Run_Consistency_Checkers_All_the_time_to_Fixup_Transactions.html">1017 high scalability-2011-04-06-Netflix: Run Consistency Checkers All the time to Fixup Transactions</a></p>
<p>18 0.70444357 <a title="1211-lsi-18" href="../high_scalability-2011/high_scalability-2011-06-20-35%2B_Use_Cases_for_Choosing_Your_Next_NoSQL_Database.html">1064 high scalability-2011-06-20-35+ Use Cases for Choosing Your Next NoSQL Database</a></p>
<p>19 0.70352143 <a title="1211-lsi-19" href="../high_scalability-2013/high_scalability-2013-12-02-Evolution_of_Bazaarvoice%E2%80%99s_Architecture_to_500M_Unique_Users_Per_Month.html">1557 high scalability-2013-12-02-Evolution of Bazaarvoice’s Architecture to 500M Unique Users Per Month</a></p>
<p>20 0.70309633 <a title="1211-lsi-20" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.151), (2, 0.142), (10, 0.057), (27, 0.011), (30, 0.016), (57, 0.263), (61, 0.076), (73, 0.011), (77, 0.016), (79, 0.075), (85, 0.032), (91, 0.011), (94, 0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.93697661 <a title="1211-lda-1" href="../high_scalability-2007/high_scalability-2007-11-18-Reverse_Proxy.html">159 high scalability-2007-11-18-Reverse Proxy</a></p>
<p>Introduction: Hi,I saw an year ago that Netapp sold netcache to blu-coat, my site is a heavy
NetCache user and we cached 83% of our site. We tested with Blue-coat and F5
WA and we are not getting same performce as NetCache.Any of you guys have the
same issue? or somebody knows another product can handle much
traffic?ThanksRodrigo</p><p>2 0.88630944 <a title="1211-lda-2" href="../high_scalability-2011/high_scalability-2011-11-17-Five_Misconceptions_on_Cloud_Portability.html">1144 high scalability-2011-11-17-Five Misconceptions on Cloud Portability</a></p>
<p>Introduction: The term "cloud portability" is often considered a synonym for
"CloudAPIportability," which implies a series of misconceptions.If we break
away from dogma, we can find that what we really looking for in cloud
portability is Application portability between clouds which can be a vastly
simpler requirement, as we can achieve application portability without
settling on a common CloudAPI.In this post i'll be covering five common
misconceptions people haveWRTto cloud portability.Cloud portability = Cloud
API portability. API portability is easy; cloud API portability is not.The
main incentive for Cloud Portability is - Avoiding Vendor lock-in.Cloud
portability is more about business agility than it is about vendor lock-
in.Cloud portability isn't for startups. Every startup that is expecting rapid
growth should re-examine their deployments and plan for cloud portability
rather than wait to be forced to make the switch when you are least prepared
to do so.Cloud portability = Compromising on t</p><p>3 0.85818619 <a title="1211-lda-3" href="../high_scalability-2011/high_scalability-2011-01-04-Map-Reduce_With_Ruby_Using_Hadoop.html">968 high scalability-2011-01-04-Map-Reduce With Ruby Using Hadoop</a></p>
<p>Introduction: A demonstration, with repeatable steps, of how to quickly fire-up a Hadoop
cluster on Amazon EC2, load data onto the HDFS (Hadoop Distributed File-
System), write map-reduce scripts in Ruby and use them to run a map-reduce job
on your Hadoop cluster. You willnotneed to ssh into the cluster, as all tasks
are run from your local machine. Below I am using my MacBook Pro as my local
machine, but the steps I have provided should be reproducible on other
platforms running bash and Java.Fire-Up Your Hadoop ClusterI choose
theCloudera distribution of Hadoopwhich is still 100% Apache licensed, but has
some additional benefits. One of these benefits is that it is released byDoug
Cutting, who started Hadoop and drove it’s development at Yahoo! He also
startedLucene, which is another of my favourite Apache Projects, so I have
good faith that he knows what he is doing. Another benefit, as you will see,
is that it is simple to fire-up a Hadoop cluster.I am going to use
Cloudera’sWhirr script, which</p><p>4 0.84738821 <a title="1211-lda-4" href="../high_scalability-2008/high_scalability-2008-10-29-CTL_-_Distributed_Control_Dispatching_Framework_.html">433 high scalability-2008-10-29-CTL - Distributed Control Dispatching Framework </a></p>
<p>Introduction: CTLis aflexible distributed control dispatching framework that enables you to
break management processes into reusable control modules and execute them in
distributed fashion over the network.From their website:CTL is a flexible
distributed control dispatching framework that enables you to break management
processes into reusable control modules and execute them in distributed
fashion over the network.What does CTL do?CTL helps you leverage your current
scripts and tools to easily automate any kind of distributed systems
management or application provisioning task. Its good for simplifiying large-
scale scripting efforts or as another tool in your toolbox that helps you
speed through your daily mix of ad-hoc administration tasks.What are CTL's
features?CTL has many features, but the general highlights are:* Execute
sophisticated procedures in distributed environments - Aren't you tired of
writing and then endlessly modifying scripts that loop over nodes and invoke
remote actions? CTL d</p><p>same-blog 5 0.8417232 <a title="1211-lda-5" href="../high_scalability-2012/high_scalability-2012-03-19-LinkedIn%3A_Creating_a_Low_Latency_Change_Data_Capture_System_with_Databus.html">1211 high scalability-2012-03-19-LinkedIn: Creating a Low Latency Change Data Capture System with Databus</a></p>
<p>Introduction: This is a guest post bySiddharth Anand, a senior member of LinkedIn's
Distributed Data Systems team.Over the past 3 years, I've had the good fortune
to work with many emerging NoSQL products in the context of supporting the
needs of a high-traffic, customer facing web site.In 2010, I helped Netflix to
successfullytransition its web scale use-cases from Oracle to SimpleDB, AWS'
hosted database service. On completion of that migration, we started a second
migration, this time from SimpleDB to Cassandra. The first transition was key
to our move from our own data center to AWS' cloud. The second was key to our
expansion from one AWS Region to multiple geographically-distributed Regions
-- today Netflix serves traffic out of two AWS Regions, one in Virginia, the
other in Ireland (F1). Both of these transitions have been successful, but
have involved integration pain points such as the creation of database
replication technology.In December 2011, I moved to LinkedIn's Distributed
Data System</p><p>6 0.8335197 <a title="1211-lda-6" href="../high_scalability-2010/high_scalability-2010-04-09-Vagrant_-_Build_and_Deploy_Virtualized_Development_Environments_Using_Ruby.html">807 high scalability-2010-04-09-Vagrant - Build and Deploy Virtualized Development Environments Using Ruby</a></p>
<p>7 0.83307666 <a title="1211-lda-7" href="../high_scalability-2009/high_scalability-2009-10-28-Need_for_change_in_your_IT_infrastructure_.html">731 high scalability-2009-10-28-Need for change in your IT infrastructure </a></p>
<p>8 0.78164166 <a title="1211-lda-8" href="../high_scalability-2011/high_scalability-2011-11-07-10_Core_Architecture_Pattern_Variations_for_Achieving_Scalability.html">1138 high scalability-2011-11-07-10 Core Architecture Pattern Variations for Achieving Scalability</a></p>
<p>9 0.77999532 <a title="1211-lda-9" href="../high_scalability-2009/high_scalability-2009-04-03-Collectl_interface_to_Ganglia_-_any_interest%3F.html">553 high scalability-2009-04-03-Collectl interface to Ganglia - any interest?</a></p>
<p>10 0.76153833 <a title="1211-lda-10" href="../high_scalability-2008/high_scalability-2008-01-17-Moving_old_to_new._Do_not_be_afraid_of_the_re-write_--_but_take_some_help.html">218 high scalability-2008-01-17-Moving old to new. Do not be afraid of the re-write -- but take some help</a></p>
<p>11 0.75165606 <a title="1211-lda-11" href="../high_scalability-2007/high_scalability-2007-07-11-Friendster_Architecture.html">6 high scalability-2007-07-11-Friendster Architecture</a></p>
<p>12 0.74906617 <a title="1211-lda-12" href="../high_scalability-2010/high_scalability-2010-07-11-So%2C_Why_is_Twitter_Really_Not_Using_Cassandra_to_Store_Tweets%3F.html">855 high scalability-2010-07-11-So, Why is Twitter Really Not Using Cassandra to Store Tweets?</a></p>
<p>13 0.73708415 <a title="1211-lda-13" href="../high_scalability-2008/high_scalability-2008-01-29-When_things_aren%27t_scalable.html">232 high scalability-2008-01-29-When things aren't scalable</a></p>
<p>14 0.7282663 <a title="1211-lda-14" href="../high_scalability-2011/high_scalability-2011-01-11-Google_Megastore_-_3_Billion_Writes_and_20_Billion_Read_Transactions_Daily.html">972 high scalability-2011-01-11-Google Megastore - 3 Billion Writes and 20 Billion Read Transactions Daily</a></p>
<p>15 0.70987767 <a title="1211-lda-15" href="../high_scalability-2008/high_scalability-2008-07-16-The_Mother_of_All_Database_Normalization_Debates_on_Coding_Horror.html">351 high scalability-2008-07-16-The Mother of All Database Normalization Debates on Coding Horror</a></p>
<p>16 0.70880437 <a title="1211-lda-16" href="../high_scalability-2010/high_scalability-2010-07-13-DbShards_Part_Deux_-_The_Internals.html">857 high scalability-2010-07-13-DbShards Part Deux - The Internals</a></p>
<p>17 0.69550449 <a title="1211-lda-17" href="../high_scalability-2011/high_scalability-2011-03-14-6_Lessons_from_Dropbox_-_One_Million_Files_Saved_Every_15_minutes.html">1003 high scalability-2011-03-14-6 Lessons from Dropbox - One Million Files Saved Every 15 minutes</a></p>
<p>18 0.69412434 <a title="1211-lda-18" href="../high_scalability-2013/high_scalability-2013-01-11-Stuff_The_Internet_Says_On_Scalability_For_January_11%2C_2013.html">1385 high scalability-2013-01-11-Stuff The Internet Says On Scalability For January 11, 2013</a></p>
<p>19 0.69206345 <a title="1211-lda-19" href="../high_scalability-2009/high_scalability-2009-08-31-Squarespace_Architecture_-_A_Grid_Handles_Hundreds_of_Millions_of_Requests_a_Month_.html">691 high scalability-2009-08-31-Squarespace Architecture - A Grid Handles Hundreds of Millions of Requests a Month </a></p>
<p>20 0.69023299 <a title="1211-lda-20" href="../high_scalability-2011/high_scalability-2011-07-26-Web_2.0_Killed_the_Middleware_Star.html">1087 high scalability-2011-07-26-Web 2.0 Killed the Middleware Star</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
