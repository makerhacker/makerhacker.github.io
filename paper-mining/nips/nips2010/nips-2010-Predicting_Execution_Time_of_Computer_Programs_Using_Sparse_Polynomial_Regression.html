<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>211 nips-2010-Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2010" href="../home/nips2010_home.html">nips2010</a> <a title="nips-2010-211" href="#">nips2010-211</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>211 nips-2010-Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression</h1>
<br/><p>Source: <a title="nips-2010-211-pdf" href="http://papers.nips.cc/paper/4145-predicting-execution-time-of-computer-programs-using-sparse-polynomial-regression.pdf">pdf</a></p><p>Author: Ling Huang, Jinzhu Jia, Bin Yu, Byung-gon Chun, Petros Maniatis, Mayur Naik</p><p>Abstract: Predicting the execution time of computer programs is an important but challenging problem in the community of computer systems. Existing methods require experts to perform detailed analysis of program code in order to construct predictors or select important features. We recently developed a new system to automatically extract a large number of features from program execution on sample inputs, on which prediction models can be constructed without expert knowledge. In this paper we study the construction of predictive models for this problem. We propose the SPORE (Sparse POlynomial REgression) methodology to build accurate prediction models of program performance using feature data collected from program execution on sample inputs. Our two SPORE algorithms are able to build relationships between responses (e.g., the execution time of a computer program) and features, and select a few from hundreds of the retrieved features to construct an explicitly sparse and non-linear model to predict the response variable. The compact and explicitly polynomial form of the estimated model could reveal important insights into the computer program (e.g., features and their non-linear combinations that dominate the execution time), enabling a better understanding of the program’s behavior. Our evaluation on three widely used computer programs shows that SPORE methods can give accurate prediction with relative error less than 7% by using a moderate number of training data samples. In addition, we compare SPORE algorithms to state-of-the-art sparse regression algorithms, and show that SPORE methods, motivated by real applications, outperform the other methods in terms of both interpretability and prediction accuracy.</p><p>Reference: <a title="nips-2010-211-reference" href="../nips2010_reference/nips-2010-Predicting_Execution_Time_of_Computer_Programs_Using_Sparse_Polynomial_Regression_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('spor', 0.555), ('execut', 0.425), ('fob', 0.327), ('lasso', 0.236), ('polynom', 0.229), ('program', 0.197), ('xnew', 0.153), ('xs', 0.137), ('feat', 0.128), ('predict', 0.122), ('spars', 0.093), ('expand', 0.088), ('expert', 0.082), ('afr', 0.077), ('luc', 0.075), ('regress', 0.07), ('images', 0.065), ('sesh', 0.065), ('methodolog', 0.059), ('spam', 0.055)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="211-tfidf-1" href="./nips-2010-Predicting_Execution_Time_of_Computer_Programs_Using_Sparse_Polynomial_Regression.html">211 nips-2010-Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression</a></p>
<p>2 0.13567406 <a title="211-tfidf-2" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>3 0.11486816 <a title="211-tfidf-3" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>4 0.11279199 <a title="211-tfidf-4" href="./nips-2010-Static_Analysis_of_Binary_Executables_Using_Structural_SVMs.html">255 nips-2010-Static Analysis of Binary Executables Using Structural SVMs</a></p>
<p>5 0.11125296 <a title="211-tfidf-5" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>6 0.10511136 <a title="211-tfidf-6" href="./nips-2010-Adaptive_Multi-Task_Lasso%3A_with_Application_to_eQTL_Detection.html">26 nips-2010-Adaptive Multi-Task Lasso: with Application to eQTL Detection</a></p>
<p>7 0.10296834 <a title="211-tfidf-7" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>8 0.087822899 <a title="211-tfidf-8" href="./nips-2010-Multi-Stage_Dantzig_Selector.html">172 nips-2010-Multi-Stage Dantzig Selector</a></p>
<p>9 0.086293593 <a title="211-tfidf-9" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>10 0.085824482 <a title="211-tfidf-10" href="./nips-2010-Moreau-Yosida_Regularization_for_Grouped_Tree_Structure_Learning.html">170 nips-2010-Moreau-Yosida Regularization for Grouped Tree Structure Learning</a></p>
<p>11 0.08372391 <a title="211-tfidf-11" href="./nips-2010-Feature_Set_Embedding_for_Incomplete_Data.html">94 nips-2010-Feature Set Embedding for Incomplete Data</a></p>
<p>12 0.073050566 <a title="211-tfidf-12" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>13 0.069361635 <a title="211-tfidf-13" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<p>14 0.067722403 <a title="211-tfidf-14" href="./nips-2010-Fast_detection_of_multiple_change-points_shared_by_many_signals_using_group_LARS.html">91 nips-2010-Fast detection of multiple change-points shared by many signals using group LARS</a></p>
<p>15 0.064195186 <a title="211-tfidf-15" href="./nips-2010-Learning_Networks_of_Stochastic_Differential_Equations.html">148 nips-2010-Learning Networks of Stochastic Differential Equations</a></p>
<p>16 0.062534519 <a title="211-tfidf-16" href="./nips-2010-Active_Learning_by_Querying_Informative_and_Representative_Examples.html">25 nips-2010-Active Learning by Querying Informative and Representative Examples</a></p>
<p>17 0.061813224 <a title="211-tfidf-17" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<p>18 0.05936639 <a title="211-tfidf-18" href="./nips-2010-Multivariate_Dyadic_Regression_Trees_for_Sparse_Learning_Problems.html">178 nips-2010-Multivariate Dyadic Regression Trees for Sparse Learning Problems</a></p>
<p>19 0.05807649 <a title="211-tfidf-19" href="./nips-2010-Extended_Bayesian_Information_Criteria_for_Gaussian_Graphical_Models.html">87 nips-2010-Extended Bayesian Information Criteria for Gaussian Graphical Models</a></p>
<p>20 0.057374574 <a title="211-tfidf-20" href="./nips-2010-Learning_Convolutional_Feature_Hierarchies_for_Visual_Recognition.html">143 nips-2010-Learning Convolutional Feature Hierarchies for Visual Recognition</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2010_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.192), (1, -0.026), (2, 0.029), (3, -0.037), (4, 0.055), (5, 0.093), (6, 0.104), (7, 0.013), (8, -0.067), (9, -0.077), (10, 0.023), (11, -0.03), (12, -0.06), (13, -0.02), (14, 0.119), (15, -0.073), (16, -0.007), (17, 0.014), (18, -0.003), (19, 0.01), (20, 0.123), (21, 0.083), (22, -0.046), (23, -0.009), (24, -0.044), (25, -0.026), (26, 0.023), (27, -0.062), (28, -0.001), (29, 0.004), (30, 0.022), (31, 0.069), (32, 0.065), (33, 0.093), (34, -0.071), (35, -0.135), (36, -0.016), (37, 0.101), (38, -0.027), (39, 0.015), (40, 0.003), (41, -0.003), (42, 0.005), (43, 0.043), (44, -0.032), (45, -0.086), (46, -0.047), (47, 0.069), (48, 0.051), (49, 0.059)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.91183549 <a title="211-lsi-1" href="./nips-2010-Predicting_Execution_Time_of_Computer_Programs_Using_Sparse_Polynomial_Regression.html">211 nips-2010-Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression</a></p>
<p>2 0.80629551 <a title="211-lsi-2" href="./nips-2010-Adaptive_Multi-Task_Lasso%3A_with_Application_to_eQTL_Detection.html">26 nips-2010-Adaptive Multi-Task Lasso: with Application to eQTL Detection</a></p>
<p>3 0.77263218 <a title="211-lsi-3" href="./nips-2010-A_Dirty_Model_for_Multi-task_Learning.html">5 nips-2010-A Dirty Model for Multi-task Learning</a></p>
<p>4 0.76293707 <a title="211-lsi-4" href="./nips-2010-Multi-Stage_Dantzig_Selector.html">172 nips-2010-Multi-Stage Dantzig Selector</a></p>
<p>5 0.73705482 <a title="211-lsi-5" href="./nips-2010-Sufficient_Conditions_for_Generating_Group_Level_Sparsity_in_a_Robust_Minimax_Framework.html">260 nips-2010-Sufficient Conditions for Generating Group Level Sparsity in a Robust Minimax Framework</a></p>
<p>6 0.72553772 <a title="211-lsi-6" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>7 0.61452687 <a title="211-lsi-7" href="./nips-2010-Efficient_and_Robust_Feature_Selection_via_Joint_%E2%84%932%2C1-Norms_Minimization.html">73 nips-2010-Efficient and Robust Feature Selection via Joint ℓ2,1-Norms Minimization</a></p>
<p>8 0.58348942 <a title="211-lsi-8" href="./nips-2010-A_Primal-Dual_Algorithm_for_Group_Sparse_Regularization_with_Overlapping_Groups.html">12 nips-2010-A Primal-Dual Algorithm for Group Sparse Regularization with Overlapping Groups</a></p>
<p>9 0.56991911 <a title="211-lsi-9" href="./nips-2010-Predictive_State_Temporal_Difference_Learning.html">212 nips-2010-Predictive State Temporal Difference Learning</a></p>
<p>10 0.5682649 <a title="211-lsi-10" href="./nips-2010-The_LASSO_risk%3A_asymptotic_results_and_real_world_examples.html">265 nips-2010-The LASSO risk: asymptotic results and real world examples</a></p>
<p>11 0.54950774 <a title="211-lsi-11" href="./nips-2010-Learning_Efficient_Markov_Networks.html">144 nips-2010-Learning Efficient Markov Networks</a></p>
<p>12 0.53318501 <a title="211-lsi-12" href="./nips-2010-Lifted_Inference_Seen_from_the_Other_Side_%3A_The_Tractable_Features.html">159 nips-2010-Lifted Inference Seen from the Other Side : The Tractable Features</a></p>
<p>13 0.52487028 <a title="211-lsi-13" href="./nips-2010-Learning_sparse_dynamic_linear_systems_using_stable_spline_kernels_and_exponential_hyperpriors.html">154 nips-2010-Learning sparse dynamic linear systems using stable spline kernels and exponential hyperpriors</a></p>
<p>14 0.52031428 <a title="211-lsi-14" href="./nips-2010-Feature_Set_Embedding_for_Incomplete_Data.html">94 nips-2010-Feature Set Embedding for Incomplete Data</a></p>
<p>15 0.52006763 <a title="211-lsi-15" href="./nips-2010-Moreau-Yosida_Regularization_for_Grouped_Tree_Structure_Learning.html">170 nips-2010-Moreau-Yosida Regularization for Grouped Tree Structure Learning</a></p>
<p>16 0.51665294 <a title="211-lsi-16" href="./nips-2010-Energy_Disaggregation_via_Discriminative_Sparse_Coding.html">76 nips-2010-Energy Disaggregation via Discriminative Sparse Coding</a></p>
<p>17 0.51524389 <a title="211-lsi-17" href="./nips-2010-Variational_Inference_over_Combinatorial_Spaces.html">283 nips-2010-Variational Inference over Combinatorial Spaces</a></p>
<p>18 0.50593358 <a title="211-lsi-18" href="./nips-2010-Probabilistic_Multi-Task_Feature_Selection.html">217 nips-2010-Probabilistic Multi-Task Feature Selection</a></p>
<p>19 0.50099832 <a title="211-lsi-19" href="./nips-2010-Efficient_Relational_Learning_with_Hidden_Variable_Detection.html">71 nips-2010-Efficient Relational Learning with Hidden Variable Detection</a></p>
<p>20 0.49510863 <a title="211-lsi-20" href="./nips-2010-Scrambled_Objects_for_Least-Squares_Regression.html">233 nips-2010-Scrambled Objects for Least-Squares Regression</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2010_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(7, 0.087), (30, 0.053), (32, 0.129), (34, 0.167), (45, 0.108), (68, 0.137), (85, 0.214)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.85197783 <a title="211-lda-1" href="./nips-2010-Multitask_Learning_without_Label_Correspondences.html">177 nips-2010-Multitask Learning without Label Correspondences</a></p>
<p>same-paper 2 0.84446317 <a title="211-lda-2" href="./nips-2010-Predicting_Execution_Time_of_Computer_Programs_Using_Sparse_Polynomial_Regression.html">211 nips-2010-Predicting Execution Time of Computer Programs Using Sparse Polynomial Regression</a></p>
<p>3 0.83462745 <a title="211-lda-3" href="./nips-2010-Learning_from_Candidate_Labeling_Sets.html">151 nips-2010-Learning from Candidate Labeling Sets</a></p>
<p>4 0.82311606 <a title="211-lda-4" href="./nips-2010-Relaxed_Clipping%3A_A_Global_Training_Method_for_Robust_Regression_and_Classification.html">225 nips-2010-Relaxed Clipping: A Global Training Method for Robust Regression and Classification</a></p>
<p>5 0.79934031 <a title="211-lda-5" href="./nips-2010-A_Primal-Dual_Message-Passing_Algorithm_for_Approximated_Large_Scale_Structured_Prediction.html">13 nips-2010-A Primal-Dual Message-Passing Algorithm for Approximated Large Scale Structured Prediction</a></p>
<p>6 0.7926386 <a title="211-lda-6" href="./nips-2010-Moreau-Yosida_Regularization_for_Grouped_Tree_Structure_Learning.html">170 nips-2010-Moreau-Yosida Regularization for Grouped Tree Structure Learning</a></p>
<p>7 0.79206926 <a title="211-lda-7" href="./nips-2010-Structured_sparsity-inducing_norms_through_submodular_functions.html">258 nips-2010-Structured sparsity-inducing norms through submodular functions</a></p>
<p>8 0.79197717 <a title="211-lda-8" href="./nips-2010-New_Adaptive_Algorithms_for_Online_Classification.html">182 nips-2010-New Adaptive Algorithms for Online Classification</a></p>
<p>9 0.79190856 <a title="211-lda-9" href="./nips-2010-A_Theory_of_Multiclass_Boosting.html">15 nips-2010-A Theory of Multiclass Boosting</a></p>
<p>10 0.78826666 <a title="211-lda-10" href="./nips-2010-A_Family_of_Penalty_Functions_for_Structured_Sparsity.html">7 nips-2010-A Family of Penalty Functions for Structured Sparsity</a></p>
<p>11 0.78741407 <a title="211-lda-11" href="./nips-2010-Efficient_Optimization_for_Discriminative_Latent_Class_Models.html">70 nips-2010-Efficient Optimization for Discriminative Latent Class Models</a></p>
<p>12 0.7870006 <a title="211-lda-12" href="./nips-2010-Efficient_Minimization_of_Decomposable_Submodular_Functions.html">69 nips-2010-Efficient Minimization of Decomposable Submodular Functions</a></p>
<p>13 0.78659296 <a title="211-lda-13" href="./nips-2010-Segmentation_as_Maximum-Weight_Independent_Set.html">234 nips-2010-Segmentation as Maximum-Weight Independent Set</a></p>
<p>14 0.7864666 <a title="211-lda-14" href="./nips-2010-t-logistic_regression.html">290 nips-2010-t-logistic regression</a></p>
<p>15 0.7847665 <a title="211-lda-15" href="./nips-2010-Bayesian_Action-Graph_Games.html">39 nips-2010-Bayesian Action-Graph Games</a></p>
<p>16 0.78384656 <a title="211-lda-16" href="./nips-2010-Self-Paced_Learning_for_Latent_Variable_Models.html">235 nips-2010-Self-Paced Learning for Latent Variable Models</a></p>
<p>17 0.78292233 <a title="211-lda-17" href="./nips-2010-Avoiding_False_Positive_in_Multi-Instance_Learning.html">36 nips-2010-Avoiding False Positive in Multi-Instance Learning</a></p>
<p>18 0.78120273 <a title="211-lda-18" href="./nips-2010-Non-Stochastic_Bandit_Slate_Problems.html">183 nips-2010-Non-Stochastic Bandit Slate Problems</a></p>
<p>19 0.77868795 <a title="211-lda-19" href="./nips-2010-Multiple_Kernel_Learning_and_the_SMO_Algorithm.html">176 nips-2010-Multiple Kernel Learning and the SMO Algorithm</a></p>
<p>20 0.77801996 <a title="211-lda-20" href="./nips-2010-Fast_global_convergence_rates_of_gradient_methods_for_high-dimensional_statistical_recovery.html">92 nips-2010-Fast global convergence rates of gradient methods for high-dimensional statistical recovery</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
