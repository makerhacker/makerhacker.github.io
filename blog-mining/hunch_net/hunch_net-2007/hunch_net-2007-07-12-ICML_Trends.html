<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>254 hunch net-2007-07-12-ICML Trends</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-254" href="#">hunch_net-2007-254</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>254 hunch net-2007-07-12-ICML Trends</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-254-html" href="http://hunch.net/?p=281">html</a></p><p>Introduction: Mark Reiddid a post onICML trendsthat I found interesting.</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 Mark Reiddid a post onICML trendsthat I found interesting. [sent-1, score-0.517]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('onicml', 0.667), ('mark', 0.618), ('post', 0.268), ('found', 0.249), ('interesting', 0.198)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="254-tfidf-1" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reiddid a post onICML trendsthat I found interesting.</p><p>2 0.32397366 <a title="254-tfidf-2" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reidhas stepped up and created acomment system for ICML paperswhichGreger
Lindenhas tightly integrated.My understanding is that Mark spent quite a bit
of time on the details, and there are some cool features like working latex
math mode. This is an excellent chance for the ICML community to experiment
with making ICML year-round, so I hope it works out. Please do consider
experimenting with it.</p><p>3 0.16926189 <a title="254-tfidf-3" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>Introduction: Mark Reidhas setup adiscussion site for ICML papersagain this year andMonica
Dinculescuhas linked it in from the ICML site. Last year's attempt appears to
have been an acceptable but not wild success as a little bit of fruitful
discussion occurred. I'm hoping this year will be a bit more of a success--
please don't be shyI'd like to also point out thatICML's
earlyregistrationdeadline has a few hours left, whileUAI's andCOLT's are in a
week.</p><p>4 0.090112761 <a title="254-tfidf-4" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point toMichael Nielsen's talkabout blogging science, which I
found interesting.</p><p>5 0.084106848 <a title="254-tfidf-5" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>Introduction: Everyone should have received notice forNY ML Symposiumabstracts. Check
carefully, as one was lost by our system.The event itself is October 21, next
week.Leon Bottou,Stephen Boyd, andYoav Freundare giving the invited talks this
year, and there are many spotlights on local work spread throughout the
day.Chris Wigginshas setup 6(!) ML-interested startups to follow the
symposium, which should be of substantial interest to the employment
interested.I also wanted to give an update onICML 2012. Unlike last year, our
deadline is coordinated withAIStat(which is due this Friday). The paper
deadline for ICML has been pushed back to February 24 which should allow
significant time for finishing up papers after the winter break. Other details
may interest people as well:We settled on usingCMTafter checking out the
possibilities. I wasn't looking for this, because I've often found CMT clunky
in terms of easy access to the right information. Nevertheless, the breadth of
features and willingness to s</p><p>6 0.075575255 <a title="254-tfidf-6" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>7 0.072814055 <a title="254-tfidf-7" href="../hunch_net-2007/hunch_net-2007-01-02-Retrospective.html">225 hunch net-2007-01-02-Retrospective</a></p>
<p>8 0.060780153 <a title="254-tfidf-8" href="../hunch_net-2012/hunch_net-2012-07-09-Videolectures.html">469 hunch net-2012-07-09-Videolectures</a></p>
<p>9 0.053905714 <a title="254-tfidf-9" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>10 0.043826666 <a title="254-tfidf-10" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>11 0.039416526 <a title="254-tfidf-11" href="../hunch_net-2009/hunch_net-2009-12-09-Inherent_Uncertainty.html">383 hunch net-2009-12-09-Inherent Uncertainty</a></p>
<p>12 0.039143346 <a title="254-tfidf-12" href="../hunch_net-2007/hunch_net-2007-02-22-Create_Your_Own_ICML_Workshop.html">234 hunch net-2007-02-22-Create Your Own ICML Workshop</a></p>
<p>13 0.038712315 <a title="254-tfidf-13" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>14 0.03790845 <a title="254-tfidf-14" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>15 0.035182405 <a title="254-tfidf-15" href="../hunch_net-2005/hunch_net-2005-07-21-Six_Months.html">96 hunch net-2005-07-21-Six Months</a></p>
<p>16 0.033779204 <a title="254-tfidf-16" href="../hunch_net-2005/hunch_net-2005-04-06-Structured_Regret_Minimization.html">53 hunch net-2005-04-06-Structured Regret Minimization</a></p>
<p>17 0.03267369 <a title="254-tfidf-17" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>18 0.030703841 <a title="254-tfidf-18" href="../hunch_net-2005/hunch_net-2005-12-09-Some_NIPS_papers.html">138 hunch net-2005-12-09-Some NIPS papers</a></p>
<p>19 0.028882124 <a title="254-tfidf-19" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>20 0.028224882 <a title="254-tfidf-20" href="../hunch_net-2005/hunch_net-2005-06-28-A_COLT_paper.html">85 hunch net-2005-06-28-A COLT paper</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.032), (1, 0.026), (2, 0.011), (3, 0.038), (4, -0.011), (5, -0.019), (6, 0.033), (7, -0.099), (8, 0.075), (9, 0.014), (10, -0.01), (11, -0.011), (12, -0.025), (13, 0.046), (14, -0.001), (15, -0.057), (16, 0.171), (17, 0.039), (18, -0.014), (19, 0.134), (20, 0.095), (21, -0.063), (22, -0.082), (23, 0.01), (24, 0.001), (25, -0.104), (26, -0.037), (27, -0.008), (28, 0.039), (29, 0.022), (30, 0.163), (31, 0.153), (32, -0.151), (33, 0.047), (34, 0.073), (35, -0.062), (36, -0.019), (37, -0.041), (38, 0.041), (39, -0.059), (40, 0.058), (41, -0.03), (42, -0.007), (43, -0.02), (44, 0.027), (45, -0.022), (46, -0.014), (47, 0.079), (48, -0.155), (49, 0.026)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97737366 <a title="254-lsi-1" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reiddid a post onICML trendsthat I found interesting.</p><p>2 0.79560459 <a title="254-lsi-2" href="../hunch_net-2008/hunch_net-2008-06-30-ICML_has_a_comment_system.html">305 hunch net-2008-06-30-ICML has a comment system</a></p>
<p>Introduction: Mark Reidhas stepped up and created acomment system for ICML paperswhichGreger
Lindenhas tightly integrated.My understanding is that Mark spent quite a bit
of time on the details, and there are some cool features like working latex
math mode. This is an excellent chance for the ICML community to experiment
with making ICML year-round, so I hope it works out. Please do consider
experimenting with it.</p><p>3 0.71816105 <a title="254-lsi-3" href="../hunch_net-2009/hunch_net-2009-05-24-2009_ICML_discussion_site.html">356 hunch net-2009-05-24-2009 ICML discussion site</a></p>
<p>Introduction: Mark Reidhas setup adiscussion site for ICML papersagain this year andMonica
Dinculescuhas linked it in from the ICML site. Last year's attempt appears to
have been an acceptable but not wild success as a little bit of fruitful
discussion occurred. I'm hoping this year will be a bit more of a success--
please don't be shyI'd like to also point out thatICML's
earlyregistrationdeadline has a few hours left, whileUAI's andCOLT's are in a
week.</p><p>4 0.54539692 <a title="254-lsi-4" href="../hunch_net-2009/hunch_net-2009-01-28-Nielsen%26%238217%3Bs_talk.html">340 hunch net-2009-01-28-Nielsen&#8217;s talk</a></p>
<p>Introduction: I wanted to point toMichael Nielsen's talkabout blogging science, which I
found interesting.</p><p>5 0.43221042 <a title="254-lsi-5" href="../hunch_net-2007/hunch_net-2007-06-13-Not_Posting.html">246 hunch net-2007-06-13-Not Posting</a></p>
<p>Introduction: If you have been disappointed by the lack of a post for the last month,
considercontributing your own(I've been busy+uninspired). Also, keep in mind
that there is a community of machine learning blogs (see the sidebar).</p><p>6 0.40388882 <a title="254-lsi-6" href="../hunch_net-2013/hunch_net-2013-07-24-ICML_2012_videos_lost.html">487 hunch net-2013-07-24-ICML 2012 videos lost</a></p>
<p>7 0.37561291 <a title="254-lsi-7" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>8 0.33360165 <a title="254-lsi-8" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>9 0.32905552 <a title="254-lsi-9" href="../hunch_net-2007/hunch_net-2007-12-20-Cool_and_Interesting_things_at_NIPS%2C_take_three.html">280 hunch net-2007-12-20-Cool and Interesting things at NIPS, take three</a></p>
<p>10 0.32491687 <a title="254-lsi-10" href="../hunch_net-2005/hunch_net-2005-03-08-Fast_Physics_for_Learning.html">37 hunch net-2005-03-08-Fast Physics for Learning</a></p>
<p>11 0.32012159 <a title="254-lsi-11" href="../hunch_net-2005/hunch_net-2005-12-14-More_NIPS_Papers_II.html">140 hunch net-2005-12-14-More NIPS Papers II</a></p>
<p>12 0.31080565 <a title="254-lsi-12" href="../hunch_net-2005/hunch_net-2005-12-28-Yet_more_nips_thoughts.html">144 hunch net-2005-12-28-Yet more nips thoughts</a></p>
<p>13 0.31019413 <a title="254-lsi-13" href="../hunch_net-2009/hunch_net-2009-05-17-Server_Update.html">354 hunch net-2009-05-17-Server Update</a></p>
<p>14 0.29930523 <a title="254-lsi-14" href="../hunch_net-2012/hunch_net-2012-08-27-NYAS_ML_2012_and_ICML_2013.html">472 hunch net-2012-08-27-NYAS ML 2012 and ICML 2013</a></p>
<p>15 0.27347404 <a title="254-lsi-15" href="../hunch_net-2007/hunch_net-2007-12-17-New_Machine_Learning_mailing_list.html">278 hunch net-2007-12-17-New Machine Learning mailing list</a></p>
<p>16 0.26888657 <a title="254-lsi-16" href="../hunch_net-2005/hunch_net-2005-10-03-Not_ICML.html">117 hunch net-2005-10-03-Not ICML</a></p>
<p>17 0.26254845 <a title="254-lsi-17" href="../hunch_net-2005/hunch_net-2005-05-29-Maximum_Margin_Mismatch%3F.html">77 hunch net-2005-05-29-Maximum Margin Mismatch?</a></p>
<p>18 0.23540576 <a title="254-lsi-18" href="../hunch_net-2005/hunch_net-2005-09-05-Site_Update.html">107 hunch net-2005-09-05-Site Update</a></p>
<p>19 0.23497957 <a title="254-lsi-19" href="../hunch_net-2006/hunch_net-2006-11-02-2006_NIPS_workshops.html">216 hunch net-2006-11-02-2006 NIPS workshops</a></p>
<p>20 0.23497392 <a title="254-lsi-20" href="../hunch_net-2005/hunch_net-2005-05-12-Math_on_the_Web.html">70 hunch net-2005-05-12-Math on the Web</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(54, 0.67)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.78779399 <a title="254-lda-1" href="../hunch_net-2007/hunch_net-2007-07-12-ICML_Trends.html">254 hunch net-2007-07-12-ICML Trends</a></p>
<p>Introduction: Mark Reiddid a post onICML trendsthat I found interesting.</p><p>2 0.77524614 <a title="254-lda-2" href="../hunch_net-2005/hunch_net-2005-01-26-Summer_Schools.html">4 hunch net-2005-01-26-Summer Schools</a></p>
<p>Introduction: There are several summer schools related to machine learning.We are running a
two weekmachine learning summer schoolin Chicago, USA May 16-27.IPAM is
running a more focused three week summer school onIntelligent Extraction of
Information from Graphs and High Dimensional Datain Los Angeles, USA July
11-29.A broad one-week school onanalysis of patternswill be held in Erice,
Italy, Oct. 28-Nov 6.</p><p>3 0.4363279 <a title="254-lda-3" href="../hunch_net-2006/hunch_net-2006-10-04-Health_of_Conferences_Wiki.html">212 hunch net-2006-10-04-Health of Conferences Wiki</a></p>
<p>Introduction: Aaron Hertzmannpoints out thehealth of conferences wiki, which has a great
deal of information about how many different conferences function.</p><p>4 0.37064776 <a title="254-lda-4" href="../hunch_net-2008/hunch_net-2008-07-15-Interesting_papers_at_COLT_%28and_a_bit_of_UAI_%26%23038%3B_workshops%29.html">310 hunch net-2008-07-15-Interesting papers at COLT (and a bit of UAI &#038; workshops)</a></p>
<p>Introduction: Here are a few papers fromCOLT 2008that I found interesting.Maria-Florina
Balcan,Steve Hanneke, andJenn Wortman,The True Sample Complexity of Active
Learning. This paper shows that in an asymptotic setting, active learning
isalwaysbetter than supervised learning (although the gap may be small). This
is evidence that the only thing in the way of universal active learning is us
knowing how to do it properly.Nir AilonandMehryar Mohri,An Efficient Reduction
of Ranking to Classification. This paper shows how to robustly ranknobjects
withn log(n)classifications using a quicksort based algorithm. The result is
applicable to many ranking loss functions and has implications for
others.Michael KearnsandJennifer Wortman.Learning from Collective Behavior.
This is about learning in a new model, where the goal is to predict how a
collection of interacting agents behave. One claim is that learning in this
setting can be reduced to IID learning.Due to the relation withMetric-E3, I
was particularly int</p><p>5 0.12543085 <a title="254-lda-5" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen ifâ€¦" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>6 0.0 <a title="254-lda-6" href="../hunch_net-2005/hunch_net-2005-01-19-Why_I_decided_to_run_a_weblog..html">1 hunch net-2005-01-19-Why I decided to run a weblog.</a></p>
<p>7 0.0 <a title="254-lda-7" href="../hunch_net-2005/hunch_net-2005-01-24-Holy_grails_of_machine_learning%3F.html">2 hunch net-2005-01-24-Holy grails of machine learning?</a></p>
<p>8 0.0 <a title="254-lda-8" href="../hunch_net-2005/hunch_net-2005-01-24-The_Humanloop_Spectrum_of_Machine_Learning.html">3 hunch net-2005-01-24-The Humanloop Spectrum of Machine Learning</a></p>
<p>9 0.0 <a title="254-lda-9" href="../hunch_net-2005/hunch_net-2005-01-26-Watchword%3A_Probability.html">5 hunch net-2005-01-26-Watchword: Probability</a></p>
<p>10 0.0 <a title="254-lda-10" href="../hunch_net-2005/hunch_net-2005-01-27-Learning_Complete_Problems.html">6 hunch net-2005-01-27-Learning Complete Problems</a></p>
<p>11 0.0 <a title="254-lda-11" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>12 0.0 <a title="254-lda-12" href="../hunch_net-2005/hunch_net-2005-02-01-NIPS%3A_Online_Bayes.html">8 hunch net-2005-02-01-NIPS: Online Bayes</a></p>
<p>13 0.0 <a title="254-lda-13" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>14 0.0 <a title="254-lda-14" href="../hunch_net-2005/hunch_net-2005-02-02-Kolmogorov_Complexity_and_Googling.html">10 hunch net-2005-02-02-Kolmogorov Complexity and Googling</a></p>
<p>15 0.0 <a title="254-lda-15" href="../hunch_net-2005/hunch_net-2005-02-02-Paper_Deadlines.html">11 hunch net-2005-02-02-Paper Deadlines</a></p>
<p>16 0.0 <a title="254-lda-16" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<p>17 0.0 <a title="254-lda-17" href="../hunch_net-2005/hunch_net-2005-02-04-JMLG.html">13 hunch net-2005-02-04-JMLG</a></p>
<p>18 0.0 <a title="254-lda-18" href="../hunch_net-2005/hunch_net-2005-02-07-The_State_of_the_Reduction.html">14 hunch net-2005-02-07-The State of the Reduction</a></p>
<p>19 0.0 <a title="254-lda-19" href="../hunch_net-2005/hunch_net-2005-02-08-Some_Links.html">15 hunch net-2005-02-08-Some Links</a></p>
<p>20 0.0 <a title="254-lda-20" href="../hunch_net-2005/hunch_net-2005-02-09-Intuitions_from_applied_learning.html">16 hunch net-2005-02-09-Intuitions from applied learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
