<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2009" href="../home/high_scalability-2009_home.html">high_scalability-2009</a> <a title="high_scalability-2009-587" href="#">high_scalability-2009-587</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2009-587-html" href="http://highscalability.com//blog/2009/5/1/fastbit-an-efficient-compressed-bitmap-index-technology.html">html</a></p><p>Introduction: Data mining and fast queries are always in that bin of hard to do things where
doing something smarter can yield big results. Bloom Filters are one such do
it smarter strategy, compressed bitmap indexes are another. In one application
"FastBit outruns other search indexes by a factor of 10 to 100 and doesn't
require much more room than the original data size." The data size is an
interesting metric. Our old standard b-trees can be two to four times larger
than the original data. In a test searching an Enron email database FastBit
outran MySQL by 10 to 1,000 times.FastBit is a software tool for searching
large read-only datasets. It organizes user data in a column-oriented
structure which is efficient for on-line analytical processing (OLAP), and
utilizes compressed bitmap indices to further speed up query processing.
Analyses have proven the compressed bitmap index used in FastBit to be
theoretically optimal for one-dimensional queries. Compared with other optimal
indexing methods, bit</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('fastbit', 0.672), ('bitmap', 0.421), ('compressed', 0.213), ('indices', 0.182), ('optimal', 0.147), ('smarter', 0.146), ('enron', 0.122), ('methods', 0.122), ('searching', 0.122), ('bin', 0.115), ('organizes', 0.105), ('digging', 0.102), ('original', 0.099), ('indexes', 0.096), ('compared', 0.093), ('utilizes', 0.091), ('theoretically', 0.089), ('analyses', 0.088), ('yield', 0.083), ('superior', 0.082)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="587-tfidf-1" href="../high_scalability-2009/high_scalability-2009-05-01-FastBit%3A_An_Efficient_Compressed_Bitmap_Index_Technology.html">587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</a></p>
<p>Introduction: Data mining and fast queries are always in that bin of hard to do things where
doing something smarter can yield big results. Bloom Filters are one such do
it smarter strategy, compressed bitmap indexes are another. In one application
"FastBit outruns other search indexes by a factor of 10 to 100 and doesn't
require much more room than the original data size." The data size is an
interesting metric. Our old standard b-trees can be two to four times larger
than the original data. In a test searching an Enron email database FastBit
outran MySQL by 10 to 1,000 times.FastBit is a software tool for searching
large read-only datasets. It organizes user data in a column-oriented
structure which is efficient for on-line analytical processing (OLAP), and
utilizes compressed bitmap indices to further speed up query processing.
Analyses have proven the compressed bitmap index used in FastBit to be
theoretically optimal for one-dimensional queries. Compared with other optimal
indexing methods, bit</p><p>2 0.10591967 <a title="587-tfidf-2" href="../high_scalability-2012/high_scalability-2012-04-05-Big_Data_Counting%3A_How_to_count_a_billion_distinct_objects_using_only_1.5KB_of_Memory.html">1222 high scalability-2012-04-05-Big Data Counting: How to count a billion distinct objects using only 1.5KB of Memory</a></p>
<p>Introduction: This is a guest post by Matt Abrams (@abramsm), from Clearspring, discussing
how they are able to accurately estimate the cardinality of sets with billions
of distinct elements using surprisingly small data structures. Their servers
receive well over 100 billion events per month.AtClearspringwe like to count
things. Counting the number of distinct elements (the cardinality) of a set is
challenge when the cardinality of the set is large.To better understand the
challenge of determining the cardinality of large sets let's imagine that you
have a 16 character ID and you'd like to count the number of distinct IDs that
you've seen in your logs. Here is an example:4f67bfc603106cb2These 16
characters represent 128 bits. 65K IDs would require 1 megabyte of space. We
receive over 3 billion events per day, and each event has an ID. Those IDs
require 384,000,000,000 bits or 45 gigabytes of storage. And that is just the
space that the ID field requires! To get the cardinality of IDs in our daily
e</p><p>3 0.077465586 <a title="587-tfidf-3" href="../high_scalability-2009/high_scalability-2009-05-05-Drop_ACID_and_Think_About_Data.html">589 high scalability-2009-05-05-Drop ACID and Think About Data</a></p>
<p>Introduction: The abstract for the talk given by Bob Ippolito, co-founder and CTO of Mochi
Media, Inc:Building large systems on top of a traditional single-master RDBMS
data storage layer is no longer good enough. This talk explores the landscape
of new technologies available today to augment your data layer to improve
performance and reliability. Is your application a good fit for caches, bloom
filters, bitmap indexes, column stores, distributed key/value stores, or
document databases? Learn how they work (in theory and practice) and decide
for yourself.Bob does an excellent job highlighting different products and the
key concepts to understand when pondering the wide variety of new database
offerings. It's unlikely you'll be able to say oh, this is the database for me
after watching the presentation, but you will be much better informed on your
options. And I imagine slightly confused as to what to do :-)An interesting
observation in the talk is that the more robust products are internal to large</p><p>4 0.074679092 <a title="587-tfidf-4" href="../high_scalability-2013/high_scalability-2013-09-09-Need_Help_with_Database_Scalability%3F_Understand_I-O.html">1514 high scalability-2013-09-09-Need Help with Database Scalability? Understand I-O</a></p>
<p>Introduction: This is a guest post byZardosht Kasheff, Software Developer atTokutek, a
storage engine company that delivers 21st-Century capabilities to the leading
open source data management platforms.As software developers, we value
abstraction. The simpler the API, the more attractive it becomes. Arguably,
MongoDB's greatest strengths are its elegant API and itsagility, which let
developers simply code.But whenMongoDBruns into scalability problems onbig
data, developers need to peek underneath the covers to understand the
underlying issues and how to fix them. Without understanding, one may end up
with an inefficient solution that costs time and money. For example, one may
shard prematurely, increasing hardware and management costs, when a simpler
replication setup would do. Or, one may increase the size of a replica set
when upgrading to SSDs would suffice.This article showshow to reason about
some big data scalability problemsin an effort to find efficient
solutions.Defining the IssuesFirst, l</p><p>5 0.073235795 <a title="587-tfidf-5" href="../high_scalability-2009/high_scalability-2009-04-16-Paper%3A_The_End_of_an_Architectural_Era_%28It%E2%80%99s_Time_for_a_Complete_Rewrite%29.html">572 high scalability-2009-04-16-Paper: The End of an Architectural Era (It’s Time for a Complete Rewrite)</a></p>
<p>Introduction: Update 3:A Comparison of Approaches to Large-Scale Data Analysis: MapReduce
vs. DBMS Benchmarks.Although the process to load data into and tune the
execution of parallel DBMSs took much longer than the MR system, the observed
performance of these DBMSs was strikingly better.Update 2:H-Store: A Next
Generation OLTP DBMSis the project implementing the ideas in this paper:The
goal of the H-Store project is to investigate how these architectural and
application shifts affect the performance of OLTP databases, and to study what
performance benefits would be possible with a complete redesign of OLTP
systems in light of these trends. Our early results show that a simple
prototype built from scratch using modern assumptions can outperform current
commercial DBMS offerings by around a factor of 80 on OLTP workloads.Update:
interesting related thread onLamda the Ultimate.A really fascinating paper
bolstering many of the anti-RDBMS threads the have popped up on the intertube
lately. The spirit of</p><p>6 0.069109276 <a title="587-tfidf-6" href="../high_scalability-2007/high_scalability-2007-08-10-How_do_we_make_a_large_real-time_search_engine%3F.html">64 high scalability-2007-08-10-How do we make a large real-time search engine?</a></p>
<p>7 0.062738262 <a title="587-tfidf-7" href="../high_scalability-2011/high_scalability-2011-12-05-Stuff_The_Internet_Says_On_Scalability_For_December_5%2C_2011.html">1151 high scalability-2011-12-05-Stuff The Internet Says On Scalability For December 5, 2011</a></p>
<p>8 0.054703284 <a title="587-tfidf-8" href="../high_scalability-2010/high_scalability-2010-04-06-Strategy%3A_Make_it_Really_Fast_vs_Do_the_Work_Up_Front.html">805 high scalability-2010-04-06-Strategy: Make it Really Fast vs Do the Work Up Front</a></p>
<p>9 0.053137708 <a title="587-tfidf-9" href="../high_scalability-2010/high_scalability-2010-03-30-Running_Large_Graph_Algorithms_-_Evaluation_of_Current_State-of-the-Art_and_Lessons_Learned.html">801 high scalability-2010-03-30-Running Large Graph Algorithms - Evaluation of Current State-of-the-Art and Lessons Learned</a></p>
<p>10 0.049675532 <a title="587-tfidf-10" href="../high_scalability-2010/high_scalability-2010-11-22-Strategy%3A_Google_Sends_Canary_Requests_into_the_Data_Mine.html">946 high scalability-2010-11-22-Strategy: Google Sends Canary Requests into the Data Mine</a></p>
<p>11 0.048576009 <a title="587-tfidf-11" href="../high_scalability-2008/high_scalability-2008-01-30-How_Rackspace_Now_Uses_MapReduce_and_Hadoop_to_Query_Terabytes_of_Data.html">233 high scalability-2008-01-30-How Rackspace Now Uses MapReduce and Hadoop to Query Terabytes of Data</a></p>
<p>12 0.047822159 <a title="587-tfidf-12" href="../high_scalability-2010/high_scalability-2010-12-16-7_Design_Patterns_for_Almost-infinite_Scalability.html">958 high scalability-2010-12-16-7 Design Patterns for Almost-infinite Scalability</a></p>
<p>13 0.047366306 <a title="587-tfidf-13" href="../high_scalability-2012/high_scalability-2012-09-11-How_big_is_a_Petabyte%2C_Exabyte%2C_Zettabyte%2C_or_a_Yottabyte%3F.html">1320 high scalability-2012-09-11-How big is a Petabyte, Exabyte, Zettabyte, or a Yottabyte?</a></p>
<p>14 0.044682704 <a title="587-tfidf-14" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>15 0.044542491 <a title="587-tfidf-15" href="../high_scalability-2009/high_scalability-2009-03-05-Strategy%3A__In_Cloud_Computing_Systematically_Drive_Load_to_the_CPU.html">526 high scalability-2009-03-05-Strategy:  In Cloud Computing Systematically Drive Load to the CPU</a></p>
<p>16 0.043839145 <a title="587-tfidf-16" href="../high_scalability-2014/high_scalability-2014-02-14-Stuff_The_Internet_Says_On_Scalability_For_February_14th%2C_2014.html">1596 high scalability-2014-02-14-Stuff The Internet Says On Scalability For February 14th, 2014</a></p>
<p>17 0.043417975 <a title="587-tfidf-17" href="../high_scalability-2007/high_scalability-2007-12-14-The_Current_Pros_and_Cons_List_for_SimpleDB.html">187 high scalability-2007-12-14-The Current Pros and Cons List for SimpleDB</a></p>
<p>18 0.042362913 <a title="587-tfidf-18" href="../high_scalability-2008/high_scalability-2008-07-16-The_Mother_of_All_Database_Normalization_Debates_on_Coding_Horror.html">351 high scalability-2008-07-16-The Mother of All Database Normalization Debates on Coding Horror</a></p>
<p>19 0.041597448 <a title="587-tfidf-19" href="../high_scalability-2013/high_scalability-2013-01-30-Better_Browser_Caching_is_More_Important_than_No_Javascript_or_Fast_Networks_for_HTTP_Performance.html">1396 high scalability-2013-01-30-Better Browser Caching is More Important than No Javascript or Fast Networks for HTTP Performance</a></p>
<p>20 0.040711485 <a title="587-tfidf-20" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.066), (1, 0.032), (2, -0.017), (3, -0.006), (4, 0.013), (5, 0.047), (6, -0.001), (7, -0.004), (8, 0.009), (9, 0.003), (10, 0.013), (11, -0.014), (12, -0.013), (13, 0.007), (14, 0.024), (15, 0.005), (16, -0.017), (17, -0.005), (18, 0.013), (19, 0.003), (20, 0.001), (21, -0.023), (22, -0.011), (23, 0.023), (24, -0.001), (25, 0.009), (26, -0.028), (27, 0.0), (28, 0.001), (29, 0.033), (30, -0.028), (31, 0.036), (32, -0.029), (33, 0.014), (34, 0.005), (35, -0.004), (36, 0.021), (37, 0.009), (38, -0.013), (39, -0.016), (40, 0.027), (41, 0.002), (42, -0.002), (43, 0.0), (44, 0.006), (45, 0.008), (46, -0.026), (47, -0.01), (48, 0.011), (49, 0.0)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92015612 <a title="587-lsi-1" href="../high_scalability-2009/high_scalability-2009-05-01-FastBit%3A_An_Efficient_Compressed_Bitmap_Index_Technology.html">587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</a></p>
<p>Introduction: Data mining and fast queries are always in that bin of hard to do things where
doing something smarter can yield big results. Bloom Filters are one such do
it smarter strategy, compressed bitmap indexes are another. In one application
"FastBit outruns other search indexes by a factor of 10 to 100 and doesn't
require much more room than the original data size." The data size is an
interesting metric. Our old standard b-trees can be two to four times larger
than the original data. In a test searching an Enron email database FastBit
outran MySQL by 10 to 1,000 times.FastBit is a software tool for searching
large read-only datasets. It organizes user data in a column-oriented
structure which is efficient for on-line analytical processing (OLAP), and
utilizes compressed bitmap indices to further speed up query processing.
Analyses have proven the compressed bitmap index used in FastBit to be
theoretically optimal for one-dimensional queries. Compared with other optimal
indexing methods, bit</p><p>2 0.78909111 <a title="587-lsi-2" href="../high_scalability-2010/high_scalability-2010-04-14-Parallel_Information_Retrieval_and_Other_Search_Engine_Goodness.html">810 high scalability-2010-04-14-Parallel Information Retrieval and Other Search Engine Goodness</a></p>
<p>Introduction: Parallel Information Retrievalis a sample chapter in what appears to be a
book-in-progress titledInformation Retrieval Implementing and Evaluation
Search EnginesbyStefan Buttcher, Google Inc andCharles L. A. Clarke,Gordon V.
Cormack, both of the University of Waterloo. The full table of contents is on-
line and looks to be really interesting:Information retrieval is the
foundation for modern search engines. This text offers an introduction to the
core topics underlying modern search technologies, including algorithms, data
structures, indexing, retrieval, and evaluation. The emphasis is on
implementation and experimentation; each chapter includes exercises and
suggestions for student projects.Currently available is the full text of
chapters: Introduction, Basic Techniques, Static Inverted Indices, Index
Compression, and Parallel Information Retrieval. Parallel Information
Retrieval is really meaty:Information retrieval systems often have to deal
with very large amounts of data. They mu</p><p>3 0.7639851 <a title="587-lsi-3" href="../high_scalability-2012/high_scalability-2012-04-25-The_Anatomy_of_Search_Technology%3A_blekko%E2%80%99s_NoSQL_database.html">1233 high scalability-2012-04-25-The Anatomy of Search Technology: blekko’s NoSQL database</a></p>
<p>Introduction: This is a guest post (part 2,part 3) by Greg Lindahl, CTO of blekko, the spam
free search engine that had over 3.5 million unique visitors in March. Greg
Lindahl was Founder and Distinguished Engineer at PathScale, at which he was
the architect of the InfiniPath low-latency InfiniBand HCA, used to build
tightly-coupled supercomputing clusters.Imagine that you're crazy enough to
think about building a search engine.  It's a huge task: the minimum index
size needed to answer most queries is a few billion webpages. Crawling and
indexing a few billion webpages requires a cluster with several petabytes of
usable disk -- that's several thousand 1 terabyte disks -- and produces an
index that's about 100 terabytes in size.Serving query results quickly
involves having most of the index in RAM or on solid state (flash) disk. If
you can buy a server with 100 gigabytes of RAM for about $3,000, that's 1,000
servers at a capital cost of $3 million, plus about $1 million per year of
server co-locatio</p><p>4 0.76054978 <a title="587-lsi-4" href="../high_scalability-2007/high_scalability-2007-08-10-How_do_we_make_a_large_real-time_search_engine%3F.html">64 high scalability-2007-08-10-How do we make a large real-time search engine?</a></p>
<p>Introduction: We're implementing a website which should be oriented to content and with
massive access by public and we would need a search engine to index and
execute queries on the indexes of contents (stored in a database, most likely
MySQL InnoDB or Oracle).The solution we found is to implement a separate
service to make index constantly the contents of the database at regular
intervals. Anyway, this is a complex and not optimal solution, since we would
like it to index in real time and make it searchable.Could you point me to
some examples or articles I could review to design asolution for such this
context?</p><p>5 0.7542755 <a title="587-lsi-5" href="../high_scalability-2014/high_scalability-2014-05-19-A_Short_On_How_the_Wayback_Machine_Stores_More_Pages_than_Stars_in_the_Milky_Way.html">1650 high scalability-2014-05-19-A Short On How the Wayback Machine Stores More Pages than Stars in the Milky Way</a></p>
<p>Introduction: How does the Wayback Machinework? Now with over 400 billion webpages indexed,
allowing the Internet to be browsed all the way back to 1996, it's an even
more compelling question. I've looked several times but I've never found a
really good answer.Here's some information from a thread on Hacker News. It
starts with mmagin, a former Archive employee:I can't speak to their current
infrastructure (though more of it is open source now - http://archive-
access.sourceforge.net/projects/wayback/ ), but as far as the wayback machine,
there was no SQL database anywhere in it.For the purposes of making the
wayback machine go:Archived data was in ARC file format (predecessor to
http://en.wikipedia.org/wiki/Web_ARChive) which is essentially a concatenation
of separately gzipped records. That is, you can seek to a particular offset
and start decompressing a record. Thus you could get at any archived web page
with a triple (server, filename, file-offset) Thus it was spread across a lot
of commodity g</p><p>6 0.74545062 <a title="587-lsi-6" href="../high_scalability-2008/high_scalability-2008-06-08-Search_fast_in_million_rows.html">342 high scalability-2008-06-08-Search fast in million rows</a></p>
<p>7 0.72574514 <a title="587-lsi-7" href="../high_scalability-2008/high_scalability-2008-03-18-Database_Design_101.html">281 high scalability-2008-03-18-Database Design 101</a></p>
<p>8 0.72257197 <a title="587-lsi-8" href="../high_scalability-2013/high_scalability-2013-01-28-DuckDuckGo_Architecture_-_1_Million_Deep_Searches_a_Day_and_Growing.html">1395 high scalability-2013-01-28-DuckDuckGo Architecture - 1 Million Deep Searches a Day and Growing</a></p>
<p>9 0.71837658 <a title="587-lsi-9" href="../high_scalability-2010/high_scalability-2010-04-29-Product%3A_SciDB_-_A_Science-Oriented_DBMS_at_100_Petabytes.html">817 high scalability-2010-04-29-Product: SciDB - A Science-Oriented DBMS at 100 Petabytes</a></p>
<p>10 0.71713251 <a title="587-lsi-10" href="../high_scalability-2009/high_scalability-2009-06-14-kngine_%27Knowledge_Engine%27_milestone_2.html">630 high scalability-2009-06-14-kngine 'Knowledge Engine' milestone 2</a></p>
<p>11 0.70432335 <a title="587-lsi-11" href="../high_scalability-2011/high_scalability-2011-02-10-Database_Isolation_Levels_And_Their_Effects_on_Performance_and_Scalability.html">986 high scalability-2011-02-10-Database Isolation Levels And Their Effects on Performance and Scalability</a></p>
<p>12 0.70132583 <a title="587-lsi-12" href="../high_scalability-2012/high_scalability-2012-08-14-MemSQL_Architecture_-_The_Fast_%28MVCC%2C_InMem%2C_LockFree%2C_CodeGen%29_and_Familiar_%28SQL%29.html">1304 high scalability-2012-08-14-MemSQL Architecture - The Fast (MVCC, InMem, LockFree, CodeGen) and Familiar (SQL)</a></p>
<p>13 0.6961658 <a title="587-lsi-13" href="../high_scalability-2012/high_scalability-2012-07-11-FictionPress%3A_Publishing_6_Million_Works_of_Fiction_on_the_Web.html">1281 high scalability-2012-07-11-FictionPress: Publishing 6 Million Works of Fiction on the Web</a></p>
<p>14 0.67543441 <a title="587-lsi-14" href="../high_scalability-2012/high_scalability-2012-05-28-The_Anatomy_of_Search_Technology%3A_Crawling_using_Combinators.html">1253 high scalability-2012-05-28-The Anatomy of Search Technology: Crawling using Combinators</a></p>
<p>15 0.67055154 <a title="587-lsi-15" href="../high_scalability-2014/high_scalability-2014-02-25-Peter_Norvig%27s_9_Master_Steps_to_Improving_a_Program.html">1601 high scalability-2014-02-25-Peter Norvig's 9 Master Steps to Improving a Program</a></p>
<p>16 0.66977853 <a title="587-lsi-16" href="../high_scalability-2013/high_scalability-2013-08-30-Stuff_The_Internet_Says_On_Scalability_For_August_30%2C_2013.html">1509 high scalability-2013-08-30-Stuff The Internet Says On Scalability For August 30, 2013</a></p>
<p>17 0.66809362 <a title="587-lsi-17" href="../high_scalability-2011/high_scalability-2011-06-21-Running_TPC-C_on_MySQL-RDS.html">1065 high scalability-2011-06-21-Running TPC-C on MySQL-RDS</a></p>
<p>18 0.66380072 <a title="587-lsi-18" href="../high_scalability-2009/high_scalability-2009-04-23-Which_Key_value_pair_database_to_be_used.html">578 high scalability-2009-04-23-Which Key value pair database to be used</a></p>
<p>19 0.66040421 <a title="587-lsi-19" href="../high_scalability-2008/high_scalability-2008-07-16-The_Mother_of_All_Database_Normalization_Debates_on_Coding_Horror.html">351 high scalability-2008-07-16-The Mother of All Database Normalization Debates on Coding Horror</a></p>
<p>20 0.65669149 <a title="587-lsi-20" href="../high_scalability-2011/high_scalability-2011-02-15-Wordnik_-_10_million_API_Requests_a_Day_on_MongoDB_and_Scala.html">990 high scalability-2011-02-15-Wordnik - 10 million API Requests a Day on MongoDB and Scala</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.112), (2, 0.163), (10, 0.117), (56, 0.023), (58, 0.344), (61, 0.095)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.80725509 <a title="587-lda-1" href="../high_scalability-2009/high_scalability-2009-05-01-FastBit%3A_An_Efficient_Compressed_Bitmap_Index_Technology.html">587 high scalability-2009-05-01-FastBit: An Efficient Compressed Bitmap Index Technology</a></p>
<p>Introduction: Data mining and fast queries are always in that bin of hard to do things where
doing something smarter can yield big results. Bloom Filters are one such do
it smarter strategy, compressed bitmap indexes are another. In one application
"FastBit outruns other search indexes by a factor of 10 to 100 and doesn't
require much more room than the original data size." The data size is an
interesting metric. Our old standard b-trees can be two to four times larger
than the original data. In a test searching an Enron email database FastBit
outran MySQL by 10 to 1,000 times.FastBit is a software tool for searching
large read-only datasets. It organizes user data in a column-oriented
structure which is efficient for on-line analytical processing (OLAP), and
utilizes compressed bitmap indices to further speed up query processing.
Analyses have proven the compressed bitmap index used in FastBit to be
theoretically optimal for one-dimensional queries. Compared with other optimal
indexing methods, bit</p><p>2 0.65409601 <a title="587-lda-2" href="../high_scalability-2013/high_scalability-2013-11-20-How_Twitter_Improved_JVM_Performance_by_Reducing_GC_and_Faster_Memory_Allocation.html">1551 high scalability-2013-11-20-How Twitter Improved JVM Performance by Reducing GC and Faster Memory Allocation</a></p>
<p>Introduction: Nettyis a high-performance NIO(New IO) client server framework for Java that
Twitter uses internally as a protocol agonostic RPC system. Twitterfound some
problemswith Netty 3's memory management for buffer allocations beacause it
generated a lot of garbage during operation. When you send as many messages as
Twitter it creates a lot of GC pressure and the simple act of zero filling
newly allocated buffers consumed 50% of memory bandwidth. Netty 4 fixes this
situation with:Short-lived event objects, methods on long-lived channel
objects are used to handle I/O events.Secialized buffer allocator that uses
pool which implementsbuddy memory allocationandslab allocation.The result:5
times less frequent GC pauses: 45.5 vs. 9.2 times/min5 times less garbage
production: 207.11 vs 41.81 MiB/sThe buffer pool is much faster than JVM as
the size of the buffer increases. Some problems with smaller buffers.Given how
many services use the JVM in their messaging infrastructure and how many
services hav</p><p>3 0.57251006 <a title="587-lda-3" href="../high_scalability-2011/high_scalability-2011-07-06-11_Common_Web_Use_Cases_Solved_in_Redis.html">1074 high scalability-2011-07-06-11 Common Web Use Cases Solved in Redis</a></p>
<p>Introduction: In How to take advantage of Redis just adding it to your stack Salvatore
'antirez' Sanfilippo shows how to solve some common problems in Redis by
taking advantage of its unique data structure handling capabilities. Common
Redis primitives like LPUSH, and LTRIM, and LREM are used to accomplish tasks
programmers need to get done, but that can be hard or slow in more traditional
stores. A very useful and practical article. How would you accomplish these
tasks in your framework?Show latest items listings in your home page. This is
a live in-memory cache and is very fast.LPUSHis used to insert a content ID at
the head of the list stored at a key.LTRIMis used to limit the number of items
in the list to 5000. If the user needs to page beyond this cache only then are
they sent to the database.Deletion and filtering. If a cached article is
deleted it can be removed from the cache using LREM.Leaderboards and related
problems. A leader board is a set sorted by score. TheZADDcommands implements
th</p><p>4 0.56924957 <a title="587-lda-4" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>Introduction: This is a guest post byJeff Behl, VP Ops @ LogicMonitor. Jeffhas been a bit
herder for the last 20 years, architecting and overseeing the infrastructure
for a number of SaaS based companies.  Data Replication for Disaster
RecoveryAn inevitable part of disaster recovery planning is making sure
customer data exists in multiple locations.  In the case of LogicMonitor, a
SaaS-based monitoring solution for physical, virtual, and cloud environments,
we wanted copies of customer data files both within a data center and outside
of it.  The former was to protect against the loss of individual servers
within a facility, and the latter for recovery in the event of the complete
loss of a data center.Where we were:  RsyncLike most everyone who starts off
in a Linux environment, we used our trusty friend rsync to copy data around.
Rsync is tried, true and tested, and works well when the number of servers,
the amount of data, and the number of files is not horrendous.  When any of
these are no longer</p><p>5 0.56879818 <a title="587-lda-5" href="../high_scalability-2013/high_scalability-2013-07-08-The_Architecture_Twitter_Uses_to_Deal_with_150M_Active_Users%2C_300K_QPS%2C_a_22_MB-S_Firehose%2C_and_Send_Tweets_in_Under_5_Seconds.html">1488 high scalability-2013-07-08-The Architecture Twitter Uses to Deal with 150M Active Users, 300K QPS, a 22 MB-S Firehose, and Send Tweets in Under 5 Seconds</a></p>
<p>Introduction: Toy solutions solving Twitter's "problems" are a favorite scalability trope.
Everybody has this idea that Twitter is easy. With a little architectural hand
waving we have a scalable Twitter, just that simple. Well, it's not that
simple asRaffi Krikorian, VP of Engineering at Twitter, describes in his
superb and very detailed presentation onTimelines at Scale. If you want to
know how Twitter works - then start here.It happened gradually so you may have
missed it, but Twitter has grown up. It started as a strugglingthree-tierish
Ruby on Railswebsite to become a beautifully service driven core that we
actually go to now to see if other services are down. Quite a change.Twitter
now has 150M world wide active users, handles 300K QPS to generate timelines,
and a firehose that churns out 22 MB/sec. 400 million tweets a day flow
through the system and it can take up to 5 minutes for a tweet to flow from
Lady Gaga's fingers to her 31 million followers.A couple of points stood
out:Twitter no lon</p><p>6 0.56707525 <a title="587-lda-6" href="../high_scalability-2009/high_scalability-2009-04-27-Some_Questions_from_a_newbie.html">584 high scalability-2009-04-27-Some Questions from a newbie</a></p>
<p>7 0.5645445 <a title="587-lda-7" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>8 0.56057531 <a title="587-lda-8" href="../high_scalability-2010/high_scalability-2010-03-10-How_FarmVille_Scales_-_The_Follow-up.html">792 high scalability-2010-03-10-How FarmVille Scales - The Follow-up</a></p>
<p>9 0.55848867 <a title="587-lda-9" href="../high_scalability-2009/high_scalability-2009-08-28-Strategy%3A_Solve_Only_80_Percent_of_the_Problem.html">689 high scalability-2009-08-28-Strategy: Solve Only 80 Percent of the Problem</a></p>
<p>10 0.55676037 <a title="587-lda-10" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>11 0.55157912 <a title="587-lda-11" href="../high_scalability-2008/high_scalability-2008-10-10-The_Art_of_Capacity_Planning%3A_Scaling_Web_Resources.html">407 high scalability-2008-10-10-The Art of Capacity Planning: Scaling Web Resources</a></p>
<p>12 0.54727334 <a title="587-lda-12" href="../high_scalability-2007/high_scalability-2007-08-10-How_do_we_make_a_large_real-time_search_engine%3F.html">64 high scalability-2007-08-10-How do we make a large real-time search engine?</a></p>
<p>13 0.54714537 <a title="587-lda-13" href="../high_scalability-2010/high_scalability-2010-11-29-Stuff_the_Internet_Says_on_Scalability_For_November_29th%2C_2010.html">949 high scalability-2010-11-29-Stuff the Internet Says on Scalability For November 29th, 2010</a></p>
<p>14 0.54690588 <a title="587-lda-14" href="../high_scalability-2014/high_scalability-2014-01-24-Stuff_The_Internet_Says_On_Scalability_For_January_24th%2C_2014.html">1585 high scalability-2014-01-24-Stuff The Internet Says On Scalability For January 24th, 2014</a></p>
<p>15 0.54638004 <a title="587-lda-15" href="../high_scalability-2008/high_scalability-2008-03-08-Audiogalaxy.com_Architecture.html">269 high scalability-2008-03-08-Audiogalaxy.com Architecture</a></p>
<p>16 0.54472011 <a title="587-lda-16" href="../high_scalability-2008/high_scalability-2008-04-10-Mysql_scalability_and_failover....html">302 high scalability-2008-04-10-Mysql scalability and failover...</a></p>
<p>17 0.54428875 <a title="587-lda-17" href="../high_scalability-2013/high_scalability-2013-09-23-Salesforce_Architecture_-_How_they_Handle_1.3_Billion_Transactions_a_Day.html">1521 high scalability-2013-09-23-Salesforce Architecture - How they Handle 1.3 Billion Transactions a Day</a></p>
<p>18 0.5441733 <a title="587-lda-18" href="../high_scalability-2010/high_scalability-2010-11-30-NoCAP_%E2%80%93_Part_III_%E2%80%93_GigaSpaces_clustering_explained...html">950 high scalability-2010-11-30-NoCAP – Part III – GigaSpaces clustering explained..</a></p>
<p>19 0.54256439 <a title="587-lda-19" href="../high_scalability-2010/high_scalability-2010-10-26-Scaling_DISQUS_to_75_Million_Comments_and_17%2C000_RPS.html">928 high scalability-2010-10-26-Scaling DISQUS to 75 Million Comments and 17,000 RPS</a></p>
<p>20 0.54100436 <a title="587-lda-20" href="../high_scalability-2011/high_scalability-2011-05-23-Evernote_Architecture_-_9_Million_Users_and_150_Million_Requests_a_Day.html">1046 high scalability-2011-05-23-Evernote Architecture - 9 Million Users and 150 Million Requests a Day</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
