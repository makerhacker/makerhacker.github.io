<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2006" href="../home/hunch_net-2006_home.html">hunch_net-2006</a> <a title="hunch_net-2006-221" href="#">hunch_net-2006-221</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2006-221-html" href="http://hunch.net/?p=241">html</a></p><p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('pc', 0.619), ('spotlights', 0.22), ('nips', 0.202), ('members', 0.198), ('veto', 0.17), ('meeting', 0.144), ('decision', 0.141), ('oral', 0.136), ('paper', 0.134), ('attention', 0.127), ('papers', 0.121), ('deficit', 0.115), ('orals', 0.115), ('assigned', 0.113), ('secondary', 0.105), ('member', 0.094), ('authors', 0.084), ('decisions', 0.084), ('blinded', 0.076), ('reconciliation', 0.076)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="221-tfidf-1" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><p>2 0.30924335 <a title="221-tfidf-2" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>Introduction: Claireasked me to be on the SODA program committee this year, which was quite
a bit of work.I had a relatively light load--merely 49 theory papers. Many of
these papers were not on subjects that I was expert about, so (as is common
for theory conferences) I found various reviewers that I trusted to help
review the papers. I ended up reviewing about 1/3 personally. There were a
couple instances where I ended up overruling a subreviewer whose logic seemed
off, but otherwise I generally let their reviews stand.There are some
differences in standards for paper reviews between the machine learning and
theory communities. In machine learning it is expected that a review be
detailed, while in the theory community this is often not the case. Every
paper given to me ended up with a review varying between somewhat and very
detailed.I'm sure not every author was happy with the outcome. While we did
our best to make good decisions, they were difficult decisions to make. For
example, if there is a</p><p>3 0.24181685 <a title="221-tfidf-3" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>4 0.21686776 <a title="221-tfidf-4" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>Introduction: This is a rather long post, detailing the ICML 2012 review process. The goal
is to make the process more transparent, help authors understand how we came
to a decision, and discuss the strengths and weaknesses of this process for
future conference organizers.Microsoft’s Conference Management Toolkit (CMT)We
chose to useCMTover other conference management software mainly because of its
rich toolkit. The interface is sub-optimal (to say the least!) but it has
extensive capabilities (to handle bids, author response, resubmissions, etc.),
good import/export mechanisms (to process the data elsewhere), excellent
technical support (to answer late night emails, add new functionalities).
Overall, it was the right choice, although we hope a designer will look at
that interface sometime soon!Toronto Matching System (TMS)TMSis now being used
by many major conferences in our field (including NIPS and UAI). It is an
automated system (developed byLaurent CharlinandRich Zemelat U. Toronto) to
match re</p><p>5 0.20592406 <a title="221-tfidf-5" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>6 0.19636175 <a title="221-tfidf-6" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>7 0.19556367 <a title="221-tfidf-7" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>8 0.18738976 <a title="221-tfidf-8" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>9 0.18300763 <a title="221-tfidf-9" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<p>10 0.17835203 <a title="221-tfidf-10" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>11 0.17201993 <a title="221-tfidf-11" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>12 0.17004152 <a title="221-tfidf-12" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>13 0.16425563 <a title="221-tfidf-13" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>14 0.16342005 <a title="221-tfidf-14" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>15 0.13946858 <a title="221-tfidf-15" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>16 0.13595909 <a title="221-tfidf-16" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>17 0.12993972 <a title="221-tfidf-17" href="../hunch_net-2011/hunch_net-2011-10-10-ML_Symposium_and_ICML_details.html">447 hunch net-2011-10-10-ML Symposium and ICML details</a></p>
<p>18 0.1280205 <a title="221-tfidf-18" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>19 0.1211101 <a title="221-tfidf-19" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>20 0.11278933 <a title="221-tfidf-20" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.254), (1, 0.23), (2, -0.18), (3, -0.014), (4, -0.026), (5, 0.015), (6, 0.002), (7, -0.014), (8, -0.01), (9, 0.002), (10, 0.026), (11, 0.065), (12, 0.008), (13, -0.003), (14, -0.043), (15, 0.04), (16, -0.043), (17, -0.016), (18, -0.035), (19, 0.036), (20, 0.011), (21, 0.041), (22, 0.011), (23, 0.008), (24, 0.069), (25, 0.014), (26, -0.006), (27, 0.011), (28, 0.047), (29, -0.014), (30, -0.093), (31, -0.019), (32, 0.025), (33, 0.083), (34, 0.023), (35, -0.012), (36, 0.012), (37, 0.003), (38, 0.074), (39, -0.06), (40, -0.02), (41, -0.029), (42, 0.043), (43, 0.04), (44, 0.008), (45, -0.034), (46, 0.033), (47, 0.128), (48, 0.017), (49, 0.063)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97522444 <a title="221-lsi-1" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><p>2 0.85981733 <a title="221-lsi-2" href="../hunch_net-2007/hunch_net-2007-04-13-What_to_do_with_an_unreasonable_conditional_accept.html">238 hunch net-2007-04-13-What to do with an unreasonable conditional accept</a></p>
<p>Introduction: Last year about this time, we received a conditional accept for thesearn
paper, which asked us to reference a paper that was not reasonable to cite
because there was strictly more relevant work by the same authors that we
already cited. We wrote a response explaining this, and didn't cite it in the
final draft, giving the SPC an excuse toreject the paper, leading to
unhappiness for all.Later,Sanjoy Dasguptasuggested that an alternative was to
talk to the PC chair instead, as soon as you see that a conditional accept is
unreasonable.William Cohenand I spoke about this by email, the relevant bit of
which is:If an SPC asks for a revision that is inappropriate, the
correctaction is to contact the chairs as soon as the decision is made,clearly
explaining what the problem is, so we can decide whether ornot to over-rule
the SPC. As you say, this is extra work for uschairs, but that's part of the
job, and we're willing to do that sortof work to improve the overall quality
of the reviewing proc</p><p>3 0.84852523 <a title="221-lsi-3" href="../hunch_net-2008/hunch_net-2008-10-14-Who_is_Responsible_for_a_Bad_Review%3F.html">320 hunch net-2008-10-14-Who is Responsible for a Bad Review?</a></p>
<p>Introduction: Although I'm greatly interested in machine learning, I think it must be
admitted that there is a large amount of low quality logic being used in
reviews. The problem is bad enough that sometimes I wonder if theByzantine
generalslimit has been exceeded. For example, I've seen recent reviews where
the given reasons for rejecting are:[NIPS] Theorem A is uninteresting because
Theorem B is uninteresting.[UAI] When you learn by memorization, the problem
addressed is trivial.[NIPS] The proof is in the appendix.[NIPS] This has been
done before. (â&euro;Ś but not giving any relevant citations)Just for the record I
want to point out what's wrong with these reviews. A future world in which
such reasons never come up again would be great, but I'm sure these errors
will be committed many times more in the future.This is nonsense. A theorem
should be evaluated based on it's merits, rather than the merits of another
theorem.Learning by memorization requires an exponentially larger sample
complexity than man</p><p>4 0.84132969 <a title="221-lsi-4" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>Introduction: Claireasked me to be on the SODA program committee this year, which was quite
a bit of work.I had a relatively light load--merely 49 theory papers. Many of
these papers were not on subjects that I was expert about, so (as is common
for theory conferences) I found various reviewers that I trusted to help
review the papers. I ended up reviewing about 1/3 personally. There were a
couple instances where I ended up overruling a subreviewer whose logic seemed
off, but otherwise I generally let their reviews stand.There are some
differences in standards for paper reviews between the machine learning and
theory communities. In machine learning it is expected that a review be
detailed, while in the theory community this is often not the case. Every
paper given to me ended up with a review varying between somewhat and very
detailed.I'm sure not every author was happy with the outcome. While we did
our best to make good decisions, they were difficult decisions to make. For
example, if there is a</p><p>5 0.83126783 <a title="221-lsi-5" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>Introduction: Essentially everyone who writes research papers suffers rejections. They
always sting immediately, but upon further reflection many of these rejections
come to seem reasonable. Maybe the equations had too many typos or maybe the
topic just isn't as important as was originally thought. A few rejections do
not come to seem acceptable, and these form the basis of reviewing horror
stories, a great material for conversations. I've decided to share three of
mine, now all safely a bit distant in the past.Prediction Theory for
Classification Tutorial. This is a tutorial about tight sample complexity
bounds for classification that I submitted toJMLR. The first decision I heard
was a reject which appeared quite unjust to me--for example one of the
reviewers appeared to claim that all the content was in standard statistics
books. Upon further inquiry, several citations were given, none of which
actually covered the content. Later, I was shocked to hear the paper was
accepted. Apparently, the pape</p><p>6 0.82194227 <a title="221-lsi-6" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>7 0.79567486 <a title="221-lsi-7" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>8 0.78617322 <a title="221-lsi-8" href="../hunch_net-2005/hunch_net-2005-03-09-Bad_Reviewing.html">38 hunch net-2005-03-09-Bad Reviewing</a></p>
<p>9 0.78398758 <a title="221-lsi-9" href="../hunch_net-2012/hunch_net-2012-06-29-ICML_survey_and_comments.html">468 hunch net-2012-06-29-ICML survey and comments</a></p>
<p>10 0.78209323 <a title="221-lsi-10" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>11 0.76989001 <a title="221-lsi-11" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>12 0.74143273 <a title="221-lsi-12" href="../hunch_net-2012/hunch_net-2012-04-09-ICML_author_feedback_is_open.html">461 hunch net-2012-04-09-ICML author feedback is open</a></p>
<p>13 0.72955316 <a title="221-lsi-13" href="../hunch_net-2005/hunch_net-2005-04-04-Grounds_for_Rejection.html">52 hunch net-2005-04-04-Grounds for Rejection</a></p>
<p>14 0.7220183 <a title="221-lsi-14" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>15 0.70615596 <a title="221-lsi-15" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>16 0.67910802 <a title="221-lsi-16" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>17 0.67679667 <a title="221-lsi-17" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>18 0.66331375 <a title="221-lsi-18" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>19 0.6516571 <a title="221-lsi-19" href="../hunch_net-2005/hunch_net-2005-03-13-Avoiding_Bad_Reviewing.html">40 hunch net-2005-03-13-Avoiding Bad Reviewing</a></p>
<p>20 0.64738852 <a title="221-lsi-20" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.031), (35, 0.039), (42, 0.204), (47, 0.011), (53, 0.017), (68, 0.024), (69, 0.031), (70, 0.207), (74, 0.215), (82, 0.062), (95, 0.048)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.92856002 <a title="221-lda-1" href="../hunch_net-2006/hunch_net-2006-12-04-Structural_Problems_in_NIPS_Decision_Making.html">221 hunch net-2006-12-04-Structural Problems in NIPS Decision Making</a></p>
<p>Introduction: This is a very difficult post to write, because it is about a perenially
touchy subject. Nevertheless, it is an important one which needs to be thought
about carefully.There are a few things which should be understood:The system
is changing and responsive. We-the-authors are we-the-reviewers, we-the-PC,
and even we-the-NIPS-board. NIPS has implemented 'secondary program chairs',
'author response', and 'double blind reviewing' in the last few years to help
with the decision process, and more changes may happen in the future.Agreement
creates a perception of correctness. When any PC meets and makes a group
decision about a paper, there is a strong tendency for the reinforcement
inherent in a group decision to create the perception of correctness. For the
many people who have been on the NIPS PC it's reasonable to entertain a
healthy skepticism in the face of this reinforcing certainty.This post is
about structural problems. What problems arise because of the structure of the
process? The</p><p>2 0.81921357 <a title="221-lda-2" href="../hunch_net-2011/hunch_net-2011-07-10-ICML_2011_and_the_future.html">437 hunch net-2011-07-10-ICML 2011 and the future</a></p>
<p>Introduction: Unfortunately, I ended up sick for much of this ICML. I did manage to catch
one interesting paper:Richard Socher,Cliff Lin,Andrew Y. Ng, andChristopher D.
ManningParsing Natural Scenes and Natural Language with Recursive Neural
Networks.I invited Richard to share his list of interesting papers, so
hopefully we'll hear from him soon. In the meantime,PaulandHalhave posted some
lists.the futureJoelleand I are program chairs for ICML 2012 inEdinburgh,
which I previously enjoyed visiting in2005. This is a huge responsibility,
that we hope to accomplish well. A part of this (perhaps the most fun part),
is imagining how we can make ICML better. A key and critical constraint is
choosing things that can be accomplished. So far we have:Colocation. The first
thing we looked into was potential colocations. We quickly discovered that
many other conferences precomitted their location. For the future, getting a
colocation withACLorSIGIR, seems to require more advanced planning. If that
can be done, I</p><p>3 0.81912333 <a title="221-lda-3" href="../hunch_net-2013/hunch_net-2013-06-16-Representative_Reviewing.html">484 hunch net-2013-06-16-Representative Reviewing</a></p>
<p>Introduction: When thinking about how best to review papers, it seems helpful to have some
conception of what good reviewing is. As far as I can tell, this is almost
always only discussed in the specific context of a paper (i.e. your rejected
paper), or at most an area (i.e. what a "good paper" looks like for that area)
rather than general principles. Neither individual papers or areas are
sufficiently general for a large conference--every paper differs in the
details, and what if you want to build a new area and/or cross areas?An
unavoidable reason for reviewing is that the community of research is too
large. In particular, it is not possible for a researcher to read every paper
which someone thinks might be of interest. This reason for reviewing exists
independent of constraints on rooms or scheduling formats of individual
conferences. Indeed, history suggests that physical constraints are relatively
meaningless over the long term -- growing conferences simply use more rooms
and/or change formats</p><p>4 0.81903619 <a title="221-lda-4" href="../hunch_net-2005/hunch_net-2005-09-30-Research_in_conferences.html">116 hunch net-2005-09-30-Research in conferences</a></p>
<p>Introduction: Conferences exist as part of the process of doing research. They provide many
roles including "announcing research", "meeting people", and "point of
reference". Not all conferences are alike so a basic question is: "to what
extent do individual conferences attempt to aid research?" This question is
very difficult to answer in any satisfying way. What we can do is compare
details of the process across multiple conferences.CommentsThe average quality
of comments across conferences can vary dramatically. At one extreme, the
tradition in CS theory conferences is to provide essentially zero feedback. At
the other extreme, some conferences have a strong tradition of providing
detailed constructive feedback. Detailed feedback can give authors significant
guidance about how to improve research. This is the most subjective
entry.BlindVirtually all conferences offer single blind review where authors
do not know reviewers. Some also providedouble blindreview where reviewers do
not know authors. T</p><p>5 0.80678803 <a title="221-lda-5" href="../hunch_net-2008/hunch_net-2008-12-27-Adversarial_Academia.html">333 hunch net-2008-12-27-Adversarial Academia</a></p>
<p>Introduction: One viewpoint on academia is that it is inherently adversarial: there are
finite research dollars, positions, and students to work with, implying a
zero-sum game between different participants. This is not a viewpoint that I
want to promote, as I consider it flawed. However, I know several people
believe strongly in this viewpoint, and I have found it to have substantial
explanatory power.For example:It explains why your paper was rejected based on
poor logic. The reviewer wasn't concerned with research quality, but rather
with rejecting a competitor.It explains why professors rarely work together.
The goal of a non-tenured professor (at least) is to get tenure, and a case
for tenure comes from a portfolio of work that is undisputably yours.It
explains why new research programs are not quickly adopted. Adopting a
competitor's program is impossible, if your career is based on the competitor
being wrong.Different academic groups subscribe to the adversarial viewpoint
in different degrees</p><p>6 0.80656379 <a title="221-lda-6" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>7 0.80573159 <a title="221-lda-7" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>8 0.80360168 <a title="221-lda-8" href="../hunch_net-2008/hunch_net-2008-09-26-The_SODA_Program_Committee.html">318 hunch net-2008-09-26-The SODA Program Committee</a></p>
<p>9 0.79541141 <a title="221-lda-9" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>10 0.79504383 <a title="221-lda-10" href="../hunch_net-2005/hunch_net-2005-12-27-Automated_Labeling.html">143 hunch net-2005-12-27-Automated Labeling</a></p>
<p>11 0.79132849 <a title="221-lda-11" href="../hunch_net-2005/hunch_net-2005-12-01-The_Webscience_Future.html">134 hunch net-2005-12-01-The Webscience Future</a></p>
<p>12 0.79110932 <a title="221-lda-12" href="../hunch_net-2010/hunch_net-2010-04-26-Compassionate_Reviewing.html">395 hunch net-2010-04-26-Compassionate Reviewing</a></p>
<p>13 0.78899676 <a title="221-lda-13" href="../hunch_net-2012/hunch_net-2012-05-02-ICML%3A_Behind_the_Scenes.html">463 hunch net-2012-05-02-ICML: Behind the Scenes</a></p>
<p>14 0.78760988 <a title="221-lda-14" href="../hunch_net-2008/hunch_net-2008-09-03-Bidding_Problems.html">315 hunch net-2008-09-03-Bidding Problems</a></p>
<p>15 0.78457487 <a title="221-lda-15" href="../hunch_net-2006/hunch_net-2006-04-02-Mad_%28Neuro%29science.html">168 hunch net-2006-04-02-Mad (Neuro)science</a></p>
<p>16 0.78427023 <a title="221-lda-16" href="../hunch_net-2006/hunch_net-2006-09-12-Incentive_Compatible_Reviewing.html">207 hunch net-2006-09-12-Incentive Compatible Reviewing</a></p>
<p>17 0.78220338 <a title="221-lda-17" href="../hunch_net-2012/hunch_net-2012-06-05-ICML_acceptance_statistics.html">466 hunch net-2012-06-05-ICML acceptance statistics</a></p>
<p>18 0.78180385 <a title="221-lda-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.78172088 <a title="221-lda-19" href="../hunch_net-2007/hunch_net-2007-01-26-Parallel_Machine_Learning_Problems.html">229 hunch net-2007-01-26-Parallel Machine Learning Problems</a></p>
<p>20 0.78012884 <a title="221-lda-20" href="../hunch_net-2012/hunch_net-2012-01-28-Why_COLT%3F.html">453 hunch net-2012-01-28-Why COLT?</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
