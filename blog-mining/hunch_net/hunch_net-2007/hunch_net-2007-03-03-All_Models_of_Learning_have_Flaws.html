<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>235 hunch net-2007-03-03-All Models of Learning have Flaws</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2007" href="../home/hunch_net-2007_home.html">hunch_net-2007</a> <a title="hunch_net-2007-235" href="#">hunch_net-2007-235</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>235 hunch net-2007-03-03-All Models of Learning have Flaws</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2007-235-html" href="http://hunch.net/?p=224">html</a></p><p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('learninglearning', 0.18), ('learningyou', 0.18), ('pomdp', 0.18), ('framework', 0.172), ('prior', 0.147), ('models', 0.138), ('samples', 0.135), ('automated', 0.128), ('flaws', 0.128), ('datamaker', 0.12), ('iid', 0.117), ('loss', 0.108), ('unknown', 0.108), ('convex', 0.103), ('world', 0.1), ('finding', 0.1), ('predictive', 0.099), ('acting', 0.099), ('frameworks', 0.099), ('states', 0.096)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000001 <a title="235-tfidf-1" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>2 0.21630213 <a title="235-tfidf-2" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>3 0.20530149 <a title="235-tfidf-3" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the "right" way to do
machine learning. This is a serious argument which deserves a serious reply.
The approximation argument is a serious reply for which I have not yet seen a
reply2.The idea for the Bayesian approach is quite simple, elegant, and
general. Essentially, you first specify a priorP(D)over possible
processesDproducing the data, observe the data, then condition on the data
according to Bayes law to construct a posterior:P(D|x) = P(x|D)P(D)/P(x)After
this, hard decisions are made (such as "turn left" or "turn right") by
choosing the one which minimizes the expected (with respect to the posterior)
loss.This basic idea is reused thousands of times with various choices
ofP(D)and loss functions which is unsurprising given the many nice
properties:There is an extremely strong associated guarantee: If the actual
distribution generating the data is drawn fromP(D)there is no better method.
One way to think about this is that in</p><p>4 0.1917264 <a title="235-tfidf-4" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>Introduction: One thing which is clear on a little reflection is that there exists a single
master learning problem capable of encoding essentially all learning problems.
This problem is of course a very general sort of reinforcement learning where
the world interacts with an agent as:The world announces an observationx.The
agent makes a choicea.The world announces a rewardr.The goal here is to
maximize the sum of the rewards over the time of the agent. No particular
structure relatingxtoaoratoris implied by this setting so we do not know
effective general algorithms for the agent. It's very easy to prove lower
bounds showing that an agent cannot hope to succeed here--just consider the
case where actions are unrelated to rewards. Nevertheless, there is a real
sense in which essentially all forms of life are agents operating in this
setting, somehow succeeding. The gap between these observations drives
research--How can we find tractable specializations of the master problem
general enough to provide</p><p>5 0.18947883 <a title="235-tfidf-5" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>Introduction: One of the remarkable things about machine learning is how diverse it is. The
viewpoints of Bayesian learning, reinforcement learning, graphical models,
supervised learning, unsupervised learning, genetic programming, etc… share
little enough overlap that many people can and do make their careers within
one without touching, or even necessarily understanding the others.There are
two fundamental reasons why this is possible.For many problems, many
approaches work in the sense that they do something useful. This is true
empirically, where for many problems we can observe that many different
approaches yield better performance than any constant predictor. It's also
true in theory, where we know that for any set of predictors representable in
a finite amount of RAM, minimizing training error over the set of predictors
does something nontrivial when there are a sufficient number of examples.There
is nothing like a unifying problem defining the field. In many other areas
there are unifying p</p><p>6 0.18520196 <a title="235-tfidf-6" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>7 0.17413034 <a title="235-tfidf-7" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>8 0.17199455 <a title="235-tfidf-8" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>9 0.1686794 <a title="235-tfidf-9" href="../hunch_net-2006/hunch_net-2006-02-24-A_Fundamentalist_Organization_of_Machine_Learning.html">158 hunch net-2006-02-24-A Fundamentalist Organization of Machine Learning</a></p>
<p>10 0.16401537 <a title="235-tfidf-10" href="../hunch_net-2008/hunch_net-2008-01-25-Turing%26%238217%3Bs_Club_for_Machine_Learning.html">286 hunch net-2008-01-25-Turing&#8217;s Club for Machine Learning</a></p>
<p>11 0.16317919 <a title="235-tfidf-11" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>12 0.1629173 <a title="235-tfidf-12" href="../hunch_net-2005/hunch_net-2005-02-01-Watchword%3A_Loss.html">9 hunch net-2005-02-01-Watchword: Loss</a></p>
<p>13 0.15915537 <a title="235-tfidf-13" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>14 0.15704171 <a title="235-tfidf-14" href="../hunch_net-2005/hunch_net-2005-06-08-Question%3A_%26%238220%3BWhen_is_the_right_time_to_insert_the_loss_function%3F%26%238221%3B.html">79 hunch net-2005-06-08-Question: &#8220;When is the right time to insert the loss function?&#8221;</a></p>
<p>15 0.15684146 <a title="235-tfidf-15" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>16 0.155563 <a title="235-tfidf-16" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>17 0.14994237 <a title="235-tfidf-17" href="../hunch_net-2007/hunch_net-2007-08-12-Exponentiated_Gradient.html">258 hunch net-2007-08-12-Exponentiated Gradient</a></p>
<p>18 0.149657 <a title="235-tfidf-18" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>19 0.14364965 <a title="235-tfidf-19" href="../hunch_net-2005/hunch_net-2005-09-08-Online_Learning_as_the_Mathematics_of_Accountability.html">109 hunch net-2005-09-08-Online Learning as the Mathematics of Accountability</a></p>
<p>20 0.13929708 <a title="235-tfidf-20" href="../hunch_net-2007/hunch_net-2007-02-02-Thoughts_regarding_%26%238220%3BIs_machine_learning_different_from_statistics%3F%26%238221%3B.html">230 hunch net-2007-02-02-Thoughts regarding &#8220;Is machine learning different from statistics?&#8221;</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.383), (1, -0.196), (2, -0.02), (3, -0.004), (4, 0.015), (5, 0.021), (6, -0.154), (7, -0.015), (8, -0.07), (9, -0.031), (10, 0.003), (11, -0.076), (12, 0.023), (13, -0.057), (14, -0.034), (15, -0.032), (16, 0.096), (17, -0.063), (18, -0.025), (19, 0.049), (20, -0.03), (21, -0.052), (22, 0.025), (23, 0.005), (24, -0.009), (25, 0.04), (26, 0.033), (27, 0.022), (28, 0.093), (29, 0.012), (30, 0.039), (31, -0.039), (32, 0.014), (33, 0.066), (34, 0.032), (35, -0.012), (36, 0.004), (37, -0.039), (38, -0.011), (39, 0.008), (40, -0.014), (41, 0.044), (42, -0.018), (43, 0.015), (44, -0.018), (45, -0.004), (46, -0.04), (47, -0.015), (48, 0.047), (49, -0.046)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96129042 <a title="235-lsi-1" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>2 0.82998526 <a title="235-lsi-2" href="../hunch_net-2006/hunch_net-2006-03-23-The_Approximation_Argument.html">165 hunch net-2006-03-23-The Approximation Argument</a></p>
<p>Introduction: An argument is sometimes made that the Bayesian way is the "right" way to do
machine learning. This is a serious argument which deserves a serious reply.
The approximation argument is a serious reply for which I have not yet seen a
reply2.The idea for the Bayesian approach is quite simple, elegant, and
general. Essentially, you first specify a priorP(D)over possible
processesDproducing the data, observe the data, then condition on the data
according to Bayes law to construct a posterior:P(D|x) = P(x|D)P(D)/P(x)After
this, hard decisions are made (such as "turn left" or "turn right") by
choosing the one which minimizes the expected (with respect to the posterior)
loss.This basic idea is reused thousands of times with various choices
ofP(D)and loss functions which is unsurprising given the many nice
properties:There is an extremely strong associated guarantee: If the actual
distribution generating the data is drawn fromP(D)there is no better method.
One way to think about this is that in</p><p>3 0.81628323 <a title="235-lsi-3" href="../hunch_net-2005/hunch_net-2005-04-23-Advantages_and_Disadvantages_of_Bayesian_Learning.html">60 hunch net-2005-04-23-Advantages and Disadvantages of Bayesian Learning</a></p>
<p>Introduction: I don't consider myself a "Bayesian", but I do try hard to understand why
Bayesian learning works. For the purposes of this post, Bayesian learning is a
simple process of:Specify a prior over world models.Integrate using Bayes law
with respect to all observed information to compute a posterior over world
models.Predict according to the posterior.Bayesian learning has many
advantages over other learning programs:InterpolationBayesian learning methods
interpolate all the way to pure engineering. When faced with any learning
problem, there is a choice of how much time and effort a human vs. a computer
puts in. (For example, the mars rover pathfinding algorithms are almost
entirely engineered.) When creating an engineered system, you build a model of
the world and then find a good controller in that model. Bayesian methods
interpolate to this extreme because the Bayesian prior can be a delta function
on one model of the world. What this means is that a recipe of "think harder"
(about speci</p><p>4 0.78327382 <a title="235-lsi-4" href="../hunch_net-2006/hunch_net-2006-03-02-Why_do_people_count_for_learning%3F.html">160 hunch net-2006-03-02-Why do people count for learning?</a></p>
<p>Introduction: This post is about a confusion of mine with respect to many commonly used
machine learning algorithms.A simple example where this comes up is Bayes net
prediction. A Bayes net where a directed acyclic graph over a set of nodes
where each node is associated with a variable and the edges indicate
dependence. The joint probability distribution over the variables is given by
a set of conditional probabilities. For example, a very simple Bayes net might
express:P(A,B,C) = P(A | B,C)P(B)P(C)What I don't understand is the mechanism
commonly used to estimateP(A | B, C). If we letN(A,B,C)be the number of
instances ofA,B,Cthen people sometimes form an estimate according to:P'(A |
B,C) = N(A,B,C) / N /[N(B)/N * N(C)/N] = N(A,B,C) N /[N(B) N(C)]â&euro;Ś in other
words, people just estimateP'(A | B,C)according to observed relative
frequencies. This is a reasonable technique when you have a large number of
samples compared to the size spaceA x B x C, but it (naturally) falls apart
when this is not the case</p><p>5 0.77443898 <a title="235-lsi-5" href="../hunch_net-2007/hunch_net-2007-04-02-Contextual_Scaling.html">237 hunch net-2007-04-02-Contextual Scaling</a></p>
<p>Introduction: Machine learning has a new kind of "scaling to larger problems" to worry
about: scaling with the amount of contextual information. The standard
development path for a machine learning application in practice seems to be
the following:Marginal. In the beginning, there was "majority vote". At this
stage, it isn't necessary to understand that you have a prediction problem.
People just realize that one answer is right sometimes and another answer
other times. In machine learning terms, this corresponds to making a
prediction without side information.First context. A clever person realizes
that some bit of informationx1could be helpful. Ifx1is discrete, they
condition on it and make a predictorh(x1), typically by counting. If they are
clever, then they also do some smoothing. Ifx1is some real valued parameter,
it's very common to make a threshold cutoff. Often, these tasks are simply
done by hand.Second. Another clever person (or perhaps the same one) realizes
that some other bit of informa</p><p>6 0.74536341 <a title="235-lsi-6" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>7 0.74110621 <a title="235-lsi-7" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>8 0.7274611 <a title="235-lsi-8" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>9 0.72615653 <a title="235-lsi-9" href="../hunch_net-2006/hunch_net-2006-02-18-Multiplication_of_Learned_Probabilities_is_Dangerous.html">157 hunch net-2006-02-18-Multiplication of Learned Probabilities is Dangerous</a></p>
<p>10 0.72429943 <a title="235-lsi-10" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>11 0.72011805 <a title="235-lsi-11" href="../hunch_net-2007/hunch_net-2007-09-18-It%26%238217%3Bs_MDL_Jim%2C_but_not_as_we_know_it%26%238230%3B%28on_Bayes%2C_MDL_and_consistency%29.html">263 hunch net-2007-09-18-It&#8217;s MDL Jim, but not as we know it&#8230;(on Bayes, MDL and consistency)</a></p>
<p>12 0.69857591 <a title="235-lsi-12" href="../hunch_net-2009/hunch_net-2009-05-02-Wielding_a_New_Abstraction.html">351 hunch net-2009-05-02-Wielding a New Abstraction</a></p>
<p>13 0.69423038 <a title="235-lsi-13" href="../hunch_net-2007/hunch_net-2007-07-06-Idempotent-capable_Predictors.html">253 hunch net-2007-07-06-Idempotent-capable Predictors</a></p>
<p>14 0.69236308 <a title="235-lsi-14" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>15 0.69014442 <a title="235-lsi-15" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>16 0.68075246 <a title="235-lsi-16" href="../hunch_net-2005/hunch_net-2005-01-31-Watchword%3A_Assumption.html">7 hunch net-2005-01-31-Watchword: Assumption</a></p>
<p>17 0.66681111 <a title="235-lsi-17" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>18 0.66232181 <a title="235-lsi-18" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>19 0.65733266 <a title="235-lsi-19" href="../hunch_net-2011/hunch_net-2011-03-19-The_Ideal_Large_Scale_Learning_Class.html">426 hunch net-2011-03-19-The Ideal Large Scale Learning Class</a></p>
<p>20 0.6538499 <a title="235-lsi-20" href="../hunch_net-2005/hunch_net-2005-02-03-Learning_Theory%2C_by_assumption.html">12 hunch net-2005-02-03-Learning Theory, by assumption</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.014), (6, 0.04), (16, 0.016), (35, 0.07), (38, 0.012), (39, 0.021), (42, 0.233), (45, 0.057), (50, 0.036), (68, 0.046), (69, 0.016), (71, 0.122), (74, 0.112), (76, 0.043), (82, 0.04), (95, 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.93340003 <a title="235-lda-1" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>Introduction: Attempts to abstract and study machine learning are within some given
framework or mathematical model. It turns out that all of these models are
significantly flawed for the purpose of studying machine learning. I've
created a table (below) outlining the major flaws in some common models of
machine learning.The point here is not simply "woe unto us". There are several
implications which seem important.The multitude of models is a point of
continuing confusion. It is common for people to learn about machine learning
within one framework which often becomes there "home framework" through which
they attempt to filter all machine learning. (Have you met people who can only
think in terms of kernels? Only via Bayes Law? Only via PAC Learning?)
Explicitly understanding the existence of these other frameworks can help
resolve the confusion. This is particularly important when reviewing and
particularly important for students.Algorithms which conform to multiple
approaches can have substantial</p><p>2 0.88458598 <a title="235-lda-2" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>Introduction: In the quest to understand what good reviewing is, perhaps it's worthwhile to
think about what good research is. One way to think about good research is in
terms of a producer/consumer model.In the producer/consumer model of research,
for any element of research there are producers (authors and coauthors of
papers, for example) and consumers (people who use the papers to make new
papers or code solving problems). An produced bit of research is judged as
"good" if it is used by many consumers. There are two basic questions which
immediately arise:Is this a good model of research?Are there alternatives?The
producer/consumer model has some difficulties which can be (partially)
addressed.Disconnect.A group of people doing research on some subject may
become disconnected from the rest of the world. Each person uses the research
of other people in the group so it appears good research is being done, but
the group has no impact on the rest of the world. One way to detect this is by
looking at</p><p>3 0.87612206 <a title="235-lda-3" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don't indulge in posters forICML, but this year is naturally an
exception for me. If you want one, there are a small numberleft here, if you
sign up before February.It also seems worthwhile to give some sense of the
scope and reviewing criteria for ICML for authors considering submitting
papers. At ICML, the (very large) program committee does the reviewing which
informs final decisions by area chairs on most papers. Program chairs setup
the process, deal with exceptions or disagreements, and provide advice for the
reviewing process. Providing advice is tricky (and easily misleading) because
a conference is a community, and in the end the aggregate interests of the
community determine the conference. Nevertheless, as a program chair this year
it seems worthwhile to state the overall philosophy I have and what I plan to
encourage (and occasionally discourage).At the highest level, I believe ICML
exists to further research into machine learning, which I generally think of
as</p><p>4 0.87583619 <a title="235-lda-4" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>Introduction: Exploration is one of the big unsolved problems in machine learning. This
isn't for lack of trying--there are many models of exploration which have been
analyzed in many different ways by many different groups of people. At some
point, it is worthwhile to sit back and see what has been done across these
many models.Reinforcement Learning(1). Reinforcement learning has
traditionally focused on Markov Decision Processes where the next states'is
given by a conditional distributionP(s'|s,a)given the current statesand
actiona. The typical result here is that certain specific algorithms
controlling an agent can behave withineof optimal for horizonTexcept
forpoly(1/e,T,S,A)"wasted" experiences (with high probability). This started
withE3bySatinder SinghandMichael Kearns.Sham Kakade's thesishas significant
discussion. Extensions have typically been of the form "under extra
assumptions, we can prove more", for exampleFactored-E3andMetric-E3. (It turns
out that the number of wasted samples can b</p><p>5 0.87419009 <a title="235-lda-5" href="../hunch_net-2008/hunch_net-2008-05-23-Three_levels_of_addressing_the_Netflix_Prize.html">301 hunch net-2008-05-23-Three levels of addressing the Netflix Prize</a></p>
<p>Introduction: In October 2006, the online movie renter, Netflix, announced theNetflix
Prizecontest. They published a comprehensive dataset including more than 100
million movie ratings, which were performed by about 480,000 real customers on
17,770 movies.Ã‚ÂCompetitors in the challenge are required to estimate a few
million ratings.Ã‚ÂTo win the "grand prize," they need to deliver a 10%
improvement in the prediction error compared with the results of Cinematch,
Netflix's proprietary recommender system. Best current results deliver
9.12%improvement, which is quite close to the 10% goal, yet painfully
distant.Ã‚ÂThe Netflix Prize breathed new life and excitement into recommender
systems research. The competition allowed the wide research community to
access a large scale, real life dataset. Beyond this, the competition changed
the rules of the game. Claiming that your nice idea could outperform some
mediocre algorithms on some toy dataset is no longer acceptable. Now
researchers should face a new gol</p><p>6 0.87032068 <a title="235-lda-6" href="../hunch_net-2005/hunch_net-2005-11-26-The_Design_of_an_Optimal_Research_Environment.html">132 hunch net-2005-11-26-The Design of an Optimal Research Environment</a></p>
<p>7 0.8694616 <a title="235-lda-7" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>8 0.86869431 <a title="235-lda-8" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>9 0.86769503 <a title="235-lda-9" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>10 0.86757034 <a title="235-lda-10" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>11 0.86599833 <a title="235-lda-11" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>12 0.86521035 <a title="235-lda-12" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<p>13 0.86499637 <a title="235-lda-13" href="../hunch_net-2006/hunch_net-2006-09-28-Programming_Languages_for_Machine_Learning_Implementations.html">210 hunch net-2006-09-28-Programming Languages for Machine Learning Implementations</a></p>
<p>14 0.86370289 <a title="235-lda-14" href="../hunch_net-2010/hunch_net-2010-06-13-The_Good_News_on_Exploration_and_Learning.html">400 hunch net-2010-06-13-The Good News on Exploration and Learning</a></p>
<p>15 0.86361045 <a title="235-lda-15" href="../hunch_net-2008/hunch_net-2008-06-27-Reviewing_Horror_Stories.html">304 hunch net-2008-06-27-Reviewing Horror Stories</a></p>
<p>16 0.86325771 <a title="235-lda-16" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>17 0.86217725 <a title="235-lda-17" href="../hunch_net-2010/hunch_net-2010-01-24-Specializations_of_the_Master_Problem.html">388 hunch net-2010-01-24-Specializations of the Master Problem</a></p>
<p>18 0.86206108 <a title="235-lda-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.86190742 <a title="235-lda-19" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>20 0.86054933 <a title="235-lda-20" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
