<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2012" href="../home/high_scalability-2012_home.html">high_scalability-2012</a> <a title="high_scalability-2012-1218" href="#">high_scalability-2012-1218</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2012-1218-html" href="http://highscalability.com//blog/2012/3/29/strategy-exploit-processor-affinity-for-high-and-predictable.html">html</a></p><p>Introduction: Martin Thompson wrote a really interestingarticleon the beneficial performance
impact of taking advantage of Processor Affinity:The interesting thing I've
observed is that the unpinned test will follow a step function of
unpredictable performance.  Across many runs I've seen different patterns but
all similar in this step function nature.  For the pinned tests I get
consistent throughput with no step pattern and always the greatest
throughput.The idea is by assigning a thread to a particular CPU that when a
thread is rescheduled to run on the same CPU, it can take advantage of the
"accumulated  state in the processor, including instructions and data in the
cache."  With multi-core chips the norm now, you may want to decide for
yourself how to assign work to cores and not let the OS do it for you. The
results are surprisingly strong.</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('step', 0.309), ('pinned', 0.262), ('processor', 0.233), ('function', 0.22), ('beneficial', 0.219), ('norm', 0.219), ('accumulated', 0.213), ('assigning', 0.192), ('thompson', 0.189), ('thread', 0.181), ('affinity', 0.178), ('advantage', 0.17), ('martin', 0.168), ('unpredictable', 0.167), ('observed', 0.165), ('assign', 0.156), ('instructions', 0.151), ('chips', 0.149), ('greatest', 0.143), ('surprisingly', 0.133)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999994 <a title="1218-tfidf-1" href="../high_scalability-2012/high_scalability-2012-03-29-Strategy%3A_Exploit_Processor_Affinity_for_High_and_Predictable_Performance.html">1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</a></p>
<p>Introduction: Martin Thompson wrote a really interestingarticleon the beneficial performance
impact of taking advantage of Processor Affinity:The interesting thing I've
observed is that the unpinned test will follow a step function of
unpredictable performance.  Across many runs I've seen different patterns but
all similar in this step function nature.  For the pinned tests I get
consistent throughput with no step pattern and always the greatest
throughput.The idea is by assigning a thread to a particular CPU that when a
thread is rescheduled to run on the same CPU, it can take advantage of the
"accumulated  state in the processor, including instructions and data in the
cache."  With multi-core chips the norm now, you may want to decide for
yourself how to assign work to cores and not let the OS do it for you. The
results are surprisingly strong.</p><p>2 0.21984844 <a title="1218-tfidf-2" href="../high_scalability-2013/high_scalability-2013-10-23-Strategy%3A_Use_Linux_Taskset_to_Pin_Processes_or_Let_the_OS_Schedule_It%3F.html">1536 high scalability-2013-10-23-Strategy: Use Linux Taskset to Pin Processes or Let the OS Schedule It?</a></p>
<p>Introduction: This question comes from Ulysses on aninteresting threadfrom the Mechanical
Sympathy news group, especially given how multiple processors are now the
norm:Ulysses:On an 8xCPU Linux instance,  is it at all advantageous to use the
Linux taskset command to pin an 8xJVM process set (co-ordinated as a
www.infinispan.org distributed cache/data grid) to a specific CPU affinity set
(i.e. pin JVM0 process to CPU 0, JVM1 process to CPU1, ...., JVM7process to
CPU 7) vs. just letting the Linux OS use its default mechanism for
provisioning the 8xJVM process set to the available CPUs?In effrort to seek an
optimal point (in the full event space), what are the conceptual trade-offs in
considering "searching" each permutation of provisioning an 8xJVM process set
to an 8xCPU set via taskset?Giventaskset is they key to the question, it would
help to have a definition:Used to set or retrieve the CPU affinity of a
running process given its PID or to launch a new COMMAND with a given CPU
affinity.  CPU affi</p><p>3 0.14116517 <a title="1218-tfidf-3" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>Introduction: Martin Thompson, a high-performance technology geek, has written an awesome
post,Fun with my-Channels Nirvana and Azul Zing. In it Martin shows the
process and techniques he used to take an existing messaging product, written
in Java, and increase throughput by 32X and reduce latency by  20X. The
article is very well written with lots of interesting details that make it
well worth reading.The TechniquesThe techniques are a good mix of Java
independent approaches, things you may have heard of before, things you
probably haven't heard of  before, and Java specific heroics. The obvious
winning technique is to create a lock free flow through the system. This
shouldn't be surprising as Martin teaches what sounds like a really goodlock-
free concurrency course.Do not use locks in the main transaction flow because
they cause context switches, and therefore latency and unpredictable
jitter.Never have more threads that need to run than you have cores
available.Set affinity of threads to cores,</p><p>4 0.12414654 <a title="1218-tfidf-4" href="../high_scalability-2008/high_scalability-2008-01-29-Speed_up_%28Oracle%29_database_code_with_result_caching.html">230 high scalability-2008-01-29-Speed up (Oracle) database code with result caching</a></p>
<p>Introduction: One of the most interesting new features of Oracle 11 is the new function
result caching mechanism. Until now, making sure that a PL/SQL function gets
executed only as many times as necessary was a black art. The new caching
system makes that quite easy -- here is how it works.</p><p>5 0.10562894 <a title="1218-tfidf-5" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><p>6 0.10437069 <a title="1218-tfidf-6" href="../high_scalability-2012/high_scalability-2012-09-10-Russ%E2%80%99_10_Ingredient_Recipe_for_Making_1_Million_TPS_on_%245K_Hardware.html">1319 high scalability-2012-09-10-Russ’ 10 Ingredient Recipe for Making 1 Million TPS on $5K Hardware</a></p>
<p>7 0.10314035 <a title="1218-tfidf-7" href="../high_scalability-2008/high_scalability-2008-10-01-The_Pattern_Bible_for_Distributed_Computing.html">400 high scalability-2008-10-01-The Pattern Bible for Distributed Computing</a></p>
<p>8 0.093684167 <a title="1218-tfidf-8" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>9 0.091502979 <a title="1218-tfidf-9" href="../high_scalability-2013/high_scalability-2013-01-21-Processing_100_Million_Pixels_a_Day_-_Small_Amounts_of_Contention_Cause_Big_Problems_at_Scale.html">1390 high scalability-2013-01-21-Processing 100 Million Pixels a Day - Small Amounts of Contention Cause Big Problems at Scale</a></p>
<p>10 0.090282634 <a title="1218-tfidf-10" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>11 0.086897977 <a title="1218-tfidf-11" href="../high_scalability-2013/high_scalability-2013-06-13-Busting_4_Modern_Hardware_Myths_-_Are_Memory%2C_HDDs%2C_and_SSDs_Really_Random_Access%3F.html">1475 high scalability-2013-06-13-Busting 4 Modern Hardware Myths - Are Memory, HDDs, and SSDs Really Random Access?</a></p>
<p>12 0.085526086 <a title="1218-tfidf-12" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>13 0.082503796 <a title="1218-tfidf-13" href="../high_scalability-2010/high_scalability-2010-11-09-The_Tera-Scale_Effect_.html">939 high scalability-2010-11-09-The Tera-Scale Effect </a></p>
<p>14 0.080909818 <a title="1218-tfidf-14" href="../high_scalability-2008/high_scalability-2008-05-10-Hitting_300_SimbleDB_Requests_Per_Second_on_a_Small_EC2_Instance.html">317 high scalability-2008-05-10-Hitting 300 SimbleDB Requests Per Second on a Small EC2 Instance</a></p>
<p>15 0.077782221 <a title="1218-tfidf-15" href="../high_scalability-2014/high_scalability-2014-05-06-The_Quest_for_Database_Scale%3A_the_1_M_TPS_challenge_-_Three_Design_Points_and_Five_common_Bottlenecks_to_avoid.html">1643 high scalability-2014-05-06-The Quest for Database Scale: the 1 M TPS challenge - Three Design Points and Five common Bottlenecks to avoid</a></p>
<p>16 0.07590355 <a title="1218-tfidf-16" href="../high_scalability-2013/high_scalability-2013-03-25-AppBackplane_-_A_Framework_for_Supporting_Multiple_Application_Architectures.html">1429 high scalability-2013-03-25-AppBackplane - A Framework for Supporting Multiple Application Architectures</a></p>
<p>17 0.074504443 <a title="1218-tfidf-17" href="../high_scalability-2012/high_scalability-2012-04-20-Stuff_The_Internet_Says_On_Scalability_For_April_20%2C_2012.html">1231 high scalability-2012-04-20-Stuff The Internet Says On Scalability For April 20, 2012</a></p>
<p>18 0.073749833 <a title="1218-tfidf-18" href="../high_scalability-2013/high_scalability-2013-07-05-Stuff_The_Internet_Says_On_Scalability_For_July_5%2C_2013.html">1487 high scalability-2013-07-05-Stuff The Internet Says On Scalability For July 5, 2013</a></p>
<p>19 0.073143564 <a title="1218-tfidf-19" href="../high_scalability-2013/high_scalability-2013-11-13-Google%3A_Multiplex_Multiple_Works_Loads_on_Computers_to_Increase_Machine_Utilization_and_Save_Money.html">1548 high scalability-2013-11-13-Google: Multiplex Multiple Works Loads on Computers to Increase Machine Utilization and Save Money</a></p>
<p>20 0.067900784 <a title="1218-tfidf-20" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.098), (1, 0.06), (2, -0.0), (3, 0.028), (4, -0.031), (5, 0.025), (6, 0.047), (7, 0.065), (8, -0.078), (9, -0.02), (10, 0.004), (11, 0.007), (12, 0.036), (13, -0.008), (14, -0.027), (15, -0.055), (16, 0.033), (17, -0.016), (18, -0.032), (19, 0.014), (20, 0.01), (21, -0.032), (22, -0.038), (23, 0.012), (24, 0.008), (25, -0.021), (26, -0.008), (27, -0.015), (28, 0.048), (29, 0.001), (30, 0.011), (31, 0.034), (32, 0.002), (33, -0.006), (34, 0.023), (35, 0.005), (36, -0.011), (37, 0.01), (38, 0.004), (39, 0.031), (40, -0.014), (41, 0.011), (42, 0.042), (43, -0.028), (44, 0.028), (45, 0.014), (46, 0.009), (47, -0.018), (48, 0.044), (49, 0.023)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96754742 <a title="1218-lsi-1" href="../high_scalability-2012/high_scalability-2012-03-29-Strategy%3A_Exploit_Processor_Affinity_for_High_and_Predictable_Performance.html">1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</a></p>
<p>Introduction: Martin Thompson wrote a really interestingarticleon the beneficial performance
impact of taking advantage of Processor Affinity:The interesting thing I've
observed is that the unpinned test will follow a step function of
unpredictable performance.  Across many runs I've seen different patterns but
all similar in this step function nature.  For the pinned tests I get
consistent throughput with no step pattern and always the greatest
throughput.The idea is by assigning a thread to a particular CPU that when a
thread is rescheduled to run on the same CPU, it can take advantage of the
"accumulated  state in the processor, including instructions and data in the
cache."  With multi-core chips the norm now, you may want to decide for
yourself how to assign work to cores and not let the OS do it for you. The
results are surprisingly strong.</p><p>2 0.89525914 <a title="1218-lsi-2" href="../high_scalability-2013/high_scalability-2013-10-23-Strategy%3A_Use_Linux_Taskset_to_Pin_Processes_or_Let_the_OS_Schedule_It%3F.html">1536 high scalability-2013-10-23-Strategy: Use Linux Taskset to Pin Processes or Let the OS Schedule It?</a></p>
<p>Introduction: This question comes from Ulysses on aninteresting threadfrom the Mechanical
Sympathy news group, especially given how multiple processors are now the
norm:Ulysses:On an 8xCPU Linux instance,  is it at all advantageous to use the
Linux taskset command to pin an 8xJVM process set (co-ordinated as a
www.infinispan.org distributed cache/data grid) to a specific CPU affinity set
(i.e. pin JVM0 process to CPU 0, JVM1 process to CPU1, ...., JVM7process to
CPU 7) vs. just letting the Linux OS use its default mechanism for
provisioning the 8xJVM process set to the available CPUs?In effrort to seek an
optimal point (in the full event space), what are the conceptual trade-offs in
considering "searching" each permutation of provisioning an 8xJVM process set
to an 8xCPU set via taskset?Giventaskset is they key to the question, it would
help to have a definition:Used to set or retrieve the CPU affinity of a
running process given its PID or to launch a new COMMAND with a given CPU
affinity.  CPU affi</p><p>3 0.78963631 <a title="1218-lsi-3" href="../high_scalability-2012/high_scalability-2012-09-10-Russ%E2%80%99_10_Ingredient_Recipe_for_Making_1_Million_TPS_on_%245K_Hardware.html">1319 high scalability-2012-09-10-Russ’ 10 Ingredient Recipe for Making 1 Million TPS on $5K Hardware</a></p>
<p>Introduction: My name isRussell Sullivan, I am the author of AlchemyDB: a highly flexible
NoSQL/SQL/DocumentStore/GraphDB-datastore built on top of redis. I have spent
the last several years trying to find a way to sanely house multiple
datastore-genres under one roof while (almost paradoxically) pushing
performance to its limits.I recently joined the NoSQL
companyAerospike(formerly Citrusleaf) with the goal of incrementally grafting
AlchemyDB's flexible data-modeling capabilities onto Aerospike's high-velocity
horizontally-scalable key-value data-fabric. We recently completed a peak-
performanceTPS optimization project: starting at 200K TPS, pushing to the
recent community edition launch at 500K TPS, and finally arriving at our 2012
goal:1M TPS on $5K hardware.Getting to one million over-the-wire client-server
database-requests per-second on a single machine costing $5K is a balance
between trimming overhead on many axes and using a shared nothing architecture
toisolatethe paths taken by unique req</p><p>4 0.78707391 <a title="1218-lsi-4" href="../high_scalability-2009/high_scalability-2009-06-23-Learn_How_to_Exploit_Multiple_Cores_for_Better_Performance_and_Scalability.html">636 high scalability-2009-06-23-Learn How to Exploit Multiple Cores for Better Performance and Scalability</a></p>
<p>Introduction: InfoQueue has thisexcellent talk by Brian Goetzon the new features being added
to Java SE 7 that will allow programmers to fully exploit our massively multi-
processor future. While the talk is about Java it's really more general than
that and there's a lot to learn here for everyone.Brian starts with a short,
coherent, and compelling explanation of why programmers can't expect to be
saved by ever faster CPUs and why we must learn to exploit the strengths of
multiple core computers to make our software go faster.Some techniques for
exploiting multiple cores are given in an equally short, coherent, and
compelling explanation of why divide and conquer as the secret to multi-core
bliss, fork-join, how the Java approach differs from map-reduce, and lots of
other juicy topics.The multi-core "problem" is only going to get worse. Tilera
founder Anant Agarwalestimates by 2017embedded processors could have 4,096
cores, server CPUs might have 512 cores and desktop chips could use 128 cores.
Some</p><p>5 0.77850252 <a title="1218-lsi-5" href="../high_scalability-2009/high_scalability-2009-02-01-More_Chips_Means_Less_Salsa.html">505 high scalability-2009-02-01-More Chips Means Less Salsa</a></p>
<p>Introduction: Yes, I just got through watching the Superbowl so chips and salsa are on my
mind and in my stomach. In recreational eating more chips requires downing
more salsa. With mulitcore chips it turns out as cores go up salsa goes down,
salsa obviously being a metaphor for speed.Sandia National Laboratories found
in their simulations:a significant increase in speed going from two to four
multicores, but an insignificant increase from four to eight multicores.
Exceeding eight multicores causes a decrease in speed. Sixteen multicores
perform barely as well as two, and after that, a steep decline is registered
as more cores are added. The problem is the lack of memory bandwidth as well
as contention between processors over the memory bus available to each
processor.The implication for those following a diagonal scaling strategy is
to work like heck to make your system fit within eight multicores. After that
you'll need to consider some sort of partitioning strategy. What's interesting
is the rese</p><p>6 0.7745896 <a title="1218-lsi-6" href="../high_scalability-2012/high_scalability-2012-05-02-12_Ways_to_Increase_Throughput_by_32X_and_Reduce_Latency_by__20X.html">1237 high scalability-2012-05-02-12 Ways to Increase Throughput by 32X and Reduce Latency by  20X</a></p>
<p>7 0.74986428 <a title="1218-lsi-7" href="../high_scalability-2013/high_scalability-2013-06-06-Paper%3A_Memory_Barriers%3A_a_Hardware_View_for_Software_Hackers.html">1471 high scalability-2013-06-06-Paper: Memory Barriers: a Hardware View for Software Hackers</a></p>
<p>8 0.72593337 <a title="1218-lsi-8" href="../high_scalability-2013/high_scalability-2013-05-08-Typesafe_Interview%3A_Scala_%2B_Akka_is_an_IaaS_for_Your_Process_Architecture.html">1454 high scalability-2013-05-08-Typesafe Interview: Scala + Akka is an IaaS for Your Process Architecture</a></p>
<p>9 0.72397196 <a title="1218-lsi-9" href="../high_scalability-2009/high_scalability-2009-03-12-Google_TechTalk%3A_Amdahl%27s_Law_in_the_Multicore_Era.html">534 high scalability-2009-03-12-Google TechTalk: Amdahl's Law in the Multicore Era</a></p>
<p>10 0.72198522 <a title="1218-lsi-10" href="../high_scalability-2014/high_scalability-2014-05-21-9_Principles_of_High_Performance_Programs.html">1652 high scalability-2014-05-21-9 Principles of High Performance Programs</a></p>
<p>11 0.7002303 <a title="1218-lsi-11" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>12 0.69721365 <a title="1218-lsi-12" href="../high_scalability-2012/high_scalability-2012-08-30-Dramatically_Improving_Performance_by_Debugging_Brutally_Complex_Prolems.html">1314 high scalability-2012-08-30-Dramatically Improving Performance by Debugging Brutally Complex Prolems</a></p>
<p>13 0.69492853 <a title="1218-lsi-13" href="../high_scalability-2013/high_scalability-2013-05-13-The_Secret_to_10_Million_Concurrent_Connections_-The_Kernel_is_the_Problem%2C_Not_the_Solution.html">1456 high scalability-2013-05-13-The Secret to 10 Million Concurrent Connections -The Kernel is the Problem, Not the Solution</a></p>
<p>14 0.69414699 <a title="1218-lsi-14" href="../high_scalability-2014/high_scalability-2014-05-01-Paper%3A_Can_Programming_Be_Liberated_From_The_Von_Neumann_Style%3F_.html">1641 high scalability-2014-05-01-Paper: Can Programming Be Liberated From The Von Neumann Style? </a></p>
<p>15 0.69044942 <a title="1218-lsi-15" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>16 0.68298942 <a title="1218-lsi-16" href="../high_scalability-2008/high_scalability-2008-05-10-Hitting_300_SimbleDB_Requests_Per_Second_on_a_Small_EC2_Instance.html">317 high scalability-2008-05-10-Hitting 300 SimbleDB Requests Per Second on a Small EC2 Instance</a></p>
<p>17 0.68133789 <a title="1218-lsi-17" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>18 0.68124723 <a title="1218-lsi-18" href="../high_scalability-2010/high_scalability-2010-10-04-Paper%3A_An_Analysis_of_Linux_Scalability_to_Many_Cores__.html">914 high scalability-2010-10-04-Paper: An Analysis of Linux Scalability to Many Cores  </a></p>
<p>19 0.66459048 <a title="1218-lsi-19" href="../high_scalability-2010/high_scalability-2010-12-03-GPU_vs_CPU_Smackdown_%3A_The_Rise_of_Throughput-Oriented_Architectures.html">953 high scalability-2010-12-03-GPU vs CPU Smackdown : The Rise of Throughput-Oriented Architectures</a></p>
<p>20 0.66037208 <a title="1218-lsi-20" href="../high_scalability-2012/high_scalability-2012-03-06-Ask_For_Forgiveness_Programming_-_Or_How_We%27ll_Program_1000_Cores.html">1204 high scalability-2012-03-06-Ask For Forgiveness Programming - Or How We'll Program 1000 Cores</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.084), (2, 0.201), (40, 0.087), (59, 0.322), (61, 0.065), (79, 0.118)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.84819007 <a title="1218-lda-1" href="../high_scalability-2009/high_scalability-2009-03-11-13_Screencasts_on_How_to_Scale_Rails.html">530 high scalability-2009-03-11-13 Screencasts on How to Scale Rails</a></p>
<p>Introduction: Gregg Pollack has made 13 screen casts on how to scale rails:Episode #1 - Page
ResponsivenessEpisode #2 - Page CachingEpisode #3 - Cache ExpirationEpisode #4
- New Relic RPMEpisode #5 - Advanced Page CachingEpisode #6 - Action
CachingEpisode #7 - Fragment CachingEpisode #8 - MemcachedEpisode #9 - Taylor
Weibley & DatabasesEpisode #10 - Client-side CachingEpisode #11 - Advanced
HTTP CachingEpisode #12 - Jesse Newland & DeploymentEpisode #13 - Jim Gochee &
Advanced RPMFor a good InfoQ interview with Greg take a look atGregg Pollack
and the How-To of Scaling Rails.</p><p>2 0.83779031 <a title="1218-lda-2" href="../high_scalability-2009/high_scalability-2009-07-16-Scalable_Web_Architectures_and_Application_State.html">656 high scalability-2009-07-16-Scalable Web Architectures and Application State</a></p>
<p>Introduction: In this article we follow a hypothetical programmer, Damian, on his quest to
make his web application scalable.Read the full article on Bytepawn</p><p>same-blog 3 0.81850809 <a title="1218-lda-3" href="../high_scalability-2012/high_scalability-2012-03-29-Strategy%3A_Exploit_Processor_Affinity_for_High_and_Predictable_Performance.html">1218 high scalability-2012-03-29-Strategy: Exploit Processor Affinity for High and Predictable Performance</a></p>
<p>Introduction: Martin Thompson wrote a really interestingarticleon the beneficial performance
impact of taking advantage of Processor Affinity:The interesting thing I've
observed is that the unpinned test will follow a step function of
unpredictable performance.  Across many runs I've seen different patterns but
all similar in this step function nature.  For the pinned tests I get
consistent throughput with no step pattern and always the greatest
throughput.The idea is by assigning a thread to a particular CPU that when a
thread is rescheduled to run on the same CPU, it can take advantage of the
"accumulated  state in the processor, including instructions and data in the
cache."  With multi-core chips the norm now, you may want to decide for
yourself how to assign work to cores and not let the OS do it for you. The
results are surprisingly strong.</p><p>4 0.81674999 <a title="1218-lda-4" href="../high_scalability-2013/high_scalability-2013-10-23-Strategy%3A_Use_Linux_Taskset_to_Pin_Processes_or_Let_the_OS_Schedule_It%3F.html">1536 high scalability-2013-10-23-Strategy: Use Linux Taskset to Pin Processes or Let the OS Schedule It?</a></p>
<p>Introduction: This question comes from Ulysses on aninteresting threadfrom the Mechanical
Sympathy news group, especially given how multiple processors are now the
norm:Ulysses:On an 8xCPU Linux instance,  is it at all advantageous to use the
Linux taskset command to pin an 8xJVM process set (co-ordinated as a
www.infinispan.org distributed cache/data grid) to a specific CPU affinity set
(i.e. pin JVM0 process to CPU 0, JVM1 process to CPU1, ...., JVM7process to
CPU 7) vs. just letting the Linux OS use its default mechanism for
provisioning the 8xJVM process set to the available CPUs?In effrort to seek an
optimal point (in the full event space), what are the conceptual trade-offs in
considering "searching" each permutation of provisioning an 8xJVM process set
to an 8xCPU set via taskset?Giventaskset is they key to the question, it would
help to have a definition:Used to set or retrieve the CPU affinity of a
running process given its PID or to launch a new COMMAND with a given CPU
affinity.  CPU affi</p><p>5 0.80960751 <a title="1218-lda-5" href="../high_scalability-2014/high_scalability-2014-01-20-8_Ways_Stardog_Made_its_Database_Insanely_Scalable.html">1582 high scalability-2014-01-20-8 Ways Stardog Made its Database Insanely Scalable</a></p>
<p>Introduction: Stardog makes a commercial graph database that is a great example of what can
be accomplished with a scale-up strategy on BigIron. In a recent article
StarDog described how they made their new 2.1 release insanely scalable,
improving query scalability by about 3 orders of magnitude and it can now
handle 50 billion triples on a $10,000 server with 32 cores and 256 GB RAM. It
can also load 20B datasets at 300,000 triples per second. What did they do
that you can also do?Avoid locks by using non-blocking algorithms and data
structures. For example, moving from BitSet to ConcurrentLinkedQueue.Use
ThreadLocal aggressively to reduce thread contention and avoid
synchronization.Batch LRU evictions in a single thread. Triggered by several
LRU caches becoming problematic when evictions were being swamped by
additions. Downside is batching increases memory pressure and GC times.Move to
SHA1 for hashing URIs, bnodes, and literal values. Making hash collisions
nearly impossible enable significant s</p><p>6 0.80654645 <a title="1218-lda-6" href="../high_scalability-2012/high_scalability-2012-08-30-Dramatically_Improving_Performance_by_Debugging_Brutally_Complex_Prolems.html">1314 high scalability-2012-08-30-Dramatically Improving Performance by Debugging Brutally Complex Prolems</a></p>
<p>7 0.80617034 <a title="1218-lda-7" href="../high_scalability-2012/high_scalability-2012-09-15-4_Reasons_Facebook_Dumped_HTML5_and_Went_Native.html">1323 high scalability-2012-09-15-4 Reasons Facebook Dumped HTML5 and Went Native</a></p>
<p>8 0.75055355 <a title="1218-lda-8" href="../high_scalability-2010/high_scalability-2010-06-30-Paper%3A_GraphLab%3A_A_New_Framework_For_Parallel_Machine_Learning.html">850 high scalability-2010-06-30-Paper: GraphLab: A New Framework For Parallel Machine Learning</a></p>
<p>9 0.71870738 <a title="1218-lda-9" href="../high_scalability-2012/high_scalability-2012-07-11-FictionPress%3A_Publishing_6_Million_Works_of_Fiction_on_the_Web.html">1281 high scalability-2012-07-11-FictionPress: Publishing 6 Million Works of Fiction on the Web</a></p>
<p>10 0.67373437 <a title="1218-lda-10" href="../high_scalability-2014/high_scalability-2014-04-18-Stuff_The_Internet_Says_On_Scalability_For_April_18th%2C_2014.html">1634 high scalability-2014-04-18-Stuff The Internet Says On Scalability For April 18th, 2014</a></p>
<p>11 0.67176062 <a title="1218-lda-11" href="../high_scalability-2009/high_scalability-2009-05-28-Scaling_PostgreSQL_using_CUDA.html">609 high scalability-2009-05-28-Scaling PostgreSQL using CUDA</a></p>
<p>12 0.66545898 <a title="1218-lda-12" href="../high_scalability-2011/high_scalability-2011-05-11-Troubleshooting_response_time_problems_%E2%80%93_why_you_cannot_trust_your_system_metrics.html">1038 high scalability-2011-05-11-Troubleshooting response time problems – why you cannot trust your system metrics</a></p>
<p>13 0.66162705 <a title="1218-lda-13" href="../high_scalability-2012/high_scalability-2012-06-15-Cloud_Bursting_between_AWS_and_Rackspace.html">1264 high scalability-2012-06-15-Cloud Bursting between AWS and Rackspace</a></p>
<p>14 0.632357 <a title="1218-lda-14" href="../high_scalability-2010/high_scalability-2010-08-12-Think_of_Latency_as_a_Pseudo-permanent_Network_Partition.html">879 high scalability-2010-08-12-Think of Latency as a Pseudo-permanent Network Partition</a></p>
<p>15 0.63009214 <a title="1218-lda-15" href="../high_scalability-2013/high_scalability-2013-07-17-How_do_you_create_a_100th_Monkey_software_development_culture%3F.html">1492 high scalability-2013-07-17-How do you create a 100th Monkey software development culture?</a></p>
<p>16 0.62496579 <a title="1218-lda-16" href="../high_scalability-2013/high_scalability-2013-02-13-7_Sensible_and_1_Really_Surprising_Way_EVE_Online_Scales_to_Play_Huge_Games.html">1405 high scalability-2013-02-13-7 Sensible and 1 Really Surprising Way EVE Online Scales to Play Huge Games</a></p>
<p>17 0.62183982 <a title="1218-lda-17" href="../high_scalability-2010/high_scalability-2010-02-01-What_Will_Kill_the_Cloud%3F.html">768 high scalability-2010-02-01-What Will Kill the Cloud?</a></p>
<p>18 0.6209017 <a title="1218-lda-18" href="../high_scalability-2008/high_scalability-2008-05-27-Should_Twitter_be_an_All-You-Can-Eat_Buffet_or_a_Vending_Machine%3F.html">330 high scalability-2008-05-27-Should Twitter be an All-You-Can-Eat Buffet or a Vending Machine?</a></p>
<p>19 0.61769521 <a title="1218-lda-19" href="../high_scalability-2012/high_scalability-2012-04-03-Hazelcast_2.0%3A_Big_Data_In-Memory.html">1221 high scalability-2012-04-03-Hazelcast 2.0: Big Data In-Memory</a></p>
<p>20 0.61553419 <a title="1218-lda-20" href="../high_scalability-2010/high_scalability-2010-02-15-The_Amazing_Collective_Compute_Power_of_the_Ambient_Cloud.html">778 high scalability-2010-02-15-The Amazing Collective Compute Power of the Ambient Cloud</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
