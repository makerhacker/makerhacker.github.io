<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2001" href="../home/nips2001_home.html">nips2001</a> <a title="nips-2001-4" href="#">nips2001-4</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</h1>
<br/><p>Source: <a title="nips-2001-4-pdf" href="http://papers.nips.cc/paper/2016-algonquin-learning-dynamic-noise-models-from-noisy-speech-for-robust-speech-recognition.pdf">pdf</a></p><p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>Reference: <a title="nips-2001-4-reference" href="../nips2001_reference/nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition_reference.html">text</a></p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 ALGONQUIN - Learning dynamic noise models from noisy speech for robust speech recognition  Brendan J. [sent-1, score-1.566]
</p><p>2 edu 2 Speech Technology Group , Microsoft Research  Abstract A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. [sent-6, score-1.255]
</p><p>3 One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. [sent-7, score-1.96]
</p><p>4 In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. [sent-8, score-2.008]
</p><p>5 We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. [sent-9, score-0.262]
</p><p>6 In many circumstances, it is not possible to obtain examples of noise without speech. [sent-10, score-0.254]
</p><p>7 Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. [sent-11, score-0.366]
</p><p>8 In this paper, we show how the noise model can be learned even when the data contains speech. [sent-12, score-0.292]
</p><p>9 In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. [sent-13, score-0.609]
</p><p>10 The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. [sent-14, score-0.547]
</p><p>11 For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. [sent-15, score-0.872]
</p><p>12 2001), where the features of noisy, distorted speech are first denoised and then fed into a speech recognition system whose acoustic recognition model is trained on clean speech. [sent-19, score-1.791]
</p><p>13 One advantage of the feature domain approach over the recognizer domain approach is that the speech modeling part of the denoising model can have much lower com-  plexity than the full acoustic recognition model. [sent-20, score-1.164]
</p><p>14 This can lead to a much faster overall system, since the denoising process uses probabilistic inference in a much smaller model. [sent-21, score-0.283]
</p><p>15 Also, since the complexity of the denoising model is much lower than the complexity of the recognizer, the denoising model can be adapted to new environments more easily, or a variety of denoising models can be stored and applied as needed. [sent-22, score-0.619]
</p><p>16 We model the log-spectra of clean speech, noise, and channel impulse response function using mixtures of Gaussians. [sent-23, score-0.68]
</p><p>17 ) The relationship between these log-spectra and the log-spectrum of the noisy speech is nonlinear, leading to a posterior distribution over the clean speech that is a mixture of non-Gaussian distributions. [sent-26, score-1.803]
</p><p>18 We show how a variational technique that makes use of an iterative 2nd order vector Taylor series approximation can be used to infer the clean speech and compute sufficient statistics for a generalized EM algorithm that can learn the noise model from noisy speech. [sent-27, score-1.721]
</p><p>19 2  ALGONQUIN's Probability Model  For clarity, we present a version of ALGONQUIN that treats frames of log-spectra independently. [sent-29, score-0.082]
</p><p>20 The extension of the version presented here to HMM models of speech, noise and channel distortion is analogous to the extension of a mixture of Gaussians to an HMM with Gaussian outputs. [sent-30, score-0.804]
</p><p>21 Following (Moreno 1996), we derive an approximate relationship between the log spectra of the clean speech, noise, channel and noisy speech. [sent-31, score-1.007]
</p><p>22 Assuming additive noise and linear channel distortion, the windowed FFT Y(j) for a particular frame (25 ms duration, spaced at 10 ms intervals) of noisy speech is related to the FFTs of the channel H(j), clean speech 5(j) and additive noise N(j) by  Y(j) = H(j)5(j)  + N(j). [sent-32, score-2.939]
</p><p>23 (1)  We use a mel-frequency scale, in which case this relationship is only approximate. [sent-33, score-0.061]
</p><p>24 However, it is quite accurate if the channel frequency response is roughly constant across each mel-frequency filter band. [sent-34, score-0.282]
</p><p>25 Assuming there is no channel distortion simplifies the description of the algorithm. [sent-36, score-0.455]
</p><p>26 To see how channel distortion can be accounted for in a nonadaptive way, see (Frey et al. [sent-37, score-0.503]
</p><p>27 The technique described in this paper for adapting the noise model can be extended to adapting the channel model. [sent-39, score-0.716]
</p><p>28 Assuming H(j) = 1, the energy spectrum is obtained as follows:  IY(j)1 2 = Y(j)*Y(j) = 5(j)* 5(j) + N(j)* N(j) + 2Re(N(j)* 5(j)) = 15(j)1 2 + IN(j)12 + 2Re(N(j)* 5(j)) , where "*,, denotes complex conjugate. [sent-40, score-0.084]
</p><p>29 If the phase of the noise and the speech are uncorrelated, the last term in the above expression is small and we can approximate  the energy spectrum as follows:  IYUW  ~  ISUW + INUW路  (2)  Although we could model these spectra directly, they are constrained to be nonnegative. [sent-41, score-1.008]
</p><p>30 To make density modeling easier, we model the log-spectrum instead. [sent-42, score-0.083]
</p><p>31 An additional benefit to this approach is that channel distortion is an additive effect in the log-spectrum domain. [sent-43, score-0.477]
</p><p>32 Taking the logarithm, we obtain a function gO that is an approximate mapping of sand n to y (see (Moreno 1996) for more details): y  ~ g([~]) = s + In(l + exp(n - s)). [sent-45, score-0.086]
</p><p>33 (4)  "T" indicates matrix transpose and InO and expO operate on the individual elements of their vector arguments. [sent-46, score-0.063]
</p><p>34 Assuming the errors in the above approximation are Gaussian, the observation likelihood is (5) p(yls,n) =N(y;g([~]),W), where W is the diagonal covariance matrix of the errors. [sent-47, score-0.039]
</p><p>35 A more precise approximation to the observation likelihood can be obtained by writing W as a function of s and n , but we assume W is constant for clarity. [sent-48, score-0.039]
</p><p>36 Using a prior p(s, n), the goal of de noising is to infer the log-spectrum of the clean speech s , given the log-spectrum ofthe noisy speech y. [sent-49, score-1.618]
</p><p>37 The minimum squared error estimate of sis s = Is sp(sly) , where p(sly) ex InP(yls, n)p(s, n). [sent-50, score-0.04]
</p><p>38 This inference is made difficult by the fact that the nonlinearity g([s n]T) in (5) makes the posterior non-Gaussian even if the prior is Gaussian. [sent-51, score-0.198]
</p><p>39 In the next section, we show how an iterative variational method that uses a 2nd order vector Taylor series approximation can be used for approximate inference and learning. [sent-52, score-0.352]
</p><p>40 We assume that a priori the speech and noise are independent - p(s , n) = p(s)p(n) - and we model each using a separate mixture of Gaussians. [sent-53, score-0.912]
</p><p>41 , NS is the class index for the clean speech and en = 1, . [sent-57, score-1.071]
</p><p>42 The mixing proportions and Gaussian components are parameterized as follows:  p(s) = LP(cS)p(slcS), p(C S) =7r~s , p(slc S) =N(s;JL~s ,~~s ), CS  We assume the covariance matrices  ~~s  and  ~~n  are diagonal. [sent-61, score-0.061]
</p><p>43 Combining (5) and (6), the joint distribution over the noisy speech, clean speech class, clean speech vector, noise class and noise vector is  p(y , s , cs, n , en) = N(y; g([~]), w)7r~sN(s; JL~s , ~~s )7r~N(n; JL~n , ~~n). [sent-62, score-2.522]
</p><p>44 (7)  Under this joint distribution, the posterior p(s, nly) is a mixture of non-Gaussian distributions. [sent-63, score-0.162]
</p><p>45 In fact, for a given speech class and noise class, the posterior p(s, nics, en , y) may have multiple modes. [sent-64, score-1.061]
</p><p>46 3  Approximating the Posterior  For the current frame of noisy speech y, ALGONQUIN approximates the posterior using a simpler, parameterized distribution, q:  p(s ,cS, n,cnly)  ~  q(s,cS,n,c n ). [sent-66, score-0.876]
</p><p>47 The "variational parameters" of q are adjusted to make this approximation accurate, and then q is used as a surrogate for the true posterior when computing 搂 and learning the noise model (c. [sent-67, score-0.461]
</p>
<br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('speech', 0.516), ('clean', 0.36), ('channel', 0.282), ('noise', 0.254), ('algonquin', 0.198), ('noisy', 0.188), ('denoising', 0.181), ('en', 0.154), ('distortion', 0.144), ('cs', 0.137), ('moreno', 0.137), ('recognizer', 0.119), ('taylor', 0.103), ('posterior', 0.096), ('recognition', 0.092), ('expo', 0.091), ('nics', 0.091), ('sly', 0.091), ('jl', 0.077), ('acoustic', 0.075), ('inference', 0.073), ('attias', 0.072), ('distorted', 0.072), ('exp', 0.07), ('mixture', 0.066), ('variational', 0.063), ('iy', 0.063), ('utterance', 0.063), ('relationship', 0.061), ('spectra', 0.06), ('approximate', 0.056), ('frey', 0.053), ('additive', 0.051), ('adapting', 0.05), ('spectrum', 0.05), ('domain', 0.049), ('frames', 0.048), ('et', 0.047), ('assuming', 0.047), ('series', 0.047), ('modeling', 0.045), ('frame', 0.044), ('technique', 0.042), ('iterative', 0.041), ('class', 0.041), ('aurora', 0.04), ('deng', 0.04), ('ffts', 0.04), ('kristjansson', 0.04), ('loud', 0.04), ('sis', 0.04), ('unsolved', 0.04), ('varga', 0.04), ('ms', 0.039), ('hmm', 0.039), ('approximation', 0.039), ('separate', 0.038), ('infer', 0.038), ('model', 0.038), ('acero', 0.036), ('freyl', 0.036), ('wall', 0.036), ('energy', 0.034), ('sufficient', 0.034), ('autoregressive', 0.034), ('eurospeech', 0.034), ('feeding', 0.034), ('gales', 0.034), ('inp', 0.034), ('nonstationary', 0.034), ('ns', 0.034), ('recognize', 0.034), ('surrogate', 0.034), ('treats', 0.034), ('windowed', 0.034), ('vector', 0.033), ('parameterized', 0.032), ('brendan', 0.032), ('brevity', 0.032), ('fft', 0.032), ('trained', 0.03), ('significantly', 0.03), ('accounted', 0.03), ('sand', 0.03), ('transpose', 0.03), ('extension', 0.029), ('probabilistic', 0.029), ('clarity', 0.029), ('community', 0.029), ('nonlinearity', 0.029), ('proportions', 0.029), ('simplifies', 0.029), ('spaced', 0.029), ('generalized', 0.028), ('em', 0.028), ('alex', 0.028), ('circumstances', 0.028), ('iterating', 0.028), ('laplace', 0.028), ('recognizing', 0.028)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999923 <a title="4-tfidf-1" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>2 0.40075579 <a title="4-tfidf-2" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>3 0.21430072 <a title="4-tfidf-3" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>4 0.18340524 <a title="4-tfidf-4" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>5 0.13298184 <a title="4-tfidf-5" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>6 0.13012515 <a title="4-tfidf-6" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>7 0.10442074 <a title="4-tfidf-7" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>8 0.092435107 <a title="4-tfidf-8" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>9 0.084090821 <a title="4-tfidf-9" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>10 0.076752707 <a title="4-tfidf-10" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>11 0.075080857 <a title="4-tfidf-11" href="./nips-2001-Multiplicative_Updates_for_Classification_by_Mixture_Models.html">129 nips-2001-Multiplicative Updates for Classification by Mixture Models</a></p>
<p>12 0.075072125 <a title="4-tfidf-12" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>13 0.072589159 <a title="4-tfidf-13" href="./nips-2001-Fast%2C_Large-Scale_Transformation-Invariant_Clustering.html">75 nips-2001-Fast, Large-Scale Transformation-Invariant Clustering</a></p>
<p>14 0.069918782 <a title="4-tfidf-14" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>15 0.067996904 <a title="4-tfidf-15" href="./nips-2001-A_Dynamic_HMM_for_On-line_Segmentation_of_Sequential_Data.html">7 nips-2001-A Dynamic HMM for On-line Segmentation of Sequential Data</a></p>
<p>16 0.067244537 <a title="4-tfidf-16" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>17 0.066526033 <a title="4-tfidf-17" href="./nips-2001-A_Parallel_Mixture_of_SVMs_for_Very_Large_Scale_Problems.html">16 nips-2001-A Parallel Mixture of SVMs for Very Large Scale Problems</a></p>
<p>18 0.065446548 <a title="4-tfidf-18" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>19 0.060233776 <a title="4-tfidf-19" href="./nips-2001-Global_Coordination_of_Local_Linear_Models.html">84 nips-2001-Global Coordination of Local Linear Models</a></p>
<p>20 0.056057468 <a title="4-tfidf-20" href="./nips-2001-Infinite_Mixtures_of_Gaussian_Process_Experts.html">95 nips-2001-Infinite Mixtures of Gaussian Process Experts</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2001_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.182), (1, 0.013), (2, -0.058), (3, -0.098), (4, -0.313), (5, 0.096), (6, 0.27), (7, -0.158), (8, 0.039), (9, -0.125), (10, 0.02), (11, 0.111), (12, -0.017), (13, 0.218), (14, -0.097), (15, 0.105), (16, -0.122), (17, -0.053), (18, -0.308), (19, 0.061), (20, -0.026), (21, -0.041), (22, 0.065), (23, 0.061), (24, 0.072), (25, -0.064), (26, 0.116), (27, -0.086), (28, 0.074), (29, 0.05), (30, -0.001), (31, 0.086), (32, 0.024), (33, 0.037), (34, -0.046), (35, -0.04), (36, -0.05), (37, 0.083), (38, 0.023), (39, -0.0), (40, 0.026), (41, -0.009), (42, -0.03), (43, 0.059), (44, -0.048), (45, 0.03), (46, -0.035), (47, 0.033), (48, -0.029), (49, -0.027)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.98605126 <a title="4-lsi-1" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>2 0.9087109 <a title="4-lsi-2" href="./nips-2001-Audio-Visual_Sound_Separation_Via_Hidden_Markov_Models.html">39 nips-2001-Audio-Visual Sound Separation Via Hidden Markov Models</a></p>
<p>Author: John R. Hershey, Michael Casey</p><p>Abstract: It is well known that under noisy conditions we can hear speech much more clearly when we read the speaker's lips. This suggests the utility of audio-visual information for the task of speech enhancement. We propose a method to exploit audio-visual cues to enable speech separation under non-stationary noise and with a single microphone. We revise and extend HMM-based speech enhancement techniques, in which signal and noise models are factori ally combined, to incorporate visual lip information and employ novel signal HMMs in which the dynamics of narrow-band and wide band components are factorial. We avoid the combinatorial explosion in the factorial model by using a simple approximate inference technique to quickly estimate the clean signals in a mixture. We present a preliminary evaluation of this approach using a small-vocabulary audio-visual database, showing promising improvements in machine intelligibility for speech enhanced using audio and visual information. 1</p><p>3 0.8917405 <a title="4-lsi-3" href="./nips-2001-Sequential_Noise_Compensation_by_Sequential_Monte_Carlo_Method.html">168 nips-2001-Sequential Noise Compensation by Sequential Monte Carlo Method</a></p>
<p>Author: K. Yao, S. Nakamura</p><p>Abstract: We present a sequential Monte Carlo method applied to additive noise compensation for robust speech recognition in time-varying noise. The method generates a set of samples according to the prior distribution given by clean speech models and noise prior evolved from previous estimation. An explicit model representing noise effects on speech features is used, so that an extended Kalman ﬁlter is constructed for each sample, generating the updated continuous state estimate as the estimation of the noise parameter, and prediction likelihood for weighting each sample. Minimum mean square error (MMSE) inference of the time-varying noise parameter is carried out over these samples by fusion the estimation of samples according to their weights. A residual resampling selection step and a Metropolis-Hastings smoothing step are used to improve calculation eﬃciency. Experiments were conducted on speech recognition in simulated non-stationary noises, where noise power changed artiﬁcially, and highly non-stationary Machinegun noise. In all the experiments carried out, we observed that the method can have signiﬁcant recognition performance improvement, over that achieved by noise compensation with stationary noise assumption. 1</p><p>4 0.7502954 <a title="4-lsi-4" href="./nips-2001-Speech_Recognition_with_Missing_Data_using_Recurrent_Neural_Nets.html">173 nips-2001-Speech Recognition with Missing Data using Recurrent Neural Nets</a></p>
<p>Author: S. Parveen, P. Green</p><p>Abstract: In the ‘missing data’ approach to improving the robustness of automatic speech recognition to added noise, an initial process identiﬁes spectraltemporal regions which are dominated by the speech source. The remaining regions are considered to be ‘missing’. In this paper we develop a connectionist approach to the problem of adapting speech recognition to the missing data case, using Recurrent Neural Networks. In contrast to methods based on Hidden Markov Models, RNNs allow us to make use of long-term time constraints and to make the problems of classiﬁcation with incomplete data and imputing missing values interact. We report encouraging results on an isolated digit recognition task.</p><p>5 0.4232778 <a title="4-lsi-5" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<p>Author: William M. Campbell</p><p>Abstract: A novel approach for comparing sequences of observations using an explicit-expansion kernel is demonstrated. The kernel is derived using the assumption of the independence of the sequence of observations and a mean-squared error training criterion. The use of an explicit expansion kernel reduces classiﬁer model size and computation dramatically, resulting in model sizes and computation one-hundred times smaller in our application. The explicit expansion also preserves the computational advantages of an earlier architecture based on mean-squared error training. Training using standard support vector machine methodology gives accuracy that signiﬁcantly exceeds the performance of state-of-the-art mean-squared error training for a speaker recognition task.</p><p>6 0.4110108 <a title="4-lsi-6" href="./nips-2001-Speech_Recognition_using_SVMs.html">172 nips-2001-Speech Recognition using SVMs</a></p>
<p>7 0.34535024 <a title="4-lsi-7" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>8 0.32177994 <a title="4-lsi-8" href="./nips-2001-Learning_Discriminative_Feature_Transforms_to_Low_Dimensions_in_Low_Dimentions.html">109 nips-2001-Learning Discriminative Feature Transforms to Low Dimensions in Low Dimentions</a></p>
<p>9 0.31041759 <a title="4-lsi-9" href="./nips-2001-A_Neural_Oscillator_Model_of_Auditory_Selective_Attention.html">14 nips-2001-A Neural Oscillator Model of Auditory Selective Attention</a></p>
<p>10 0.29775196 <a title="4-lsi-10" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>11 0.27714881 <a title="4-lsi-11" href="./nips-2001-Fast%2C_Large-Scale_Transformation-Invariant_Clustering.html">75 nips-2001-Fast, Large-Scale Transformation-Invariant Clustering</a></p>
<p>12 0.26462799 <a title="4-lsi-12" href="./nips-2001-A_Variational_Approach_to_Learning_Curves.html">21 nips-2001-A Variational Approach to Learning Curves</a></p>
<p>13 0.26035523 <a title="4-lsi-13" href="./nips-2001-Intransitive_Likelihood-Ratio_Classifiers.html">99 nips-2001-Intransitive Likelihood-Ratio Classifiers</a></p>
<p>14 0.25857103 <a title="4-lsi-14" href="./nips-2001-Product_Analysis%3A_Learning_to_Model_Observations_as_Products_of_Hidden_Variables.html">153 nips-2001-Product Analysis: Learning to Model Observations as Products of Hidden Variables</a></p>
<p>15 0.24501938 <a title="4-lsi-15" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>16 0.24417622 <a title="4-lsi-16" href="./nips-2001-TAP_Gibbs_Free_Energy%2C_Belief_Propagation_and_Sparsity.html">178 nips-2001-TAP Gibbs Free Energy, Belief Propagation and Sparsity</a></p>
<p>17 0.23239411 <a title="4-lsi-17" href="./nips-2001-Asymptotic_Universality_for_Learning_Curves_of_Support_Vector_Machines.html">38 nips-2001-Asymptotic Universality for Learning Curves of Support Vector Machines</a></p>
<p>18 0.22891524 <a title="4-lsi-18" href="./nips-2001-Gaussian_Process_Regression_with_Mismatched_Models.html">79 nips-2001-Gaussian Process Regression with Mismatched Models</a></p>
<p>19 0.2278796 <a title="4-lsi-19" href="./nips-2001-ACh%2C_Uncertainty%2C_and_Cortical_Inference.html">3 nips-2001-ACh, Uncertainty, and Cortical Inference</a></p>
<p>20 0.22492534 <a title="4-lsi-20" href="./nips-2001-Multiplicative_Updates_for_Classification_by_Mixture_Models.html">129 nips-2001-Multiplicative Updates for Classification by Mixture Models</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2001_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(13, 0.272), (14, 0.024), (17, 0.035), (19, 0.013), (27, 0.097), (30, 0.128), (38, 0.014), (59, 0.045), (72, 0.091), (79, 0.062), (83, 0.021), (91, 0.107)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.83239043 <a title="4-lda-1" href="./nips-2001-ALGONQUIN_-_Learning_Dynamic_Noise_Models_From_Noisy_Speech_for_Robust_Speech_Recognition.html">4 nips-2001-ALGONQUIN - Learning Dynamic Noise Models From Noisy Speech for Robust Speech Recognition</a></p>
<p>Author: Brendan J. Frey, Trausti T. Kristjansson, Li Deng, Alex Acero</p><p>Abstract: A challenging, unsolved problem in the speech recognition community is recognizing speech signals that are corrupted by loud, highly nonstationary noise. One approach to noisy speech recognition is to automatically remove the noise from the cepstrum sequence before feeding it in to a clean speech recognizer. In previous work published in Eurospeech, we showed how a probability model trained on clean speech and a separate probability model trained on noise could be combined for the purpose of estimating the noisefree speech from the noisy speech. We showed how an iterative 2nd order vector Taylor series approximation could be used for probabilistic inference in this model. In many circumstances, it is not possible to obtain examples of noise without speech. Noise statistics may change significantly during an utterance, so that speechfree frames are not sufficient for estimating the noise model. In this paper, we show how the noise model can be learned even when the data contains speech. In particular, the noise model can be learned from the test utterance and then used to de noise the test utterance. The approximate inference technique is used as an approximate E step in a generalized EM algorithm that learns the parameters of the noise model from a test utterance. For both Wall Street J ournal data with added noise samples and the Aurora benchmark, we show that the new noise adaptive technique performs as well as or significantly better than the non-adaptive algorithm, without the need for a separate training set of noise examples. 1</p><p>2 0.74631864 <a title="4-lda-2" href="./nips-2001-Fast_and_Robust_Classification_using_Asymmetric_AdaBoost_and_a_Detector_Cascade.html">77 nips-2001-Fast and Robust Classification using Asymmetric AdaBoost and a Detector Cascade</a></p>
<p>Author: Paul Viola, Michael Jones</p><p>Abstract: This paper develops a new approach for extremely fast detection in domains where the distribution of positive and negative examples is highly skewed (e.g. face detection or database retrieval). In such domains a cascade of simple classiﬁers each trained to achieve high detection rates and modest false positive rates can yield a ﬁnal detector with many desirable features: including high detection rates, very low false positive rates, and fast performance. Achieving extremely high detection rates, rather than low error, is not a task typically addressed by machine learning algorithms. We propose a new variant of AdaBoost as a mechanism for training the simple classiﬁers used in the cascade. Experimental results in the domain of face detection show the training algorithm yields signiﬁcant improvements in performance over conventional AdaBoost. The ﬁnal face detection system can process 15 frames per second, achieves over 90% detection, and a false positive rate of 1 in a 1,000,000.</p><p>3 0.63643885 <a title="4-lda-3" href="./nips-2001-KLD-Sampling%3A_Adaptive_Particle_Filters.html">102 nips-2001-KLD-Sampling: Adaptive Particle Filters</a></p>
<p>Author: Dieter Fox</p><p>Abstract: Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique.</p><p>4 0.62809527 <a title="4-lda-4" href="./nips-2001-Probabilistic_Abstraction_Hierarchies.html">149 nips-2001-Probabilistic Abstraction Hierarchies</a></p>
<p>Author: Eran Segal, Daphne Koller, Dirk Ormoneit</p><p>Abstract: Many domains are naturally organized in an abstraction hierarchy or taxonomy, where the instances in “nearby” classes in the taxonomy are similar. In this paper, we provide a general probabilistic framework for clustering data into a set of classes organized as a taxonomy, where each class is associated with a probabilistic model from which the data was generated. The clustering algorithm simultaneously optimizes three things: the assignment of data instances to clusters, the models associated with the clusters, and the structure of the abstraction hierarchy. A unique feature of our approach is that it utilizes global optimization algorithms for both of the last two steps, reducing the sensitivity to noise and the propensity to local maxima that are characteristic of algorithms such as hierarchical agglomerative clustering that only take local steps. We provide a theoretical analysis for our algorithm, showing that it converges to a local maximum of the joint likelihood of model and data. We present experimental results on synthetic data, and on real data in the domains of gene expression and text.</p><p>5 0.61889052 <a title="4-lda-5" href="./nips-2001-Dynamic_Time-Alignment_Kernel_in_Support_Vector_Machine.html">63 nips-2001-Dynamic Time-Alignment Kernel in Support Vector Machine</a></p>
<p>Author: Hiroshi Shimodaira, Ken-ichi Noma, Mitsuru Nakai, Shigeki Sagayama</p><p>Abstract: A new class of Support Vector Machine (SVM) that is applicable to sequential-pattern recognition such as speech recognition is developed by incorporating an idea of non-linear time alignment into the kernel function. Since the time-alignment operation of sequential pattern is embedded in the new kernel function, standard SVM training and classiﬁcation algorithms can be employed without further modiﬁcations. The proposed SVM (DTAK-SVM) is evaluated in speaker-dependent speech recognition experiments of hand-segmented phoneme recognition. Preliminary experimental results show comparable recognition performance with hidden Markov models (HMMs). 1</p><p>6 0.61125708 <a title="4-lda-6" href="./nips-2001-Categorization_by_Learning_and_Combining_Object_Parts.html">46 nips-2001-Categorization by Learning and Combining Object Parts</a></p>
<p>7 0.60744929 <a title="4-lda-7" href="./nips-2001-Adaptive_Sparseness_Using_Jeffreys_Prior.html">29 nips-2001-Adaptive Sparseness Using Jeffreys Prior</a></p>
<p>8 0.60458934 <a title="4-lda-8" href="./nips-2001-Relative_Density_Nets%3A_A_New_Way_to_Combine_Backpropagation_with_HMM%27s.html">162 nips-2001-Relative Density Nets: A New Way to Combine Backpropagation with HMM's</a></p>
<p>9 0.59973955 <a title="4-lda-9" href="./nips-2001-Neural_Implementation_of_Bayesian_Inference_in_Population_Codes.html">131 nips-2001-Neural Implementation of Bayesian Inference in Population Codes</a></p>
<p>10 0.59756303 <a title="4-lda-10" href="./nips-2001-Convolution_Kernels_for_Natural_Language.html">56 nips-2001-Convolution Kernels for Natural Language</a></p>
<p>11 0.59751946 <a title="4-lda-11" href="./nips-2001-Discriminative_Direction_for_Kernel_Classifiers.html">60 nips-2001-Discriminative Direction for Kernel Classifiers</a></p>
<p>12 0.59602058 <a title="4-lda-12" href="./nips-2001-Activity_Driven_Adaptive_Stochastic_Resonance.html">27 nips-2001-Activity Driven Adaptive Stochastic Resonance</a></p>
<p>13 0.59536278 <a title="4-lda-13" href="./nips-2001-The_Method_of_Quantum_Clustering.html">185 nips-2001-The Method of Quantum Clustering</a></p>
<p>14 0.59490991 <a title="4-lda-14" href="./nips-2001-Variance_Reduction_Techniques_for_Gradient_Estimates_in_Reinforcement_Learning.html">195 nips-2001-Variance Reduction Techniques for Gradient Estimates in Reinforcement Learning</a></p>
<p>15 0.5947848 <a title="4-lda-15" href="./nips-2001-Risk_Sensitive_Particle_Filters.html">163 nips-2001-Risk Sensitive Particle Filters</a></p>
<p>16 0.59435248 <a title="4-lda-16" href="./nips-2001-Model-Free_Least-Squares_Policy_Iteration.html">121 nips-2001-Model-Free Least-Squares Policy Iteration</a></p>
<p>17 0.59388584 <a title="4-lda-17" href="./nips-2001-Probabilistic_Inference_of_Hand_Motion_from_Neural_Activity_in_Motor_Cortex.html">150 nips-2001-Probabilistic Inference of Hand Motion from Neural Activity in Motor Cortex</a></p>
<p>18 0.59261274 <a title="4-lda-18" href="./nips-2001-Reinforcement_Learning_with_Long_Short-Term_Memory.html">161 nips-2001-Reinforcement Learning with Long Short-Term Memory</a></p>
<p>19 0.59078598 <a title="4-lda-19" href="./nips-2001-Rates_of_Convergence_of_Performance_Gradient_Estimates_Using_Function_Approximation_and_Bias_in_Reinforcement_Learning.html">157 nips-2001-Rates of Convergence of Performance Gradient Estimates Using Function Approximation and Bias in Reinforcement Learning</a></p>
<p>20 0.59054726 <a title="4-lda-20" href="./nips-2001-A_Sequence_Kernel_and_its_Application_to_Speaker_Recognition.html">20 nips-2001-A Sequence Kernel and its Application to Speaker Recognition</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
