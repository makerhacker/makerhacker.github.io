<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-821" href="#">high_scalability-2010-821</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-821-html" href="http://highscalability.com//blog/2010/5/3/mocospace-architecture-3-billion-mobile-page-views-a-month.html">html</a></p><p>Introduction: This is a guest post by Jamie Hall, Co-founder & CTO of  MocoSpace , describing the architecture for their mobile social network. This is a timely architecture to learn from as it combines several hot trends: it is very large, mobile, and social. What they think is especially cool about their system is: how it optimizes for device/browser fragmentation on the mobile Web; their multi-tiered,  read/write, local/distributed caching system; selecting PostgreSQL over MySQL as a relational DB that can scale.
 
MocoSpace is a mobile social network, with 12 million members and 3 billion page views a month, which makes it one of the most highly trafficked mobile Websites in the US. Members access the site mainly from their mobile phone Web browser, ranging from high end smartphones to lower end devices, as well as the Web. Activities on the site include customizing profiles, chat, instant messaging, music, sharing photos & videos, games, eCards and blogs. The monetization strategy is focused on</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 This is a guest post by Jamie Hall, Co-founder & CTO of  MocoSpace , describing the architecture for their mobile social network. [sent-1, score-0.402]
</p><p>2 What they think is especially cool about their system is: how it optimizes for device/browser fragmentation on the mobile Web; their multi-tiered,  read/write, local/distributed caching system; selecting PostgreSQL over MySQL as a relational DB that can scale. [sent-3, score-0.527]
</p><p>3 MocoSpace is a mobile social network, with 12 million members and 3 billion page views a month, which makes it one of the most highly trafficked mobile Websites in the US. [sent-4, score-1.023]
</p><p>4 Members access the site mainly from their mobile phone Web browser, ranging from high end smartphones to lower end devices, as well as the Web. [sent-5, score-0.476]
</p><p>5 The monetization strategy is focused on advertising, on both the mobile and Websites, as well as a virtual currency system and a handful of premium feature upgrades. [sent-7, score-0.474]
</p><p>6 Stats      3 billion page views a month     Top 4 most trafficked mobile website after MySpace, Facebook and Google (http://www. [sent-8, score-0.411]
</p><p>7 com/mobile-is-mobile)     75% mobile Web, 25% Web     12 million members     6 million unique visitors a month     100k concurrent users     12 million photo uploads a month     2 million emails received a day, 90% spam, 2. [sent-10, score-0.971]
</p><p>8 Browser and device fragmentation issues are much greater on mobile than on the Web. [sent-12, score-0.569]
</p><p>9 Many optimizations, adaptations required based on browser capabilities, limited support for CSS/JavaScript, screen size, etc. [sent-13, score-0.274]
</p><p>10 A big challenge is handling the device/browser fragmentation on the mobile Web - optimizing  for a huge range of device capabilities (everything from iPhones with  touchscreens to 5 year old Motorola Razrs), screen sizes, lack of /  inconsistent Web standards compliance, etc. [sent-15, score-0.765]
</p><p>11 The database contains capability details for  hundreds of devices and mobile browser types. [sent-17, score-0.632]
</p><p>12 Large tables are partitioned into smaller sub tables for more efficient access, reducing time tables are locked for updates as well as operational maintenance activities. [sent-22, score-0.297]
</p><p>13 A multi-tiered caching system is used, with data cached locally within the application servers as well as distributed via Memcached. [sent-24, score-0.231]
</p><p>14 When updating the cache an invalidation directive is sent via the messaging queue to the local caches on each of the application servers. [sent-26, score-0.281]
</p><p>15 A distributed message queue is used for distributed server communication, everything from sending messages in realtime between users to system messages such as local cache invalidation directives. [sent-27, score-0.431]
</p><p>16 Dedicated server for building and traversing social graph entirely in memory, used to generate friend recommendations, etc. [sent-28, score-0.246]
</p><p>17 Puppet is used to configure a server to a specific personality i. [sent-34, score-0.234]
</p><p>18 Webserver, database server, cache server etc, as well as to push updated policies to running nodes. [sent-36, score-0.243]
</p><p>19 If the server fails the user loses their state and may need to re-login, but that's rare and acceptable depending on what you need to do. [sent-70, score-0.225]
</p><p>20 We use Concurrent Mark Sweep (CMS) garbage collector, which introduces some additional system overhead, but have been able to eliminate full garbage collections. [sent-72, score-0.243]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('mobile', 0.327), ('browser', 0.153), ('mocospace', 0.137), ('fragmentation', 0.137), ('jamie', 0.124), ('screen', 0.121), ('queue', 0.112), ('photo', 0.11), ('dell', 0.109), ('million', 0.108), ('zabbix', 0.107), ('device', 0.105), ('members', 0.102), ('deletion', 0.099), ('dual', 0.095), ('boxes', 0.093), ('garbage', 0.09), ('sticky', 0.088), ('used', 0.088), ('etc', 0.087), ('invalidation', 0.085), ('well', 0.084), ('via', 0.084), ('trafficked', 0.084), ('server', 0.083), ('batches', 0.083), ('user', 0.08), ('database', 0.076), ('devices', 0.076), ('capabilities', 0.075), ('social', 0.075), ('nagios', 0.072), ('release', 0.072), ('io', 0.071), ('tables', 0.071), ('red', 0.07), ('web', 0.068), ('core', 0.067), ('behavior', 0.066), ('mark', 0.066), ('pages', 0.066), ('spam', 0.066), ('site', 0.065), ('monitoring', 0.064), ('tb', 0.064), ('postgresql', 0.064), ('system', 0.063), ('configure', 0.063), ('fails', 0.062), ('hyperic', 0.062)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0000006 <a title="821-tfidf-1" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>Introduction: This is a guest post by Jamie Hall, Co-founder & CTO of  MocoSpace , describing the architecture for their mobile social network. This is a timely architecture to learn from as it combines several hot trends: it is very large, mobile, and social. What they think is especially cool about their system is: how it optimizes for device/browser fragmentation on the mobile Web; their multi-tiered,  read/write, local/distributed caching system; selecting PostgreSQL over MySQL as a relational DB that can scale.
 
MocoSpace is a mobile social network, with 12 million members and 3 billion page views a month, which makes it one of the most highly trafficked mobile Websites in the US. Members access the site mainly from their mobile phone Web browser, ranging from high end smartphones to lower end devices, as well as the Web. Activities on the site include customizing profiles, chat, instant messaging, music, sharing photos & videos, games, eCards and blogs. The monetization strategy is focused on</p><p>2 0.20514233 <a title="821-tfidf-2" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>Introduction: Fotolog, a social blogging site centered around photos, grew from about 300 thousand users in 2004 to over 11 million users in 2007. Though they initially experienced the inevitable pains of rapid growth, they overcame their problems and now manage over 300 million photos and 800,000 new photos are added each day. Generating all that fabulous content are 20 million unique monthly visitors and a volunteer army of 30,000 new users each day. They did so well a very impressed suitor bought them out for a cool $90 million. That's scale meets success by anyone standards. How did they do it?
 
Site: http://www.fotolog.com
  Information Sources     Scaling the World's Largest Photo Blogging Community      Congrats to Fotolog on $90mm sale to Hi-Media      Fotolog overtaking Flickr?      Fotolog Hits 11 Million Members and 300 Million Photos Posted      Site of the Week: Fotolog.com   by PC Magazine     CEO John Borthwick's Blog .     DBA Frank Mash's Blog     Fotolog, lessons learnt  by John B</p><p>3 0.19199169 <a title="821-tfidf-3" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>Introduction: With Lavabit  shutting down  under  murky circumstances , it seems fitting to  repost an old  (2009), yet still very good post by  Ladar Levison  on Lavabit's architecture. I don't know how much of this information is still current, but it should give you a general idea what Lavabit was all about.
  
 Getting to Know You 
 What is the name of your system and where can we find out more about it? 

 Note: these links are no longer valid... 


Lavabit   http://lavabit.com      http://lavabit.com/network.html    http://lavabit.com/about.html 

 What is your system for? 

Lavabit is a mid-sized email service provider. We currently have about 140,000 registered users with more than 260,000 email addresses. While most of our accounts belong to individual users, we also provide corporate email services to approximately 70 companies.

 Why did you decide to build this system? 

We built the system to compete against the other large free email providers, with an emphasis on serving the privacy c</p><p>4 0.18860771 <a title="821-tfidf-4" href="../high_scalability-2009/high_scalability-2009-02-12-MySpace_Architecture.html">511 high scalability-2009-02-12-MySpace Architecture</a></p>
<p>Introduction: Update:  Presentation: Behind the Scenes at MySpace.com . Dan Farino, Chief Systems Architect at MySpace shares details of some of MySpace's cool internal operations tools.   MySpace.com  is one of the fastest growing site on the Internet with 65 million subscribers and 260,000 new users registering each day. Often criticized for poor performance, MySpace has had to tackle scalability issues few other sites have faced. How did they do it?
 
Site: http://myspace.com
  Information Sources    Presentation: Behind the Scenes at MySpace.com      Inside MySpace.com  
 Platform 
    ASP.NET 2.0     Windows    IIS    SQL Server 
 What's Inside? 
   300 million users.   Pushes 100 gigabits/second to the internet. 10Gb/sec is HTML content.   4,500+ web servers windows 2003/IIS 6.0/APS.NET.   1,200+ cache servers running 64-bit Windows 2003. 16GB of objects cached in RAM.   500+ database servers running 64-bit Windows and SQL Server 2005.      MySpace processes 1.5 Billion page views per day and</p><p>5 0.18542589 <a title="821-tfidf-5" href="../high_scalability-2011/high_scalability-2011-03-08-Medialets_Architecture_-__Defeating_the_Daunting_Mobile_Device_Data_Deluge.html">1000 high scalability-2011-03-08-Medialets Architecture -  Defeating the Daunting Mobile Device Data Deluge</a></p>
<p>Introduction: Mobile developers have a huge scaling problem ahead: doing something useful with massive continuous streams of telemetry data from millions and millions of devices. This is a really good problem to have. It means smartphone sales are finally fulfilling their destiny:  slaughtering PCs  in the sales arena. And it also means mobile devices aren't just containers for simple standalone apps anymore, they are becoming the dominant interface to giant backend systems.
    
While developers are now rocking mobile development on the client side, their next challenge is how to code those tricky backend bits. A company facing those same exact problems right now is  Medialets , a mobile rich media ad platform. What they do is help publishers create high quality interactive ads, though for our purposes their ad stuff isn't that interesting. What I did find really interesting about their system is how they are tackling the problem of defeating the mobile device data deluge.
 
Each day Medialets munc</p><p>6 0.17994951 <a title="821-tfidf-6" href="../high_scalability-2008/high_scalability-2008-05-02-Friends_for_Sale_Architecture_-_A_300_Million_Page_View-Month_Facebook_RoR_App.html">313 high scalability-2008-05-02-Friends for Sale Architecture - A 300 Million Page View-Month Facebook RoR App</a></p>
<p>7 0.17865865 <a title="821-tfidf-7" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>8 0.1782677 <a title="821-tfidf-8" href="../high_scalability-2011/high_scalability-2011-06-27-TripAdvisor_Architecture_-_40M_Visitors%2C_200M_Dynamic_Page_Views%2C_30TB_Data.html">1068 high scalability-2011-06-27-TripAdvisor Architecture - 40M Visitors, 200M Dynamic Page Views, 30TB Data</a></p>
<p>9 0.16642877 <a title="821-tfidf-9" href="../high_scalability-2009/high_scalability-2009-06-26-PlentyOfFish_Architecture.html">638 high scalability-2009-06-26-PlentyOfFish Architecture</a></p>
<p>10 0.16476557 <a title="821-tfidf-10" href="../high_scalability-2012/high_scalability-2012-11-22-Gone_Fishin%27%3A_PlentyOfFish_Architecture.html">1361 high scalability-2012-11-22-Gone Fishin': PlentyOfFish Architecture</a></p>
<p>11 0.16324478 <a title="821-tfidf-11" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>12 0.16169482 <a title="821-tfidf-12" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>13 0.16131951 <a title="821-tfidf-13" href="../high_scalability-2012/high_scalability-2012-11-15-Gone_Fishin%27%3A_Justin.Tv%27s_Live_Video_Broadcasting_Architecture.html">1359 high scalability-2012-11-15-Gone Fishin': Justin.Tv's Live Video Broadcasting Architecture</a></p>
<p>14 0.16123076 <a title="821-tfidf-14" href="../high_scalability-2010/high_scalability-2010-03-16-Justin.tv%27s_Live_Video_Broadcasting_Architecture.html">796 high scalability-2010-03-16-Justin.tv's Live Video Broadcasting Architecture</a></p>
<p>15 0.158831 <a title="821-tfidf-15" href="../high_scalability-2010/high_scalability-2010-10-15-Troubles_with_Sharding_-_What_can_we_learn_from_the_Foursquare_Incident%3F.html">920 high scalability-2010-10-15-Troubles with Sharding - What can we learn from the Foursquare Incident?</a></p>
<p>16 0.15680151 <a title="821-tfidf-16" href="../high_scalability-2012/high_scalability-2012-10-04-LinkedIn_Moved_from_Rails_to_Node%3A__27_Servers_Cut_and_Up_to_20x_Faster.html">1333 high scalability-2012-10-04-LinkedIn Moved from Rails to Node:  27 Servers Cut and Up to 20x Faster</a></p>
<p>17 0.15595242 <a title="821-tfidf-17" href="../high_scalability-2013/high_scalability-2013-08-28-Sean_Hull%27s_20_Biggest_Bottlenecks_that_Reduce_and_Slow_Down_Scalability.html">1508 high scalability-2013-08-28-Sean Hull's 20 Biggest Bottlenecks that Reduce and Slow Down Scalability</a></p>
<p>18 0.15533881 <a title="821-tfidf-18" href="../high_scalability-2013/high_scalability-2013-04-10-Check_Yourself_Before_You_Wreck_Yourself_-_Avocado%27s_5_Early_Stages_of_Architecture_Evolution.html">1438 high scalability-2013-04-10-Check Yourself Before You Wreck Yourself - Avocado's 5 Early Stages of Architecture Evolution</a></p>
<p>19 0.15515533 <a title="821-tfidf-19" href="../high_scalability-2012/high_scalability-2012-04-10-Sponsored_Post%3A_Infragistics%2C_Reality_Check_Network%2C_Gigaspaces%2C_AiCache%2C_ElasticHosts%2C_Logic_Monitor%2C_Attribution_Modeling%2C_New_Relic%2C_AppDynamics%2C_CloudSigma%2C_ManageEnine%2C_Site24x7.html">1226 high scalability-2012-04-10-Sponsored Post: Infragistics, Reality Check Network, Gigaspaces, AiCache, ElasticHosts, Logic Monitor, Attribution Modeling, New Relic, AppDynamics, CloudSigma, ManageEnine, Site24x7</a></p>
<p>20 0.15515533 <a title="821-tfidf-20" href="../high_scalability-2012/high_scalability-2012-04-24-Sponsored_Post%3A_Reality_Check_Network%2C_Infragistics%2C_Gigaspaces%2C_AiCache%2C_ElasticHosts%2C_Logic_Monitor%2C_Attribution_Modeling%2C_New_Relic%2C_AppDynamics%2C_CloudSigma%2C_ManageEnine%2C_Site24x7.html">1232 high scalability-2012-04-24-Sponsored Post: Reality Check Network, Infragistics, Gigaspaces, AiCache, ElasticHosts, Logic Monitor, Attribution Modeling, New Relic, AppDynamics, CloudSigma, ManageEnine, Site24x7</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.33), (1, 0.102), (2, -0.035), (3, -0.162), (4, 0.029), (5, -0.022), (6, 0.042), (7, 0.019), (8, -0.039), (9, 0.027), (10, 0.013), (11, 0.003), (12, 0.019), (13, -0.002), (14, -0.08), (15, 0.074), (16, -0.015), (17, 0.071), (18, 0.073), (19, -0.021), (20, -0.005), (21, -0.016), (22, -0.009), (23, 0.026), (24, -0.017), (25, -0.024), (26, -0.063), (27, -0.009), (28, -0.032), (29, -0.017), (30, -0.05), (31, 0.022), (32, 0.007), (33, -0.002), (34, 0.067), (35, -0.012), (36, -0.059), (37, 0.011), (38, 0.015), (39, 0.03), (40, -0.004), (41, -0.019), (42, -0.019), (43, 0.059), (44, -0.012), (45, 0.001), (46, -0.014), (47, -0.024), (48, -0.075), (49, 0.049)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.97136843 <a title="821-lsi-1" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>Introduction: This is a guest post by Jamie Hall, Co-founder & CTO of  MocoSpace , describing the architecture for their mobile social network. This is a timely architecture to learn from as it combines several hot trends: it is very large, mobile, and social. What they think is especially cool about their system is: how it optimizes for device/browser fragmentation on the mobile Web; their multi-tiered,  read/write, local/distributed caching system; selecting PostgreSQL over MySQL as a relational DB that can scale.
 
MocoSpace is a mobile social network, with 12 million members and 3 billion page views a month, which makes it one of the most highly trafficked mobile Websites in the US. Members access the site mainly from their mobile phone Web browser, ranging from high end smartphones to lower end devices, as well as the Web. Activities on the site include customizing profiles, chat, instant messaging, music, sharing photos & videos, games, eCards and blogs. The monetization strategy is focused on</p><p>2 0.81356961 <a title="821-lsi-2" href="../high_scalability-2014/high_scalability-2014-02-17-How_the_AOL.com_Architecture_Evolved_to_99.999%25_Availability%2C_8_Million_Visitors_Per_Day%2C_and_200%2C000_Requests_Per_Second.html">1597 high scalability-2014-02-17-How the AOL.com Architecture Evolved to 99.999% Availability, 8 Million Visitors Per Day, and 200,000 Requests Per Second</a></p>
<p>Introduction: This is a guest post by  Dave Hagler  Systems Architect at AOL. 
  The AOL homepages receive more than  8 million visitors per day .  That’s more daily viewers than Good Morning America or the Today Show on television.  Over a billion page views are served each month.  AOL.com has been a major internet destination since 1996, and still has a strong following of loyal users.
   The architecture for AOL.com is in it’s 5th generation .  It has essentially been rebuilt from scratch 5 times over two decades.  The current architecture was designed 6 years ago.  Pieces have been upgraded and new components have been added along the way, but the overall design remains largely intact.  The code, tools, development and deployment processes are highly tuned over 6 years of continual improvement, making the AOL.com architecture battle tested and very stable.
  The engineering team is made up of developers, testers, and operations and  totals around 25 people .  The majority are in Dulles, Virginia</p><p>3 0.81139404 <a title="821-lsi-3" href="../high_scalability-2012/high_scalability-2012-07-16-Cinchcast_Architecture_-_Producing_1%2C500_Hours_of_Audio_Every_Day.html">1284 high scalability-2012-07-16-Cinchcast Architecture - Producing 1,500 Hours of Audio Every Day</a></p>
<p>Introduction: This is a guest post by  Dr. Aleksandr Yampolskiy , CTO of  Cinchcast  and  BlogTalkRadio , where he oversees Engineering, QA, TechOps, Telephony, and Product teams. 
 
  Cinchcast    provides solutions that allow companies to create, share, measure and monetize audio content to reach and engage the people that are most important to their business.  Our technology integrates conference bridge with live audio streaming to simplify online events and enhance participant engagement. The Cinchcast technology is also used to power  Blogtalkradio   , the world’s largest audio social network. Today our platform produces and distributes over 1,500 hours of original content every day.   In this article, we describe the engineering decisions we have made in order to scale our platform to support this scale of data. 
   Stats    
  Over 50 million page views a month  
  50,000 hours of audio content created  
  15,000,000 media streams          
  175,000,000 ad impressions  
  Peak rate of 40,000</p><p>4 0.797499 <a title="821-lsi-4" href="../high_scalability-2009/high_scalability-2009-08-16-ThePort__Network__Architecture.html">682 high scalability-2009-08-16-ThePort  Network  Architecture</a></p>
<p>Introduction: ThePort Network's Director of Engineering, TJ Muehleman was kind of enough to share some of the architectural details for their white label social media system. It currently runs about 50 social networks varying in size from less than 1000 members to more than 300,000 members, all on a Microsoft stack. In addition to their social networking platform, they offer Javascript APIs and web service APIs (both REST and SOAP) which account for a significant percentage of overall system usage.  ThePort is an excellent example of a real world in-the-trenches product offering real value to customers.  One of the most interesting problems they have to solve is multi-tenancy. How do you provide good performance, complete customization, support, develop new features, and provide individual search indexes for each customer? It's not an easy problem to solve.  How did they solve their problems and build a successful system? 
 
Site: http://theport.com
  Platform    Microsoft.NET 3.5    C# / VB.NET</p><p>5 0.7962262 <a title="821-lsi-5" href="../high_scalability-2013/high_scalability-2013-11-04-ESPN%27s_Architecture_at_Scale_-_Operating_at_100%2C000_Duh_Nuh_Nuhs_Per_Second.html">1542 high scalability-2013-11-04-ESPN's Architecture at Scale - Operating at 100,000 Duh Nuh Nuhs Per Second</a></p>
<p>Introduction: ESPN went on airin 1978. In those 30+ years think of the wonders we've seen!
When I think of ESPN I think of a world wide brand that is the very definition
of prime time. And it shows in their stats. ESPN.com peaks at 100,000 requests
per second. Their peak event is, not surprisingly, the World Cup. But would
you be surprised to learn ESPN is powered by only a few hundred servers and a
couple of dozen engineers? I was.And would you be surprised to learn ESPN is
undergoing a fundamental transition from an Enterprise architecture to one
capable of handling web scale loads driven by increasing mobile usage,
personalization, and a service orientation? Again, thinking ESPN was just
about watching sports on TV, I was surprised. ESPN is becoming much more than
that. ESPN is becoming a sports platform. How does ESPN handle all of this
complexity, responsibility, change, and load? Unlike most every other profile
on HighScalability. The fascinating story of ESPN's architecture is told
byManny Pe</p><p>6 0.79458708 <a title="821-lsi-6" href="../high_scalability-2012/high_scalability-2012-10-04-LinkedIn_Moved_from_Rails_to_Node%3A__27_Servers_Cut_and_Up_to_20x_Faster.html">1333 high scalability-2012-10-04-LinkedIn Moved from Rails to Node:  27 Servers Cut and Up to 20x Faster</a></p>
<p>7 0.79390997 <a title="821-lsi-7" href="../high_scalability-2009/high_scalability-2009-02-12-MySpace_Architecture.html">511 high scalability-2009-02-12-MySpace Architecture</a></p>
<p>8 0.77982676 <a title="821-lsi-8" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>9 0.7784887 <a title="821-lsi-9" href="../high_scalability-2014/high_scalability-2014-04-28-How_Disqus_Went_Realtime_with_165K_Messages_Per_Second_and_Less_than_.2_Seconds_Latency.html">1638 high scalability-2014-04-28-How Disqus Went Realtime with 165K Messages Per Second and Less than .2 Seconds Latency</a></p>
<p>10 0.77764297 <a title="821-lsi-10" href="../high_scalability-2007/high_scalability-2007-10-02-Secrets_to_Fotolog%27s_Scaling_Success.html">106 high scalability-2007-10-02-Secrets to Fotolog's Scaling Success</a></p>
<p>11 0.77739745 <a title="821-lsi-11" href="../high_scalability-2010/high_scalability-2010-04-12-Poppen.de_Architecture.html">808 high scalability-2010-04-12-Poppen.de Architecture</a></p>
<p>12 0.77212626 <a title="821-lsi-12" href="../high_scalability-2007/high_scalability-2007-10-28-Scaling_Early_Stage_Startups.html">136 high scalability-2007-10-28-Scaling Early Stage Startups</a></p>
<p>13 0.77150989 <a title="821-lsi-13" href="../high_scalability-2010/high_scalability-2010-03-26-Strategy%3A_Caching_404s_Saved_the_Onion_66%25_on_Server_Time.html">800 high scalability-2010-03-26-Strategy: Caching 404s Saved the Onion 66% on Server Time</a></p>
<p>14 0.76809752 <a title="821-lsi-14" href="../high_scalability-2011/high_scalability-2011-02-08-Mollom_Architecture_-_Killing_Over_373_Million_Spams_at_100_Requests_Per_Second.html">985 high scalability-2011-02-08-Mollom Architecture - Killing Over 373 Million Spams at 100 Requests Per Second</a></p>
<p>15 0.76644772 <a title="821-lsi-15" href="../high_scalability-2008/high_scalability-2008-11-03-How_Sites_are_Scaling_Up_for_the_Election_Night_Crush.html">437 high scalability-2008-11-03-How Sites are Scaling Up for the Election Night Crush</a></p>
<p>16 0.76150048 <a title="821-lsi-16" href="../high_scalability-2012/high_scalability-2012-06-25-StubHub_Architecture%3A_The_Surprising_Complexity_Behind_the_World%E2%80%99s_Largest_Ticket_Marketplace.html">1271 high scalability-2012-06-25-StubHub Architecture: The Surprising Complexity Behind the World’s Largest Ticket Marketplace</a></p>
<p>17 0.7596063 <a title="821-lsi-17" href="../high_scalability-2007/high_scalability-2007-07-12-FeedBurner_Architecture.html">7 high scalability-2007-07-12-FeedBurner Architecture</a></p>
<p>18 0.75866586 <a title="821-lsi-18" href="../high_scalability-2009/high_scalability-2009-04-16-Serving_250M_quotes-day_at_CNBC.com_with_aiCache.html">573 high scalability-2009-04-16-Serving 250M quotes-day at CNBC.com with aiCache</a></p>
<p>19 0.75860471 <a title="821-lsi-19" href="../high_scalability-2012/high_scalability-2012-08-27-Zoosk_-_The_Engineering_behind_Real_Time_Communications.html">1312 high scalability-2012-08-27-Zoosk - The Engineering behind Real Time Communications</a></p>
<p>20 0.75842321 <a title="821-lsi-20" href="../high_scalability-2013/high_scalability-2013-06-28-Stuff_The_Internet_Says_On_Scalability_For_June_28%2C_2013.html">1484 high scalability-2013-06-28-Stuff The Internet Says On Scalability For June 28, 2013</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.146), (2, 0.247), (10, 0.075), (15, 0.012), (30, 0.031), (40, 0.028), (47, 0.018), (51, 0.01), (61, 0.098), (77, 0.011), (79, 0.075), (83, 0.076), (85, 0.048), (94, 0.042)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96858633 <a title="821-lda-1" href="../high_scalability-2010/high_scalability-2010-05-03-MocoSpace_Architecture_-_3_Billion_Mobile_Page_Views_a_Month.html">821 high scalability-2010-05-03-MocoSpace Architecture - 3 Billion Mobile Page Views a Month</a></p>
<p>Introduction: This is a guest post by Jamie Hall, Co-founder & CTO of  MocoSpace , describing the architecture for their mobile social network. This is a timely architecture to learn from as it combines several hot trends: it is very large, mobile, and social. What they think is especially cool about their system is: how it optimizes for device/browser fragmentation on the mobile Web; their multi-tiered,  read/write, local/distributed caching system; selecting PostgreSQL over MySQL as a relational DB that can scale.
 
MocoSpace is a mobile social network, with 12 million members and 3 billion page views a month, which makes it one of the most highly trafficked mobile Websites in the US. Members access the site mainly from their mobile phone Web browser, ranging from high end smartphones to lower end devices, as well as the Web. Activities on the site include customizing profiles, chat, instant messaging, music, sharing photos & videos, games, eCards and blogs. The monetization strategy is focused on</p><p>2 0.96737021 <a title="821-lda-2" href="../high_scalability-2010/high_scalability-2010-12-23-Paper%3A_CRDTs%3A_Consistency_without_concurrency_control.html">963 high scalability-2010-12-23-Paper: CRDTs: Consistency without concurrency control</a></p>
<p>Introduction: For a great Christmas read forget  The Night Before Christmas , a heart warming poem written by Clement Moore for his children, that created the modern idea of Santa Clause we all know and anticipate each Christmas eve. Instead, curl up with a some potentÂ  eggnog , nog being any drink made with rum, and readÂ  CRDTs: Consistency without concurrency control Â by Mihai Letia, Nuno PreguiĂ§a, and Marc Shapiro, which talks about CRDTs (Commutative Replicated Data Type),  a data type whose operations commute when they are concurrent .
 
From the introduction, which also serves as a nice concise overview of distributed consistency issues:
  

Shared read-only data is easy to scale by using well-understood replication techniques. However, sharing mutable data at a large scale is a difficult problem, because of the CAP impossibility result [5]. Two approaches dominate in practice. One ensures scalability by giving up consistency guarantees, for instance using the Last-Writer-Wins (LWW) approach [</p><p>3 0.96687061 <a title="821-lda-3" href="../high_scalability-2012/high_scalability-2012-03-02-Stuff_The_Internet_Says_On_Scalability_For_March_2%2C_2012.html">1203 high scalability-2012-03-02-Stuff The Internet Says On Scalability For March 2, 2012</a></p>
<p>Introduction: Please don't squeeze the HighScalability:
  
 Quotable quotes:             
 
  @karmafile : "Scalability" is a much more evil word than we make it out to be 
  @ostaquet : More hardware won't solve #SQL resp. time issues; proper indexing does. 
  @datachick : All computing technology is the rearrangement of data. Data is the center of the universe 
 ‏ @jamesurquhart : "Complexity is a characteristic of the system, not of the parts in it." 
 
 
 Data is the star of the cat walk, looking fierce in Ilya Katsov's impeccably constructed post on  NoSQL Data Modeling Techniques : In this article I provide a short comparison of NoSQL system families from the data modeling point of view and digest several common modeling techniques.  
 Peter Burns  talks computer nanosecond time scales  as a human might experience them. Your memory == computer registers , L1 cache == papers kept close by, L2 cache == books, RAM == the library down the street, and going to disk is a 3 year odessy for data. 
  F</p><p>4 0.96541733 <a title="821-lda-4" href="../high_scalability-2011/high_scalability-2011-04-18-6_Ways_Not_to_Scale_that_Will_Make_You_Hip%2C_Popular_and_Loved_By_VCs.html">1026 high scalability-2011-04-18-6 Ways Not to Scale that Will Make You Hip, Popular and Loved By VCs</a></p>
<p>Introduction: This is a hilarious presentation by  Josh Berkus , called  Scale Fail , given at O'Reilly MySQL CE 2011. Josh is entertaining, well spoken, and cleverly hides insight inside chaos. And he makes some dang good points along the way.
  Josh has a problem, you see Josh has learned how to make sites that are both scalable and reliable. So he's puzzled why companies "whose downtime interfaces (Twitter) are more well known than their uptime interfaces" get all the attention, respect, and money for being failures. Just doing your job doesn't make you a hero.  You need these self-inflicted wounds in-order to have the war stories to share at conferences. They get the attention. Just doing your job is boring. This is so unfair in that way life can be. 
 
  
 
So if you want to turn the tables and take the low road to fame and fortune, here's Josh's program for learning how not to scale:
  
  Be trendy . Use the tool that has the most buzz: NoSQL, Cloud, MapReduce, Rails, RabbitMQ. It helps you no</p><p>5 0.9645564 <a title="821-lda-5" href="../high_scalability-2007/high_scalability-2007-08-22-Wikimedia_architecture.html">72 high scalability-2007-08-22-Wikimedia architecture</a></p>
<p>Introduction: Wikimedia is the platform on which Wikipedia, Wiktionary, and the other seven wiki dwarfs are built on. This document is just excellent for the student trying to scale the heights of giant websites. It is full of details and innovative ideas that have been proven on some of the most used websites on the internet.
 
Site: http://wikimedia.org/
  Information Sources     Wikimedia architecture     http://meta.wikimedia.org/wiki/Wikimedia_servers     scale-out vs scale-up  in the  from Oracle to MySQL  blog. 
 Platform 
    Apache    Linux    MySQL    PHP    Squid    LVS    Lucene for Search    Memcached for Distributed Object Cache    Lighttpd Image Server 
 The Stats 
    8 million articles spread over hundreds of language projects (english, dutch, ...)    10th busiest site in the world (source: Alexa)    Exponential growth: doubling every 4-6 months in terms of visitors / traffic / servers    30 000 HTTP requests/s during peak-time    3 Gbit/s of data traffic    3 data centers: Tampa, A</p><p>6 0.96177804 <a title="821-lda-6" href="../high_scalability-2013/high_scalability-2013-02-15-Stuff_The_Internet_Says_On_Scalability_For_February_15%2C_2013.html">1407 high scalability-2013-02-15-Stuff The Internet Says On Scalability For February 15, 2013</a></p>
<p>7 0.96007049 <a title="821-lda-7" href="../high_scalability-2011/high_scalability-2011-03-03-Stack_Overflow_Architecture_Update_-_Now_at_95_Million_Page_Views_a_Month.html">998 high scalability-2011-03-03-Stack Overflow Architecture Update - Now at 95 Million Page Views a Month</a></p>
<p>8 0.95898294 <a title="821-lda-8" href="../high_scalability-2012/high_scalability-2012-12-14-Stuff_The_Internet_Says_On_Scalability_For_December_14%2C_2012.html">1372 high scalability-2012-12-14-Stuff The Internet Says On Scalability For December 14, 2012</a></p>
<p>9 0.95865792 <a title="821-lda-9" href="../high_scalability-2012/high_scalability-2012-06-20-iDoneThis_-_Scaling_an_Email-based_App_from_Scratch.html">1269 high scalability-2012-06-20-iDoneThis - Scaling an Email-based App from Scratch</a></p>
<p>10 0.95832229 <a title="821-lda-10" href="../high_scalability-2011/high_scalability-2011-12-05-Stuff_The_Internet_Says_On_Scalability_For_December_5%2C_2011.html">1151 high scalability-2011-12-05-Stuff The Internet Says On Scalability For December 5, 2011</a></p>
<p>11 0.95797962 <a title="821-lda-11" href="../high_scalability-2012/high_scalability-2012-05-11-Stuff_The_Internet_Says_On_Scalability_For_May_11%2C_2012.html">1244 high scalability-2012-05-11-Stuff The Internet Says On Scalability For May 11, 2012</a></p>
<p>12 0.95746064 <a title="821-lda-12" href="../high_scalability-2014/high_scalability-2014-01-28-How_Next_Big_Sound_Tracks_Over_a_Trillion_Song_Plays%2C_Likes%2C_and_More_Using_a_Version_Control_System_for_Hadoop_Data.html">1586 high scalability-2014-01-28-How Next Big Sound Tracks Over a Trillion Song Plays, Likes, and More Using a Version Control System for Hadoop Data</a></p>
<p>13 0.95735908 <a title="821-lda-13" href="../high_scalability-2011/high_scalability-2011-09-23-The_Real_News_is_Not_that_Facebook_Serves_Up_1_Trillion_Pages_a_Month%E2%80%A6.html">1123 high scalability-2011-09-23-The Real News is Not that Facebook Serves Up 1 Trillion Pages a Month…</a></p>
<p>14 0.95730042 <a title="821-lda-14" href="../high_scalability-2012/high_scalability-2012-10-12-Stuff_The_Internet_Says_On_Scalability_For_October_12%2C_2012.html">1339 high scalability-2012-10-12-Stuff The Internet Says On Scalability For October 12, 2012</a></p>
<p>15 0.95648593 <a title="821-lda-15" href="../high_scalability-2014/high_scalability-2014-05-02-Stuff_The_Internet_Says_On_Scalability_For_May_2nd%2C_2014.html">1642 high scalability-2014-05-02-Stuff The Internet Says On Scalability For May 2nd, 2014</a></p>
<p>16 0.95595461 <a title="821-lda-16" href="../high_scalability-2014/high_scalability-2014-04-25-Stuff_The_Internet_Says_On_Scalability_For_April_25th%2C_2014.html">1637 high scalability-2014-04-25-Stuff The Internet Says On Scalability For April 25th, 2014</a></p>
<p>17 0.9557994 <a title="821-lda-17" href="../high_scalability-2013/high_scalability-2013-08-13-In_Memoriam%3A_Lavabit_Architecture_-_Creating_a_Scalable_Email_Service.html">1501 high scalability-2013-08-13-In Memoriam: Lavabit Architecture - Creating a Scalable Email Service</a></p>
<p>18 0.95487589 <a title="821-lda-18" href="../high_scalability-2009/high_scalability-2009-06-05-HotPads_Shows_the_True_Cost_of_Hosting_on_Amazon.html">619 high scalability-2009-06-05-HotPads Shows the True Cost of Hosting on Amazon</a></p>
<p>19 0.95485955 <a title="821-lda-19" href="../high_scalability-2009/high_scalability-2009-01-20-Product%3A_Amazon%27s_SimpleDB.html">498 high scalability-2009-01-20-Product: Amazon's SimpleDB</a></p>
<p>20 0.95485324 <a title="821-lda-20" href="../high_scalability-2010/high_scalability-2010-03-22-7_Secrets_to_Successfully_Scaling_with_Scalr_%28on_Amazon%29_by_Sebastian_Stadil.html">798 high scalability-2010-03-22-7 Secrets to Successfully Scaling with Scalr (on Amazon) by Sebastian Stadil</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
