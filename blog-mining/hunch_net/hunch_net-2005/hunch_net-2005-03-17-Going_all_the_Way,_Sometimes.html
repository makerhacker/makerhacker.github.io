<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>42 hunch net-2005-03-17-Going all the Way, Sometimes</title>
</head>

<body>
<p><a title="hunch_net" href="../hunch_net_home.html">hunch_net</a> <a title="hunch_net-2005" href="../home/hunch_net-2005_home.html">hunch_net-2005</a> <a title="hunch_net-2005-42" href="#">hunch_net-2005-42</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>42 hunch net-2005-03-17-Going all the Way, Sometimes</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="hunch_net-2005-42-html" href="http://hunch.net/?p=46">html</a></p><p>Introduction: At many points in research, you face a choice: should I keep on improving some
old piece of technology or should I do something new? For example:Should I
refine bounds to make them tighter?Should I take some learning theory and turn
it into a learning algorithm?Should I implement the learning algorithm?Should
I test the learning algorithm widely?Should I release the algorithm as source
code?Should I go see what problems people actually need to solve?The universal
temptation of people attracted to research is doing something new. That is
sometimes the right decision, but is also often not. I'd like to discuss some
reasons why not.ExpertiseOnce expertise are developed on some subject, you are
the right person to refine them.What is the real problem?Continually improving
a piece of technology is a mechanism forcing you to confront this question. In
many cases, this confrontation is uncomfortable because you discover that your
method has fundamental flaws with respect to solving the real p</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('discover', 0.335), ('refine', 0.25), ('piece', 0.171), ('improving', 0.162), ('algorithm', 0.157), ('technology', 0.152), ('way', 0.136), ('confront', 0.135), ('deeper', 0.135), ('invaluable', 0.135), ('invites', 0.135), ('issue', 0.132), ('real', 0.121), ('forcing', 0.118), ('focusing', 0.112), ('home', 0.112), ('releasing', 0.112), ('uncomfortable', 0.108), ('flaws', 0.108), ('go', 0.106)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.99999976 <a title="42-tfidf-1" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>Introduction: At many points in research, you face a choice: should I keep on improving some
old piece of technology or should I do something new? For example:Should I
refine bounds to make them tighter?Should I take some learning theory and turn
it into a learning algorithm?Should I implement the learning algorithm?Should
I test the learning algorithm widely?Should I release the algorithm as source
code?Should I go see what problems people actually need to solve?The universal
temptation of people attracted to research is doing something new. That is
sometimes the right decision, but is also often not. I'd like to discuss some
reasons why not.ExpertiseOnce expertise are developed on some subject, you are
the right person to refine them.What is the real problem?Continually improving
a piece of technology is a mechanism forcing you to confront this question. In
many cases, this confrontation is uncomfortable because you discover that your
method has fundamental flaws with respect to solving the real p</p><p>2 0.15416983 <a title="42-tfidf-2" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>Introduction: I've had serious conversations with several people who believe that the theory
in machine learning is "only useful for getting papers published". That's a
compelling statement, as I've seen many papers where the algorithm clearly
came first, and the theoretical justification for it came second, purely as a
perceived means to improve the chance of publication.Naturally, I disagree and
believe that learning theory has much more substantial applications.Even in
core learning algorithm design, I've found learning theory to be useful,
although it's application is more subtle than many realize. The most
straightforward applications can fail, because (as expectation suggests) worst
case bounds tend to be loose in practice (*). In my experience, considering
learning theory when designing an algorithm has two important effects in
practice:It can help make your algorithm behave right at a crude level of
analysis, leaving finer details to tuning or common sense. The best example I
have of this is</p><p>3 0.12783463 <a title="42-tfidf-3" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>4 0.12415025 <a title="42-tfidf-4" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>Introduction: Normally, I don't indulge in posters forICML, but this year is naturally an
exception for me. If you want one, there are a small numberleft here, if you
sign up before February.It also seems worthwhile to give some sense of the
scope and reviewing criteria for ICML for authors considering submitting
papers. At ICML, the (very large) program committee does the reviewing which
informs final decisions by area chairs on most papers. Program chairs setup
the process, deal with exceptions or disagreements, and provide advice for the
reviewing process. Providing advice is tricky (and easily misleading) because
a conference is a community, and in the end the aggregate interests of the
community determine the conference. Nevertheless, as a program chair this year
it seems worthwhile to state the overall philosophy I have and what I plan to
encourage (and occasionally discourage).At the highest level, I believe ICML
exists to further research into machine learning, which I generally think of
as</p><p>5 0.12066042 <a title="42-tfidf-5" href="../hunch_net-2010/hunch_net-2010-12-26-NIPS_2010.html">420 hunch net-2010-12-26-NIPS 2010</a></p>
<p>Introduction: I enjoyed attendingNIPSthis year, with several things interesting me. For the
conference itself:Peter Welinder,Steve Branson,Serge Belongie, andPietro
Perona,The Multidimensional Wisdom of Crowds. This paper is about
usingmechanical turkto get label information, with results superior to a
majority vote approach.David McAllester,Tamir Hazan, andJoseph KeshetDirect
Loss Minimization for Structured Prediction. This is about another technique
for directly optimizing the loss in structured prediction, with an application
to speech recognition.Mohammad SaberianandNuno VasconcelosBoosting Classifier
Cascades. This is about an algorithm for simultaneously optimizing loss and
computation in a classifier cascade construction. There were several other
papers on cascades which are worth looking at if interested.Alan FernandPrasad
Tadepalli,A Computational Decision Theory for Interactive Assistants. This
paper carves out some forms of natural not-MDP problems and shows their RL-
style solution is t</p><p>6 0.11790058 <a title="42-tfidf-6" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>7 0.11449245 <a title="42-tfidf-7" href="../hunch_net-2005/hunch_net-2005-09-10-%26%238220%3BFailure%26%238221%3B_is_an_option.html">110 hunch net-2005-09-10-&#8220;Failure&#8221; is an option</a></p>
<p>8 0.11429005 <a title="42-tfidf-8" href="../hunch_net-2005/hunch_net-2005-07-14-What_Learning_Theory_might_do.html">95 hunch net-2005-07-14-What Learning Theory might do</a></p>
<p>9 0.11302744 <a title="42-tfidf-9" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>10 0.10843439 <a title="42-tfidf-10" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>11 0.10679942 <a title="42-tfidf-11" href="../hunch_net-2009/hunch_net-2009-07-31-Vowpal_Wabbit_Open_Source_Project.html">365 hunch net-2009-07-31-Vowpal Wabbit Open Source Project</a></p>
<p>12 0.10658763 <a title="42-tfidf-12" href="../hunch_net-2005/hunch_net-2005-03-04-The_Big_O_and_Constants_in_Learning.html">35 hunch net-2005-03-04-The Big O and Constants in Learning</a></p>
<p>13 0.10396802 <a title="42-tfidf-13" href="../hunch_net-2005/hunch_net-2005-02-25-Problem%3A_Online_Learning.html">28 hunch net-2005-02-25-Problem: Online Learning</a></p>
<p>14 0.10386479 <a title="42-tfidf-14" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<p>15 0.10237398 <a title="42-tfidf-15" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>16 0.10150827 <a title="42-tfidf-16" href="../hunch_net-2006/hunch_net-2006-01-06-MLTV.html">146 hunch net-2006-01-06-MLTV</a></p>
<p>17 0.10101486 <a title="42-tfidf-17" href="../hunch_net-2005/hunch_net-2005-03-21-Research_Styles_in_Machine_Learning.html">44 hunch net-2005-03-21-Research Styles in Machine Learning</a></p>
<p>18 0.10093023 <a title="42-tfidf-18" href="../hunch_net-2009/hunch_net-2009-06-01-Multitask_Poisoning.html">358 hunch net-2009-06-01-Multitask Poisoning</a></p>
<p>19 0.099708334 <a title="42-tfidf-19" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>20 0.097992323 <a title="42-tfidf-20" href="../hunch_net-2006/hunch_net-2006-01-08-Debugging_Your_Brain.html">147 hunch net-2006-01-08-Debugging Your Brain</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/hunch_net_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.255), (1, 0.022), (2, 0.027), (3, -0.087), (4, 0.024), (5, 0.0), (6, 0.025), (7, -0.006), (8, -0.058), (9, 0.002), (10, -0.049), (11, -0.036), (12, -0.021), (13, -0.0), (14, -0.022), (15, 0.058), (16, -0.077), (17, -0.1), (18, 0.057), (19, -0.022), (20, 0.054), (21, -0.004), (22, 0.024), (23, 0.03), (24, 0.024), (25, 0.027), (26, 0.018), (27, -0.055), (28, 0.015), (29, 0.067), (30, -0.034), (31, -0.007), (32, -0.062), (33, 0.012), (34, -0.032), (35, -0.105), (36, -0.004), (37, 0.056), (38, 0.077), (39, -0.036), (40, 0.016), (41, 0.052), (42, 0.012), (43, -0.05), (44, 0.04), (45, -0.002), (46, -0.134), (47, 0.015), (48, 0.043), (49, 0.104)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.96876454 <a title="42-lsi-1" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>Introduction: At many points in research, you face a choice: should I keep on improving some
old piece of technology or should I do something new? For example:Should I
refine bounds to make them tighter?Should I take some learning theory and turn
it into a learning algorithm?Should I implement the learning algorithm?Should
I test the learning algorithm widely?Should I release the algorithm as source
code?Should I go see what problems people actually need to solve?The universal
temptation of people attracted to research is doing something new. That is
sometimes the right decision, but is also often not. I'd like to discuss some
reasons why not.ExpertiseOnce expertise are developed on some subject, you are
the right person to refine them.What is the real problem?Continually improving
a piece of technology is a mechanism forcing you to confront this question. In
many cases, this confrontation is uncomfortable because you discover that your
method has fundamental flaws with respect to solving the real p</p><p>2 0.73369712 <a title="42-lsi-2" href="../hunch_net-2010/hunch_net-2010-05-02-What%26%238217%3Bs_the_difference_between_gambling_and_rewarding_good_prediction%3F.html">397 hunch net-2010-05-02-What&#8217;s the difference between gambling and rewarding good prediction?</a></p>
<p>Introduction: After amajor financial crisis, there is much discussion about howfinance has
become a casinogambling with other's money, keeping the winnings, and walking
away when the money is lost.When thinking about financial reform, all the many
losers in the above scenario are apt to take the view that this activity
should be completely, or nearly completely curtailed. But, a more thoughtful
view is that sometimes there is a real sense in which there are right and
wrong decisions, and we as a society would really prefer that the people most
likely to make right decisions are making them. A crucial question then is:
"What is the difference between gambling and rewarding good
prediction?"Wediscussed this before the financial crisis. The cheat-sheet
sketch is that the online learning against an adversary problem, algorithm,
and theorems, provide a good mathematical model for thinking about this
question. What I would like to do here is map this onto various types of
financial transactions. The basic</p><p>3 0.71063071 <a title="42-lsi-3" href="../hunch_net-2006/hunch_net-2006-08-10-Precision_is_not_accuracy.html">202 hunch net-2006-08-10-Precision is not accuracy</a></p>
<p>Introduction: In my experience, there are two different groups of people who believe the
same thing: the mathematics encountered in typical machine learning conference
papers is often of questionable value.The two groups who agree on this are
applied machine learning people who have given up on math, and mature
theoreticians who understand the limits of theory.Partly, this is just a
statement about where we are with respect to machine learning. In particular,
we have no mechanism capable of generating a prescription for how to solve all
learning problems. In the absence of such certainty, people try to come up
with formalisms that partially describe and motivate how and why they do
things. This is natural and healthy--we might hope that it will eventually
lead to just such a mechanism.But, part of this is simply an emphasis on
complexity over clarity. A very natural and simple theoretical statement is
often obscured by complexifications. Common sources of complexification
include:GeneralizationBy tr</p><p>4 0.6930815 <a title="42-lsi-4" href="../hunch_net-2006/hunch_net-2006-03-09-Use_of_Notation.html">162 hunch net-2006-03-09-Use of Notation</a></p>
<p>Introduction: For most people, a mathematical notation is like a language: you learn it and
stick with it. For people doing mathematical research, however, this is not
enough: they must design new notations for new problems. The design of good
notation is both hard and worthwhile since a bad initial notation can retard a
line of research greatly.Before we had mathematical notation, equations were
all written out in language. Since words have multiple meanings and variable
precedences, long equations written out in language can be extraordinarily
difficult and sometimes fundamentally ambiguous. A good representative example
of this is the legalese in the tax code. Since we want greater precision and
clarity, we adopt mathematical notation.One fundamental thing to understand
about mathematical notation, is that humans as logic verifiers, are barely
capable. This is the fundamental reason why one notation can be much better
than another. This observation is easier to miss than you might expect
because,</p><p>5 0.67744833 <a title="42-lsi-5" href="../hunch_net-2005/hunch_net-2005-02-18-What_it_means_to_do_research..html">22 hunch net-2005-02-18-What it means to do research.</a></p>
<p>Introduction: I want to try to describe what doing research means, especially from the point
of view of an undergraduate. The shift from a class-taking mentality to a
research mentality is very significant and not easy.Problem PosingPosing the
right problem is often as important as solving them. Many people can get by in
research by solving problems others have posed, but that's not sufficient for
really inspiring research. For learning in particular, there is a strong
feeling that we just haven't figured out which questions are the right ones to
ask. You can see this, because the answers we have do not seem
convincing.Gambling your lifeWhen you do research, you think very hard about
new ways of solving problems, new problems, and new solutions. Many
conversations are of the form "I wonder what would happen if…" These processes
can be short (days or weeks) or years-long endeavours. The worst part is that
you'll only know if you were succesful at the end of the process (and
sometimes not even then be</p><p>6 0.67449939 <a title="42-lsi-6" href="../hunch_net-2006/hunch_net-2006-08-28-Learning_Theory_standards_for_NIPS_2006.html">204 hunch net-2006-08-28-Learning Theory standards for NIPS 2006</a></p>
<p>7 0.65783978 <a title="42-lsi-7" href="../hunch_net-2012/hunch_net-2012-01-30-ICML_Posters_and_Scope.html">454 hunch net-2012-01-30-ICML Posters and Scope</a></p>
<p>8 0.65339619 <a title="42-lsi-8" href="../hunch_net-2005/hunch_net-2005-07-10-Thinking_the_Unthought.html">91 hunch net-2005-07-10-Thinking the Unthought</a></p>
<p>9 0.64832187 <a title="42-lsi-9" href="../hunch_net-2008/hunch_net-2008-07-04-More_Presentation_Preparation.html">307 hunch net-2008-07-04-More Presentation Preparation</a></p>
<p>10 0.6478337 <a title="42-lsi-10" href="../hunch_net-2005/hunch_net-2005-08-22-Do_you_believe_in_induction%3F.html">104 hunch net-2005-08-22-Do you believe in induction?</a></p>
<p>11 0.63333267 <a title="42-lsi-11" href="../hunch_net-2008/hunch_net-2008-12-23-Use_of_Learning_Theory.html">332 hunch net-2008-12-23-Use of Learning Theory</a></p>
<p>12 0.63318694 <a title="42-lsi-12" href="../hunch_net-2007/hunch_net-2007-02-10-Best_Practices_for_Collaboration.html">231 hunch net-2007-02-10-Best Practices for Collaboration</a></p>
<p>13 0.63294995 <a title="42-lsi-13" href="../hunch_net-2005/hunch_net-2005-07-27-Not_goal_metrics.html">98 hunch net-2005-07-27-Not goal metrics</a></p>
<p>14 0.62349474 <a title="42-lsi-14" href="../hunch_net-2006/hunch_net-2006-06-25-Presentation_of_Proofs_is_Hard..html">187 hunch net-2006-06-25-Presentation of Proofs is Hard.</a></p>
<p>15 0.60117316 <a title="42-lsi-15" href="../hunch_net-2007/hunch_net-2007-06-21-Presentation_Preparation.html">249 hunch net-2007-06-21-Presentation Preparation</a></p>
<p>16 0.59626156 <a title="42-lsi-16" href="../hunch_net-2011/hunch_net-2011-05-16-Research_Directions_for_Machine_Learning_and_Algorithms.html">435 hunch net-2011-05-16-Research Directions for Machine Learning and Algorithms</a></p>
<p>17 0.59396636 <a title="42-lsi-17" href="../hunch_net-2006/hunch_net-2006-01-13-Benchmarks_for_RL.html">148 hunch net-2006-01-13-Benchmarks for RL</a></p>
<p>18 0.59172225 <a title="42-lsi-18" href="../hunch_net-2007/hunch_net-2007-02-16-The_Forgetting.html">233 hunch net-2007-02-16-The Forgetting</a></p>
<p>19 0.58928937 <a title="42-lsi-19" href="../hunch_net-2005/hunch_net-2005-10-26-Fallback_Analysis_is_a_Secret_to_Useful_Algorithms.html">126 hunch net-2005-10-26-Fallback Analysis is a Secret to Useful Algorithms</a></p>
<p>20 0.58907878 <a title="42-lsi-20" href="../hunch_net-2009/hunch_net-2009-03-26-Machine_Learning_is_too_easy.html">347 hunch net-2009-03-26-Machine Learning is too easy</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/hunch_net_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(35, 0.07), (42, 0.225), (45, 0.06), (68, 0.073), (74, 0.14), (80, 0.192), (83, 0.031), (88, 0.038), (95, 0.079)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>1 0.89689243 <a title="42-lda-1" href="../hunch_net-2005/hunch_net-2005-08-11-Why_Manifold-Based_Dimension_Reduction_Techniques%3F.html">102 hunch net-2005-08-11-Why Manifold-Based Dimension Reduction Techniques?</a></p>
<p>Introduction: Manifold based dimension-reduction algorithms share the following general
outline.Given: a metricd()and a set of pointsSConstruct a graph with a point
in every node and every edge connecting to the node of one of thek-nearest
neighbors. Associate with the edge a weight which is the distance between the
points in the connected nodes.Digest the graph. This might include computing
the shortest path between all points or figuring out how to linearly
interpolate the point from it's neighbors.Find a set of points in a low
dimensional space which preserve the digested properties.Examples include LLE,
Isomap (which I worked on), Hessian-LLE, SDE, and many others. The hope with
these algorithms is that they can recover the low dimensional structure of
point sets in high dimensional spaces. Many of them can be shown to work in
interesting ways producing various compelling pictures.Despite doing some
early work in this direction, I suffer from a motivational problem: Why do we
want to recover the</p><p>2 0.8940022 <a title="42-lda-2" href="../hunch_net-2011/hunch_net-2011-07-11-Interesting_Neural_Network_Papers_at_ICML_2011.html">438 hunch net-2011-07-11-Interesting Neural Network Papers at ICML 2011</a></p>
<p>Introduction: Maybe it's too early to call, but with four separate Neural Network sessions
at this year'sICML, it looks like Neural Networks are making a comeback. Here
are my highlights of these sessions. In general, my feeling is that these
papers both demystify deep learning and show its broader applicability.The
first observation I made is that the once disreputable "Neural" nomenclature
is being used againin lieu of"deep learning". Maybe it's because Adam Coates
et al. showed that single layer networks can work surprisingly well.An
Analysis of Single-Layer Networks in Unsupervised Feature Learning,Adam
Coates,Honglak Lee,Andrew Y. Ng(AISTATS 2011)The Importance of Encoding Versus
Training with Sparse Coding and Vector Quantization,Adam Coates,Andrew Y.
Ng(ICML 2011)Another surprising result out of Andrew Ng's group comes from
Andrew Saxe et al. who show that certain convolutional pooling architectures
can obtain close to state-of-the-art performance with random weights (that is,
without actuall</p><p>same-blog 3 0.88198233 <a title="42-lda-3" href="../hunch_net-2005/hunch_net-2005-03-17-Going_all_the_Way%2C_Sometimes.html">42 hunch net-2005-03-17-Going all the Way, Sometimes</a></p>
<p>Introduction: At many points in research, you face a choice: should I keep on improving some
old piece of technology or should I do something new? For example:Should I
refine bounds to make them tighter?Should I take some learning theory and turn
it into a learning algorithm?Should I implement the learning algorithm?Should
I test the learning algorithm widely?Should I release the algorithm as source
code?Should I go see what problems people actually need to solve?The universal
temptation of people attracted to research is doing something new. That is
sometimes the right decision, but is also often not. I'd like to discuss some
reasons why not.ExpertiseOnce expertise are developed on some subject, you are
the right person to refine them.What is the real problem?Continually improving
a piece of technology is a mechanism forcing you to confront this question. In
many cases, this confrontation is uncomfortable because you discover that your
method has fundamental flaws with respect to solving the real p</p><p>4 0.83577222 <a title="42-lda-4" href="../hunch_net-2005/hunch_net-2005-10-13-Site_tweak.html">122 hunch net-2005-10-13-Site tweak</a></p>
<p>Introduction: Several people have had difficulty with comments which seem to have an allowed
language significantly poorer than posts. The set of allowed html tags has
been increased and themarkdown filterhas been put in place to try to make
commenting easier. I'll put some examples into the comments of this post.</p><p>5 0.83399314 <a title="42-lda-5" href="../hunch_net-2009/hunch_net-2009-05-19-CI_Fellows.html">355 hunch net-2009-05-19-CI Fellows</a></p>
<p>Introduction: Lev Reyzinpoints out theCI Fellows Project. Essentially,NSFis funding 60
postdocs in computer science for graduates from a wide array of US places to a
wide array of US places. This is particularly welcome given a tough year for
new hires. I expect some fraction of these postdocs will be in ML. The time
frame is quite short, so those interested should look it over immediately.</p><p>6 0.82077056 <a title="42-lda-6" href="../hunch_net-2011/hunch_net-2011-08-20-The_Large_Scale_Learning_Survey_Tutorial.html">442 hunch net-2011-08-20-The Large Scale Learning Survey Tutorial</a></p>
<p>7 0.79571098 <a title="42-lda-7" href="../hunch_net-2005/hunch_net-2005-10-10-Predictive_Search_is_Coming.html">120 hunch net-2005-10-10-Predictive Search is Coming</a></p>
<p>8 0.79536164 <a title="42-lda-8" href="../hunch_net-2005/hunch_net-2005-09-12-Fast_Gradient_Descent.html">111 hunch net-2005-09-12-Fast Gradient Descent</a></p>
<p>9 0.79506069 <a title="42-lda-9" href="../hunch_net-2007/hunch_net-2007-03-03-All_Models_of_Learning_have_Flaws.html">235 hunch net-2007-03-03-All Models of Learning have Flaws</a></p>
<p>10 0.7947579 <a title="42-lda-10" href="../hunch_net-2012/hunch_net-2012-01-04-Why_ICML%3F_and_the_summer_conferences.html">452 hunch net-2012-01-04-Why ICML? and the summer conferences</a></p>
<p>11 0.79391968 <a title="42-lda-11" href="../hunch_net-2006/hunch_net-2006-08-18-Report_of_MLSS_2006_Taipei.html">203 hunch net-2006-08-18-Report of MLSS 2006 Taipei</a></p>
<p>12 0.78853595 <a title="42-lda-12" href="../hunch_net-2006/hunch_net-2006-06-14-Explorations_of_Exploration.html">183 hunch net-2006-06-14-Explorations of Exploration</a></p>
<p>13 0.78701484 <a title="42-lda-13" href="../hunch_net-2006/hunch_net-2006-05-05-An_ICML_reject.html">177 hunch net-2006-05-05-An ICML reject</a></p>
<p>14 0.78657401 <a title="42-lda-14" href="../hunch_net-2008/hunch_net-2008-04-22-Taking_the_next_step.html">297 hunch net-2008-04-22-Taking the next step</a></p>
<p>15 0.78647172 <a title="42-lda-15" href="../hunch_net-2005/hunch_net-2005-08-23-%28Dis%29similarities_between_academia_and_open_source_programmers.html">105 hunch net-2005-08-23-(Dis)similarities between academia and open source programmers</a></p>
<p>16 0.78574997 <a title="42-lda-16" href="../hunch_net-2005/hunch_net-2005-04-01-The_Producer-Consumer_Model_of_Research.html">51 hunch net-2005-04-01-The Producer-Consumer Model of Research</a></p>
<p>17 0.78545892 <a title="42-lda-17" href="../hunch_net-2010/hunch_net-2010-08-22-KDD_2010.html">406 hunch net-2010-08-22-KDD 2010</a></p>
<p>18 0.78533077 <a title="42-lda-18" href="../hunch_net-2009/hunch_net-2009-02-18-Decision_by_Vetocracy.html">343 hunch net-2009-02-18-Decision by Vetocracy</a></p>
<p>19 0.7852366 <a title="42-lda-19" href="../hunch_net-2009/hunch_net-2009-02-22-Effective_Research_Funding.html">344 hunch net-2009-02-22-Effective Research Funding</a></p>
<p>20 0.7844215 <a title="42-lda-20" href="../hunch_net-2011/hunch_net-2011-12-02-Hadoop_AllReduce_and_Terascale_Learning.html">450 hunch net-2011-12-02-Hadoop AllReduce and Terascale Learning</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
