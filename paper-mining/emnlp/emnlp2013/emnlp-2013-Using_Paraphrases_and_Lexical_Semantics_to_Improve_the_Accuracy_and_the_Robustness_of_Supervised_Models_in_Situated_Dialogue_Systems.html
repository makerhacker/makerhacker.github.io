<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2013" href="../home/emnlp2013_home.html">emnlp2013</a> <a title="emnlp-2013-197" href="#">emnlp2013-197</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</h1>
<br/><p>Source: <a title="emnlp-2013-197-pdf" href="http://aclweb.org/anthology//D/D13/D13-1076.pdf">pdf</a></p><p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>Reference: <a title="emnlp-2013-197-reference" href="../emnlp2013_reference/emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('dialog', 0.535), ('synonym', 0.417), ('paraphras', 0.29), ('lem', 0.268), ('eurowordnet', 0.179), ('barahon', 0.149), ('emospeech', 0.149), ('roja', 0.149), ('ut', 0.127), ('unknown', 0.123), ('impact', 0.109), ('virt', 0.098), ('french', 0.096), ('devault', 0.09), ('subdialog', 0.09), ('handl', 0.089), ('expand', 0.089), ('treetag', 0.088), ('qa', 0.085), ('neighbo', 0.07)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999917 <a title="197-tfidf-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.25311971 <a title="197-tfidf-2" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>3 0.18137982 <a title="197-tfidf-3" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>4 0.17166443 <a title="197-tfidf-4" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>Author: Yangfeng Ji ; Jacob Eisenstein</p><p>Abstract: Matrix and tensor factorization have been applied to a number of semantic relatedness tasks, including paraphrase identification. The key idea is that similarity in the latent space implies semantic relatedness. We describe three ways in which labeled data can improve the accuracy of these approaches on paraphrase classification. First, we design a new discriminative term-weighting metric called TF-KLD, which outperforms TF-IDF. Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy. Finally, we combine latent features with fine-grained n-gram overlap features, yielding performance that is 3% more accurate than the prior state-of-the-art.</p><p>5 0.13351403 <a title="197-tfidf-5" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>Author: Gyorgy Szarvas ; Robert Busa-Fekete ; Eyke Hullermeier</p><p>Abstract: The problem to replace a word with a synonym that fits well in its sentential context is known as the lexical substitution task. In this paper, we tackle this task as a supervised ranking problem. Given a dataset of target words, their sentential contexts and the potential substitutions for the target words, the goal is to train a model that accurately ranks the candidate substitutions based on their contextual fitness. As a key contribution, we customize and evaluate several learning-to-rank models to the lexical substitution task, including classification-based and regression-based approaches. On two datasets widely used for lexical substitution, our best models signifi- cantly advance the state-of-the-art.</p><p>6 0.12590227 <a title="197-tfidf-6" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>7 0.090549693 <a title="197-tfidf-7" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>8 0.079613984 <a title="197-tfidf-8" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>9 0.075297549 <a title="197-tfidf-9" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>10 0.074886657 <a title="197-tfidf-10" href="./emnlp-2013-Detecting_Compositionality_of_Multi-Word_Expressions_using_Nearest_Neighbours_in_Vector_Space_Models.html">60 emnlp-2013-Detecting Compositionality of Multi-Word Expressions using Nearest Neighbours in Vector Space Models</a></p>
<p>11 0.061259113 <a title="197-tfidf-11" href="./emnlp-2013-Semi-Markov_Phrase-Based_Monolingual_Alignment.html">167 emnlp-2013-Semi-Markov Phrase-Based Monolingual Alignment</a></p>
<p>12 0.060243532 <a title="197-tfidf-12" href="./emnlp-2013-Monolingual_Marginal_Matching_for_Translation_Model_Adaptation.html">135 emnlp-2013-Monolingual Marginal Matching for Translation Model Adaptation</a></p>
<p>13 0.054218248 <a title="197-tfidf-13" href="./emnlp-2013-Multi-Relational_Latent_Semantic_Analysis.html">137 emnlp-2013-Multi-Relational Latent Semantic Analysis</a></p>
<p>14 0.050069399 <a title="197-tfidf-14" href="./emnlp-2013-Paraphrasing_4_Microblog_Normalization.html">151 emnlp-2013-Paraphrasing 4 Microblog Normalization</a></p>
<p>15 0.048138496 <a title="197-tfidf-15" href="./emnlp-2013-Building_Specialized_Bilingual_Lexicons_Using_Large_Scale_Background_Knowledge.html">42 emnlp-2013-Building Specialized Bilingual Lexicons Using Large Scale Background Knowledge</a></p>
<p>16 0.047667906 <a title="197-tfidf-16" href="./emnlp-2013-Improving_Statistical_Machine_Translation_with_Word_Class_Models.html">104 emnlp-2013-Improving Statistical Machine Translation with Word Class Models</a></p>
<p>17 0.047286101 <a title="197-tfidf-17" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>18 0.045545809 <a title="197-tfidf-18" href="./emnlp-2013-Unsupervised_Induction_of_Contingent_Event_Pairs_from_Film_Scenes.html">192 emnlp-2013-Unsupervised Induction of Contingent Event Pairs from Film Scenes</a></p>
<p>19 0.045485985 <a title="197-tfidf-19" href="./emnlp-2013-Semi-Supervised_Representation_Learning_for_Cross-Lingual_Text_Classification.html">169 emnlp-2013-Semi-Supervised Representation Learning for Cross-Lingual Text Classification</a></p>
<p>20 0.0441668 <a title="197-tfidf-20" href="./emnlp-2013-The_Effects_of_Syntactic_Features_in_Automatic_Prediction_of_Morphology.html">181 emnlp-2013-The Effects of Syntactic Features in Automatic Prediction of Morphology</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.165), (1, -0.019), (2, 0.025), (3, -0.058), (4, -0.048), (5, -0.045), (6, -0.006), (7, -0.042), (8, -0.085), (9, -0.028), (10, -0.088), (11, 0.156), (12, -0.047), (13, 0.011), (14, 0.082), (15, 0.077), (16, -0.067), (17, -0.013), (18, -0.274), (19, 0.088), (20, 0.261), (21, -0.163), (22, -0.305), (23, 0.071), (24, 0.152), (25, -0.206), (26, 0.11), (27, 0.139), (28, -0.041), (29, 0.058), (30, -0.01), (31, 0.061), (32, -0.145), (33, 0.055), (34, 0.0), (35, -0.096), (36, 0.058), (37, -0.024), (38, 0.016), (39, -0.097), (40, 0.006), (41, 0.017), (42, -0.127), (43, -0.027), (44, -0.03), (45, -0.001), (46, -0.082), (47, -0.025), (48, -0.054), (49, -0.049)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95305026 <a title="197-lsi-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.82075816 <a title="197-lsi-2" href="./emnlp-2013-Grounding_Strategic_Conversation%3A_Using_Negotiation_Dialogues_to_Predict_Trades_in_a_Win-Lose_Game.html">91 emnlp-2013-Grounding Strategic Conversation: Using Negotiation Dialogues to Predict Trades in a Win-Lose Game</a></p>
<p>Author: Anais Cadilhac ; Nicholas Asher ; Farah Benamara ; Alex Lascarides</p><p>Abstract: This paper describes a method that predicts which trades players execute during a winlose game. Our method uses data collected from chat negotiations of the game The Settlers of Catan and exploits the conversation to construct dynamically a partial model of each player’s preferences. This in turn yields equilibrium trading moves via principles from game theory. We compare our method against four baselines and show that tracking how preferences evolve through the dialogue and reasoning about equilibrium moves are both crucial to success.</p><p>3 0.54494208 <a title="197-lsi-3" href="./emnlp-2013-Predicting_the_Resolution_of_Referring_Expressions_from_User_Behavior.html">153 emnlp-2013-Predicting the Resolution of Referring Expressions from User Behavior</a></p>
<p>Author: Nikos Engonopoulos ; Martin Villalba ; Ivan Titov ; Alexander Koller</p><p>Abstract: We present a statistical model for predicting how the user of an interactive, situated NLP system resolved a referring expression. The model makes an initial prediction based on the meaning of the utterance, and revises it continuously based on the user’s behavior. The combined model outperforms its components in predicting reference resolution and when to give feedback.</p><p>4 0.51563448 <a title="197-lsi-4" href="./emnlp-2013-Discriminative_Improvements_to_Distributional_Sentence_Similarity.html">64 emnlp-2013-Discriminative Improvements to Distributional Sentence Similarity</a></p>
<p>Author: Yangfeng Ji ; Jacob Eisenstein</p><p>Abstract: Matrix and tensor factorization have been applied to a number of semantic relatedness tasks, including paraphrase identification. The key idea is that similarity in the latent space implies semantic relatedness. We describe three ways in which labeled data can improve the accuracy of these approaches on paraphrase classification. First, we design a new discriminative term-weighting metric called TF-KLD, which outperforms TF-IDF. Next, we show that using the latent representation from matrix factorization as features in a classification algorithm substantially improves accuracy. Finally, we combine latent features with fine-grained n-gram overlap features, yielding performance that is 3% more accurate than the prior state-of-the-art.</p><p>5 0.47728321 <a title="197-lsi-5" href="./emnlp-2013-Harvesting_Parallel_News_Streams_to_Generate_Paraphrases_of_Event_Relations.html">93 emnlp-2013-Harvesting Parallel News Streams to Generate Paraphrases of Event Relations</a></p>
<p>Author: Congle Zhang ; Daniel S. Weld</p><p>Abstract: The distributional hypothesis, which states that words that occur in similar contexts tend to have similar meanings, has inspired several Web mining algorithms for paraphrasing semantically equivalent phrases. Unfortunately, these methods have several drawbacks, such as confusing synonyms with antonyms and causes with effects. This paper introduces three Temporal Correspondence Heuristics, that characterize regularities in parallel news streams, and shows how they may be used to generate high precision paraphrases for event relations. We encode the heuristics in a probabilistic graphical model to create the NEWSSPIKE algorithm for mining news streams. We present experiments demonstrating that NEWSSPIKE significantly outperforms several competitive baselines. In order to spur further research, we provide a large annotated corpus of timestamped news arti- cles as well as the paraphrases produced by NEWSSPIKE.</p><p>6 0.43380505 <a title="197-lsi-6" href="./emnlp-2013-A_Generative_Joint%2C_Additive%2C_Sequential_Model_of_Topics_and_Speech_Acts_in_Patient-Doctor_Communication.html">6 emnlp-2013-A Generative Joint, Additive, Sequential Model of Topics and Speech Acts in Patient-Doctor Communication</a></p>
<p>7 0.42574534 <a title="197-lsi-7" href="./emnlp-2013-Learning_to_Rank_Lexical_Substitutions.html">123 emnlp-2013-Learning to Rank Lexical Substitutions</a></p>
<p>8 0.28808221 <a title="197-lsi-8" href="./emnlp-2013-Towards_Situated_Dialogue%3A_Revisiting_Referring_Expression_Generation.html">185 emnlp-2013-Towards Situated Dialogue: Revisiting Referring Expression Generation</a></p>
<p>9 0.26983559 <a title="197-lsi-9" href="./emnlp-2013-Multi-Relational_Latent_Semantic_Analysis.html">137 emnlp-2013-Multi-Relational Latent Semantic Analysis</a></p>
<p>10 0.26811466 <a title="197-lsi-10" href="./emnlp-2013-Two-Stage_Method_for_Large-Scale_Acquisition_of_Contradiction_Pattern_Pairs_using_Entailment.html">189 emnlp-2013-Two-Stage Method for Large-Scale Acquisition of Contradiction Pattern Pairs using Entailment</a></p>
<p>11 0.26639864 <a title="197-lsi-11" href="./emnlp-2013-With_Blinkers_on%3A_Robust_Prediction_of_Eye_Movements_across_Readers.html">203 emnlp-2013-With Blinkers on: Robust Prediction of Eye Movements across Readers</a></p>
<p>12 0.23379521 <a title="197-lsi-12" href="./emnlp-2013-This_Text_Has_the_Scent_of_Starbucks%3A_A_Laplacian_Structured_Sparsity_Model_for_Computational_Branding_Analytics.html">184 emnlp-2013-This Text Has the Scent of Starbucks: A Laplacian Structured Sparsity Model for Computational Branding Analytics</a></p>
<p>13 0.23253699 <a title="197-lsi-13" href="./emnlp-2013-Scaling_to_Large3_Data%3A_An_Efficient_and_Effective_Method_to_Compute_Distributional_Thesauri.html">165 emnlp-2013-Scaling to Large3 Data: An Efficient and Effective Method to Compute Distributional Thesauri</a></p>
<p>14 0.2187261 <a title="197-lsi-14" href="./emnlp-2013-Automatic_Idiom_Identification_in_Wiktionary.html">32 emnlp-2013-Automatic Idiom Identification in Wiktionary</a></p>
<p>15 0.20930879 <a title="197-lsi-15" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>16 0.20319341 <a title="197-lsi-16" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>17 0.19985288 <a title="197-lsi-17" href="./emnlp-2013-Exploiting_Multiple_Sources_for_Open-Domain_Hypernym_Discovery.html">79 emnlp-2013-Exploiting Multiple Sources for Open-Domain Hypernym Discovery</a></p>
<p>18 0.19737507 <a title="197-lsi-18" href="./emnlp-2013-Dependency_Language_Models_for_Sentence_Completion.html">58 emnlp-2013-Dependency Language Models for Sentence Completion</a></p>
<p>19 0.19721021 <a title="197-lsi-19" href="./emnlp-2013-Cascading_Collective_Classification_for_Bridging_Anaphora_Recognition_using_a_Rich_Linguistic_Feature_Set.html">43 emnlp-2013-Cascading Collective Classification for Bridging Anaphora Recognition using a Rich Linguistic Feature Set</a></p>
<p>20 0.1891904 <a title="197-lsi-20" href="./emnlp-2013-Anchor_Graph%3A_Global_Reordering_Contexts_for_Statistical_Machine_Translation.html">22 emnlp-2013-Anchor Graph: Global Reordering Contexts for Statistical Machine Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(11, 0.016), (23, 0.019), (25, 0.032), (29, 0.03), (47, 0.046), (51, 0.06), (65, 0.131), (69, 0.045), (73, 0.132), (79, 0.031), (86, 0.361)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71655893 <a title="197-lda-1" href="./emnlp-2013-Using_Paraphrases_and_Lexical_Semantics_to_Improve_the_Accuracy_and_the_Robustness_of_Supervised_Models_in_Situated_Dialogue_Systems.html">197 emnlp-2013-Using Paraphrases and Lexical Semantics to Improve the Accuracy and the Robustness of Supervised Models in Situated Dialogue Systems</a></p>
<p>Author: Claire Gardent ; Lina M. Rojas Barahona</p><p>Abstract: This paper explores to what extent lemmatisation, lexical resources, distributional semantics and paraphrases can increase the accuracy of supervised models for dialogue management. The results suggest that each of these factors can help improve performance but that the impact will vary depending on their combination and on the evaluation mode.</p><p>2 0.67514783 <a title="197-lda-2" href="./emnlp-2013-Sentiment_Analysis%3A_How_to_Derive_Prior_Polarities_from_SentiWordNet.html">170 emnlp-2013-Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</a></p>
<p>Author: Marco Guerini ; Lorenzo Gatti ; Marco Turchi</p><p>Abstract: Assigning a positive or negative score to a word out of context (i.e. a word’s prior polarity) is a challenging task for sentiment analysis. In the literature, various approaches based on SentiWordNet have been proposed. In this paper, we compare the most often used techniques together with newly proposed ones and incorporate all of them in a learning framework to see whether blending them can further improve the estimation of prior polarity scores. Using two different versions of SentiWordNet and testing regression and classification models across tasks and datasets, our learning approach consistently outperforms the single metrics, providing a new state-ofthe-art approach in computing words’ prior polarity for sentiment analysis. We conclude our investigation showing interesting biases in calculated prior polarity scores when word Part of Speech and annotator gender are considered.</p><p>3 0.50014669 <a title="197-lda-3" href="./emnlp-2013-Collective_Personal_Profile_Summarization_with_Social_Networks.html">48 emnlp-2013-Collective Personal Profile Summarization with Social Networks</a></p>
<p>Author: Zhongqing Wang ; Shoushan LI ; Fang Kong ; Guodong Zhou</p><p>Abstract: Personal profile information on social media like LinkedIn.com and Facebook.com is at the core of many interesting applications, such as talent recommendation and contextual advertising. However, personal profiles usually lack organization confronted with the large amount of available information. Therefore, it is always a challenge for people to find desired information from them. In this paper, we address the task of personal profile summarization by leveraging both personal profile textual information and social networks. Here, using social networks is motivated by the intuition that, people with similar academic, business or social connections (e.g. co-major, co-university, and cocorporation) tend to have similar experience and summaries. To achieve the learning process, we propose a collective factor graph (CoFG) model to incorporate all these resources of knowledge to summarize personal profiles with local textual attribute functions and social connection factors. Extensive evaluation on a large-scale dataset from LinkedIn.com demonstrates the effectiveness of the proposed approach. 1</p><p>4 0.49737683 <a title="197-lda-4" href="./emnlp-2013-A_Dataset_for_Research_on_Short-Text_Conversations.html">4 emnlp-2013-A Dataset for Research on Short-Text Conversations</a></p>
<p>Author: Hao Wang ; Zhengdong Lu ; Hang Li ; Enhong Chen</p><p>Abstract: Natural language conversation is widely regarded as a highly difficult problem, which is usually attacked with either rule-based or learning-based models. In this paper we propose a retrieval-based automatic response model for short-text conversation, to exploit the vast amount of short conversation instances available on social media. For this purpose we introduce a dataset of short-text conversation based on the real-world instances from Sina Weibo (a popular Chinese microblog service), which will be soon released to public. This dataset provides rich collection of instances for the research on finding natural and relevant short responses to a given short text, and useful for both training and testing of conversation models. This dataset consists of both naturally formed conversations, manually labeled data, and a large repository of candidate responses. Our preliminary experiments demonstrate that the simple retrieval-based conversation model performs reasonably well when combined with the rich instances in our dataset.</p><p>5 0.49715295 <a title="197-lda-5" href="./emnlp-2013-Simulating_Early-Termination_Search_for_Verbose_Spoken_Queries.html">173 emnlp-2013-Simulating Early-Termination Search for Verbose Spoken Queries</a></p>
<p>Author: Jerome White ; Douglas W. Oard ; Nitendra Rajput ; Marion Zalk</p><p>Abstract: Building search engines that can respond to spoken queries with spoken content requires that the system not just be able to find useful responses, but also that it know when it has heard enough about what the user wants to be able to do so. This paper describes a simulation study with queries spoken by non-native speakers that suggests that indicates that finding relevant content is often possible within a half minute, and that combining features based on automatically recognized words with features designed for automated prediction of query difficulty can serve as a useful basis for predicting when that useful content has been found.</p><p>6 0.49664536 <a title="197-lda-6" href="./emnlp-2013-Structured_Penalties_for_Log-Linear_Language_Models.html">176 emnlp-2013-Structured Penalties for Log-Linear Language Models</a></p>
<p>7 0.49543124 <a title="197-lda-7" href="./emnlp-2013-What_is_Hidden_among_Translation_Rules.html">201 emnlp-2013-What is Hidden among Translation Rules</a></p>
<p>8 0.495303 <a title="197-lda-8" href="./emnlp-2013-A_Log-Linear_Model_for_Unsupervised_Text_Normalization.html">9 emnlp-2013-A Log-Linear Model for Unsupervised Text Normalization</a></p>
<p>9 0.49456373 <a title="197-lda-9" href="./emnlp-2013-Measuring_Ideological_Proportions_in_Political_Speeches.html">129 emnlp-2013-Measuring Ideological Proportions in Political Speeches</a></p>
<p>10 0.49426362 <a title="197-lda-10" href="./emnlp-2013-The_Answer_is_at_your_Fingertips%3A_Improving_Passage_Retrieval_for_Web_Question_Answering_with_Search_Behavior_Data.html">180 emnlp-2013-The Answer is at your Fingertips: Improving Passage Retrieval for Web Question Answering with Search Behavior Data</a></p>
<p>11 0.49327916 <a title="197-lda-11" href="./emnlp-2013-Max-Margin_Synchronous_Grammar_Induction_for_Machine_Translation.html">127 emnlp-2013-Max-Margin Synchronous Grammar Induction for Machine Translation</a></p>
<p>12 0.49207225 <a title="197-lda-12" href="./emnlp-2013-Scaling_Semantic_Parsers_with_On-the-Fly_Ontology_Matching.html">164 emnlp-2013-Scaling Semantic Parsers with On-the-Fly Ontology Matching</a></p>
<p>13 0.49166024 <a title="197-lda-13" href="./emnlp-2013-Centering_Similarity_Measures_to_Reduce_Hubs.html">44 emnlp-2013-Centering Similarity Measures to Reduce Hubs</a></p>
<p>14 0.49092415 <a title="197-lda-14" href="./emnlp-2013-Dynamic_Feature_Selection_for_Dependency_Parsing.html">66 emnlp-2013-Dynamic Feature Selection for Dependency Parsing</a></p>
<p>15 0.49091882 <a title="197-lda-15" href="./emnlp-2013-Discourse_Level_Explanatory_Relation_Extraction_from_Product_Reviews_Using_First-Order_Logic.html">63 emnlp-2013-Discourse Level Explanatory Relation Extraction from Product Reviews Using First-Order Logic</a></p>
<p>16 0.49082845 <a title="197-lda-16" href="./emnlp-2013-A_Discourse-Driven_Content_Model_for_Summarising_Scientific_Articles_Evaluated_in_a_Complex_Question_Answering_Task.html">5 emnlp-2013-A Discourse-Driven Content Model for Summarising Scientific Articles Evaluated in a Complex Question Answering Task</a></p>
<p>17 0.49017966 <a title="197-lda-17" href="./emnlp-2013-Interactive_Machine_Translation_using_Hierarchical_Translation_Models.html">107 emnlp-2013-Interactive Machine Translation using Hierarchical Translation Models</a></p>
<p>18 0.49005115 <a title="197-lda-18" href="./emnlp-2013-Unsupervised_Induction_of_Cross-Lingual_Semantic_Relations.html">193 emnlp-2013-Unsupervised Induction of Cross-Lingual Semantic Relations</a></p>
<p>19 0.49002382 <a title="197-lda-19" href="./emnlp-2013-Inducing_Document_Plans_for_Concept-to-Text_Generation.html">106 emnlp-2013-Inducing Document Plans for Concept-to-Text Generation</a></p>
<p>20 0.48975694 <a title="197-lda-20" href="./emnlp-2013-Exploring_the_Utility_of_Joint_Morphological_and_Syntactic_Learning_from_Child-directed_Speech.html">83 emnlp-2013-Exploring the Utility of Joint Morphological and Syntactic Learning from Child-directed Speech</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
