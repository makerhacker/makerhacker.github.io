<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</title>
</head>

<body>
<p><a title="acl" href="../acl_home.html">acl</a> <a title="acl-2012" href="../home/acl2012_home.html">acl2012</a> <a title="acl-2012-28" href="#">acl2012-28</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</h1>
<br/><p>Source: <a title="acl-2012-28-pdf" href="http://aclweb.org/anthology//P/P12/P12-1036.pdf">pdf</a></p><p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>Reference: <a title="acl-2012-28-reference" href="../acl2012_reference/acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('aspect', 0.592), ('senty', 0.406), ('sas', 0.381), ('staff', 0.157), ('zha', 0.144), ('pillow', 0.14), ('see', 0.128), ('opin', 0.12), ('nonsee', 0.12), ('emit', 0.112), ('andrzejewsk', 0.111), ('discov', 0.091), ('term', 0.089), ('flav', 0.087), ('switch', 0.071), ('asm', 0.07), ('hu', 0.069), ('bed', 0.067), ('draw', 0.058), ('top', 0.056)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999893 <a title="28-tfidf-1" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>2 0.51996326 <a title="28-tfidf-2" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>3 0.35256943 <a title="28-tfidf-3" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>4 0.27098954 <a title="28-tfidf-4" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Writing comments about news articles, blogs, or reviews have become a popular activity in social media. In this paper, we analyze reader comments about reviews. Analyzing review comments is important because reviews only tell the experiences and evaluations of reviewers about the reviewed products or services. Comments, on the other hand, are readers’ evaluations of reviews, their questions and concerns. Clearly, the information in comments is valuable for both future readers and brands. This paper proposes two latent variable models to simultaneously model and extract these key pieces of information. The results also enable classification of comments accurately. Experiments using Amazon review comments demonstrate the effectiveness of the proposed models.</p><p>5 0.2234554 <a title="28-tfidf-5" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>Author: Xinfan Meng ; Furu Wei ; Xiaohua Liu ; Ming Zhou ; Ge Xu ; Houfeng Wang</p><p>Abstract: The amount of labeled sentiment data in English is much larger than that in other languages. Such a disproportion arouse interest in cross-lingual sentiment classification, which aims to conduct sentiment classification in the target language (e.g. Chinese) using labeled data in the source language (e.g. English). Most existing work relies on machine translation engines to directly adapt labeled data from the source language to the target language. This approach suffers from the limited coverage of vocabulary in the machine translation results. In this paper, we propose a generative cross-lingual mixture model (CLMM) to leverage unlabeled bilingual parallel data. By fitting parameters to maximize the likelihood of the bilingual parallel data, the proposed model learns previously unseen sentiment words from the large bilingual parallel data and improves vocabulary coverage signifi- cantly. Experiments on multiple data sets show that CLMM is consistently effective in two settings: (1) labeled data in the target language are unavailable; and (2) labeled data in the target language are also available.</p><p>6 0.19455239 <a title="28-tfidf-6" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>7 0.18605864 <a title="28-tfidf-7" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>8 0.16845527 <a title="28-tfidf-8" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>9 0.16777183 <a title="28-tfidf-9" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>10 0.14521593 <a title="28-tfidf-10" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>11 0.14448415 <a title="28-tfidf-11" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>12 0.13663022 <a title="28-tfidf-12" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<p>13 0.11568361 <a title="28-tfidf-13" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>14 0.10925823 <a title="28-tfidf-14" href="./acl-2012-Fully_Abstractive_Approach_to_Guided_Summarization.html">101 acl-2012-Fully Abstractive Approach to Guided Summarization</a></p>
<p>15 0.099803142 <a title="28-tfidf-15" href="./acl-2012-Subgroup_Detector%3A_A_System_for_Detecting_Subgroups_in_Online_Discussions.html">188 acl-2012-Subgroup Detector: A System for Detecting Subgroups in Online Discussions</a></p>
<p>16 0.092728481 <a title="28-tfidf-16" href="./acl-2012-Tense_and_Aspect_Error_Correction_for_ESL_Learners_Using_Global_Context.html">192 acl-2012-Tense and Aspect Error Correction for ESL Learners Using Global Context</a></p>
<p>17 0.087432504 <a title="28-tfidf-17" href="./acl-2012-Efficient_Tree-Based_Topic_Modeling.html">79 acl-2012-Efficient Tree-Based Topic Modeling</a></p>
<p>18 0.083742417 <a title="28-tfidf-18" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>19 0.081715353 <a title="28-tfidf-19" href="./acl-2012-SITS%3A_A_Hierarchical_Nonparametric_Model_using_Speaker_Identity_for_Topic_Segmentation_in_Multiparty_Conversations.html">171 acl-2012-SITS: A Hierarchical Nonparametric Model using Speaker Identity for Topic Segmentation in Multiparty Conversations</a></p>
<p>20 0.079508983 <a title="28-tfidf-20" href="./acl-2012-A_Topic_Similarity_Model_for_Hierarchical_Phrase-based_Translation.html">22 acl-2012-A Topic Similarity Model for Hierarchical Phrase-based Translation</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/acl2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, -0.222), (1, 0.3), (2, 0.309), (3, -0.211), (4, 0.03), (5, 0.009), (6, 0.001), (7, 0.065), (8, -0.136), (9, -0.138), (10, -0.129), (11, 0.031), (12, 0.113), (13, -0.15), (14, 0.09), (15, -0.005), (16, -0.01), (17, -0.056), (18, -0.112), (19, -0.0), (20, 0.012), (21, 0.067), (22, 0.018), (23, 0.046), (24, -0.013), (25, -0.087), (26, -0.086), (27, 0.051), (28, 0.017), (29, 0.038), (30, -0.031), (31, -0.004), (32, -0.062), (33, -0.072), (34, 0.022), (35, 0.043), (36, 0.091), (37, -0.071), (38, 0.024), (39, -0.019), (40, 0.067), (41, -0.025), (42, -0.024), (43, -0.107), (44, 0.129), (45, 0.079), (46, 0.087), (47, -0.055), (48, -0.062), (49, -0.04)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.956882 <a title="28-lsi-1" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>2 0.93387735 <a title="28-lsi-2" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>3 0.76071519 <a title="28-lsi-3" href="./acl-2012-Cross-Domain_Co-Extraction_of_Sentiment_and_Topic_Lexicons.html">61 acl-2012-Cross-Domain Co-Extraction of Sentiment and Topic Lexicons</a></p>
<p>Author: Fangtao Li ; Sinno Jialin Pan ; Ou Jin ; Qiang Yang ; Xiaoyan Zhu</p><p>Abstract: Extracting sentiment and topic lexicons is important for opinion mining. Previous works have showed that supervised learning methods are superior for this task. However, the performance of supervised methods highly relies on manually labeled training data. In this paper, we propose a domain adaptation framework for sentiment- and topic- lexicon co-extraction in a domain of interest where we do not require any labeled data, but have lots of labeled data in another related domain. The framework is twofold. In the first step, we generate a few high-confidence sentiment and topic seeds in the target domain. In the second step, we propose a novel Relational Adaptive bootstraPping (RAP) algorithm to expand the seeds in the target domain by exploiting the labeled source domain data and the relationships between topic and sentiment words. Experimental results show that our domain adaptation framework can extract precise lexicons in the target domain without any annotation.</p><p>4 0.68239498 <a title="28-lsi-4" href="./acl-2012-Baselines_and_Bigrams%3A_Simple%2C_Good_Sentiment_and_Topic_Classification.html">37 acl-2012-Baselines and Bigrams: Simple, Good Sentiment and Topic Classification</a></p>
<p>Author: Sida Wang ; Christopher Manning</p><p>Abstract: Variants of Naive Bayes (NB) and Support Vector Machines (SVM) are often used as baseline methods for text classification, but their performance varies greatly depending on the model variant, features used and task/ dataset. We show that: (i) the inclusion of word bigram features gives consistent gains on sentiment analysis tasks; (ii) for short snippet sentiment tasks, NB actually does better than SVMs (while for longer documents the opposite result holds); (iii) a simple but novel SVM variant using NB log-count ratios as feature values consistently performs well across tasks and datasets. Based on these observations, we identify simple NB and SVM variants which outperform most published results on sentiment analysis datasets, sometimes providing a new state-of-the-art performance level.</p><p>5 0.66189933 <a title="28-lsi-5" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Writing comments about news articles, blogs, or reviews have become a popular activity in social media. In this paper, we analyze reader comments about reviews. Analyzing review comments is important because reviews only tell the experiences and evaluations of reviewers about the reviewed products or services. Comments, on the other hand, are readers’ evaluations of reviews, their questions and concerns. Clearly, the information in comments is valuable for both future readers and brands. This paper proposes two latent variable models to simultaneously model and extract these key pieces of information. The results also enable classification of comments accurately. Experiments using Amazon review comments demonstrate the effectiveness of the proposed models.</p><p>6 0.62699568 <a title="28-lsi-6" href="./acl-2012-Multilingual_Subjectivity_and_Sentiment_Analysis.html">151 acl-2012-Multilingual Subjectivity and Sentiment Analysis</a></p>
<p>7 0.61725479 <a title="28-lsi-7" href="./acl-2012-Cross-Lingual_Mixture_Model_for_Sentiment_Classification.html">62 acl-2012-Cross-Lingual Mixture Model for Sentiment Classification</a></p>
<p>8 0.60342705 <a title="28-lsi-8" href="./acl-2012-Polarity_Consistency_Checking_for_Sentiment_Dictionaries.html">161 acl-2012-Polarity Consistency Checking for Sentiment Dictionaries</a></p>
<p>9 0.53147197 <a title="28-lsi-9" href="./acl-2012-A_System_for_Real-time_Twitter_Sentiment_Analysis_of_2012_U.S._Presidential_Election_Cycle.html">21 acl-2012-A System for Real-time Twitter Sentiment Analysis of 2012 U.S. Presidential Election Cycle</a></p>
<p>10 0.49396208 <a title="28-lsi-10" href="./acl-2012-Social_Event_Radar%3A_A_Bilingual_Context_Mining_and_Sentiment_Analysis_Summarization_System.html">180 acl-2012-Social Event Radar: A Bilingual Context Mining and Sentiment Analysis Summarization System</a></p>
<p>11 0.47306719 <a title="28-lsi-11" href="./acl-2012-Identifying_High-Impact_Sub-Structures_for_Convolution_Kernels_in_Document-level_Sentiment_Classification.html">115 acl-2012-Identifying High-Impact Sub-Structures for Convolution Kernels in Document-level Sentiment Classification</a></p>
<p>12 0.44756699 <a title="28-lsi-12" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>13 0.41609895 <a title="28-lsi-13" href="./acl-2012-Structuring_E-Commerce_Inventory.html">186 acl-2012-Structuring E-Commerce Inventory</a></p>
<p>14 0.39529198 <a title="28-lsi-14" href="./acl-2012-Syntactic_Stylometry_for_Deception_Detection.html">190 acl-2012-Syntactic Stylometry for Deception Detection</a></p>
<p>15 0.3523275 <a title="28-lsi-15" href="./acl-2012-Historical_Analysis_of_Legal_Opinions_with_a_Sparse_Mixed-Effects_Latent_Variable_Model.html">110 acl-2012-Historical Analysis of Legal Opinions with a Sparse Mixed-Effects Latent Variable Model</a></p>
<p>16 0.34843212 <a title="28-lsi-16" href="./acl-2012-Genre_Independent_Subgroup_Detection_in_Online_Discussion_Threads%3A_A_Study_of_Implicit_Attitude_using_Textual_Latent_Semantics.html">102 acl-2012-Genre Independent Subgroup Detection in Online Discussion Threads: A Study of Implicit Attitude using Textual Latent Semantics</a></p>
<p>17 0.33113235 <a title="28-lsi-17" href="./acl-2012-Efficient_Tree-Based_Topic_Modeling.html">79 acl-2012-Efficient Tree-Based Topic Modeling</a></p>
<p>18 0.32544744 <a title="28-lsi-18" href="./acl-2012-Humor_as_Circuits_in_Semantic_Networks.html">112 acl-2012-Humor as Circuits in Semantic Networks</a></p>
<p>19 0.3225528 <a title="28-lsi-19" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>20 0.32138509 <a title="28-lsi-20" href="./acl-2012-Subgroup_Detection_in_Ideological_Discussions.html">187 acl-2012-Subgroup Detection in Ideological Discussions</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/acl2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.032), (8, 0.125), (19, 0.014), (22, 0.036), (31, 0.028), (38, 0.042), (47, 0.037), (58, 0.125), (61, 0.01), (77, 0.041), (82, 0.011), (83, 0.113), (88, 0.023), (91, 0.181), (92, 0.039), (96, 0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93397981 <a title="28-lda-1" href="./acl-2012-Aspect_Extraction_through_Semi-Supervised_Modeling.html">28 acl-2012-Aspect Extraction through Semi-Supervised Modeling</a></p>
<p>Author: Arjun Mukherjee ; Bing Liu</p><p>Abstract: Aspect extraction is a central problem in sentiment analysis. Current methods either extract aspects without categorizing them, or extract and categorize them using unsupervised topic modeling. By categorizing, we mean the synonymous aspects should be clustered into the same category. In this paper, we solve the problem in a different setting where the user provides some seed words for a few aspect categories and the model extracts and clusters aspect terms into categories simultaneously. This setting is important because categorizing aspects is a subjective task. For different application purposes, different categorizations may be needed. Some form of user guidance is desired. In this paper, we propose two statistical models to solve this seeded problem, which aim to discover exactly what the user wants. Our experimental results show that the two proposed models are indeed able to perform the task effectively. 1</p><p>2 0.88979191 <a title="28-lda-2" href="./acl-2012-Fine_Granular_Aspect_Analysis_using_Latent_Structural_Models.html">100 acl-2012-Fine Granular Aspect Analysis using Latent Structural Models</a></p>
<p>Author: Lei Fang ; Minlie Huang</p><p>Abstract: In this paper, we present a structural learning model forjoint sentiment classification and aspect analysis of text at various levels of granularity. Our model aims to identify highly informative sentences that are aspect-specific in online custom reviews. The primary advantages of our model are two-fold: first, it performs document-level and sentence-level sentiment polarity classification jointly; second, it is able to find informative sentences that are closely related to some respects in a review, which may be helpful for aspect-level sentiment analysis such as aspect-oriented summarization. The proposed method was evaluated with 9,000 Chinese restaurant reviews. Preliminary experiments demonstrate that our model obtains promising performance. 1</p><p>3 0.88677961 <a title="28-lda-3" href="./acl-2012-Sentence_Dependency_Tagging_in_Online_Question_Answering_Forums.html">177 acl-2012-Sentence Dependency Tagging in Online Question Answering Forums</a></p>
<p>Author: Zhonghua Qu ; Yang Liu</p><p>Abstract: Online forums are becoming a popular resource in the state of the art question answering (QA) systems. Because of its nature as an online community, it contains more updated knowledge than other places. However, going through tedious and redundant posts to look for answers could be very time consuming. Most prior work focused on extracting only question answering sentences from user conversations. In this paper, we introduce the task of sentence dependency tagging. Finding dependency structure can not only help find answer quickly but also allow users to trace back how the answer is concluded through user conversations. We use linear-chain conditional random fields (CRF) for sentence type tagging, and a 2D CRF to label the dependency relation between sentences. Our experimental results show that our proposed approach performs well for sentence dependency tagging. This dependency information can benefit other tasks such as thread ranking and answer summarization in online forums.</p><p>4 0.88305438 <a title="28-lda-4" href="./acl-2012-Grammar_Error_Correction_Using_Pseudo-Error_Sentences_and_Domain_Adaptation.html">103 acl-2012-Grammar Error Correction Using Pseudo-Error Sentences and Domain Adaptation</a></p>
<p>Author: Kenji Imamura ; Kuniko Saito ; Kugatsu Sadamitsu ; Hitoshi Nishikawa</p><p>Abstract: This paper presents grammar error correction for Japanese particles that uses discriminative sequence conversion, which corrects erroneous particles by substitution, insertion, and deletion. The error correction task is hindered by the difficulty of collecting large error corpora. We tackle this problem by using pseudoerror sentences generated automatically. Furthermore, we apply domain adaptation, the pseudo-error sentences are from the source domain, and the real-error sentences are from the target domain. Experiments show that stable improvement is achieved by using domain adaptation.</p><p>5 0.88302028 <a title="28-lda-5" href="./acl-2012-Translation_Model_Adaptation_for_Statistical_Machine_Translation_with_Monolingual_Topic_Information.html">203 acl-2012-Translation Model Adaptation for Statistical Machine Translation with Monolingual Topic Information</a></p>
<p>Author: Jinsong Su ; Hua Wu ; Haifeng Wang ; Yidong Chen ; Xiaodong Shi ; Huailin Dong ; Qun Liu</p><p>Abstract: To adapt a translation model trained from the data in one domain to another, previous works paid more attention to the studies of parallel corpus while ignoring the in-domain monolingual corpora which can be obtained more easily. In this paper, we propose a novel approach for translation model adaptation by utilizing in-domain monolingual topic information instead of the in-domain bilingual corpora, which incorporates the topic information into translation probability estimation. Our method establishes the relationship between the out-of-domain bilingual corpus and the in-domain monolingual corpora via topic mapping and phrase-topic distribution probability estimation from in-domain monolingual corpora. Experimental result on the NIST Chinese-English translation task shows that our approach significantly outperforms the baseline system.</p><p>6 0.88101095 <a title="28-lda-6" href="./acl-2012-Unsupervised_Relation_Discovery_with_Sense_Disambiguation.html">208 acl-2012-Unsupervised Relation Discovery with Sense Disambiguation</a></p>
<p>7 0.87879121 <a title="28-lda-7" href="./acl-2012-Spice_it_up%3F_Mining_Refinements_to_Online_Instructions_from_User_Generated_Content.html">182 acl-2012-Spice it up? Mining Refinements to Online Instructions from User Generated Content</a></p>
<p>8 0.87816769 <a title="28-lda-8" href="./acl-2012-Modeling_Review_Comments.html">144 acl-2012-Modeling Review Comments</a></p>
<p>9 0.87623763 <a title="28-lda-9" href="./acl-2012-Efficient_Tree-Based_Topic_Modeling.html">79 acl-2012-Efficient Tree-Based Topic Modeling</a></p>
<p>10 0.87575865 <a title="28-lda-10" href="./acl-2012-Automatically_Mining_Question_Reformulation_Patterns_from_Search_Log_Data.html">35 acl-2012-Automatically Mining Question Reformulation Patterns from Search Log Data</a></p>
<p>11 0.8698529 <a title="28-lda-11" href="./acl-2012-ACCURAT_Toolkit_for_Multi-Level_Alignment_and_Information_Extraction_from_Comparable_Corpora.html">1 acl-2012-ACCURAT Toolkit for Multi-Level Alignment and Information Extraction from Comparable Corpora</a></p>
<p>12 0.86969304 <a title="28-lda-12" href="./acl-2012-Bootstrapping_a_Unified_Model_of_Lexical_and_Phonetic_Acquisition.html">41 acl-2012-Bootstrapping a Unified Model of Lexical and Phonetic Acquisition</a></p>
<p>13 0.86907685 <a title="28-lda-13" href="./acl-2012-Pattern_Learning_for_Relation_Extraction_with_a_Hierarchical_Topic_Model.html">159 acl-2012-Pattern Learning for Relation Extraction with a Hierarchical Topic Model</a></p>
<p>14 0.86903214 <a title="28-lda-14" href="./acl-2012-Authorship_Attribution_with_Author-aware_Topic_Models.html">31 acl-2012-Authorship Attribution with Author-aware Topic Models</a></p>
<p>15 0.86843157 <a title="28-lda-15" href="./acl-2012-Semi-supervised_Dependency_Parsing_using_Lexical_Affinities.html">175 acl-2012-Semi-supervised Dependency Parsing using Lexical Affinities</a></p>
<p>16 0.86757958 <a title="28-lda-16" href="./acl-2012-Learning_to_%22Read_Between_the_Lines%22_using_Bayesian_Logic_Programs.html">133 acl-2012-Learning to "Read Between the Lines" using Bayesian Logic Programs</a></p>
<p>17 0.86740792 <a title="28-lda-17" href="./acl-2012-A_Novel_Burst-based_Text_Representation_Model_for_Scalable_Event_Detection.html">17 acl-2012-A Novel Burst-based Text Representation Model for Scalable Event Detection</a></p>
<p>18 0.86628753 <a title="28-lda-18" href="./acl-2012-Named_Entity_Disambiguation_in_Streaming_Data.html">153 acl-2012-Named Entity Disambiguation in Streaming Data</a></p>
<p>19 0.86382824 <a title="28-lda-19" href="./acl-2012-Big_Data_versus_the_Crowd%3A_Looking_for_Relationships_in_All_the_Right_Places.html">40 acl-2012-Big Data versus the Crowd: Looking for Relationships in All the Right Places</a></p>
<p>20 0.86317158 <a title="28-lda-20" href="./acl-2012-A_Ranking-based_Approach_to_Word_Reordering_for_Statistical_Machine_Translation.html">19 acl-2012-A Ranking-based Approach to Word Reordering for Statistical Machine Translation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
