<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-135" href="#">emnlp2012-135</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</h1>
<br/><p>Source: <a title="emnlp-2012-135-pdf" href="http://aclweb.org/anthology//D/D12/D12-1084.pdf">pdf</a></p><p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>Reference: <a title="emnlp-2012-135-reference" href="../emnlp2012_reference/emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('paraphras', 0.569), ('msa', 0.506), ('frag', 0.302), ('recap', 0.211), ('hous', 0.163), ('discours', 0.162), ('align', 0.144), ('vec', 0.136), ('coref', 0.104), ('paraphrasecol', 0.091), ('episod', 0.076), ('forem', 0.075), ('taub', 0.075), ('parallel', 0.074), ('barzilay', 0.066), ('vp', 0.061), ('regner', 0.06), ('resolv', 0.059), ('bleu', 0.058), ('precid', 0.053)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0 <a title="135-tfidf-1" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>2 0.51766396 <a title="135-tfidf-2" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>Author: Aurelien Max ; Houda Bouamor ; Anne Vilnat</p><p>Abstract: This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given.</p><p>3 0.46179959 <a title="135-tfidf-3" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>Author: Atsushi Fujita ; Pierre Isabelle ; Roland Kuhn</p><p>Abstract: This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances. Unlike existing methods, ours uses both bilingual parallel and monolingual corpora. While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases. We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora. In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are ofreasonable quality. Remaining noise can be further reduced by filtering seed paraphrases.</p><p>4 0.24014826 <a title="135-tfidf-4" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>5 0.14173876 <a title="135-tfidf-5" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>Author: Jong-Hoon Oh ; Kentaro Torisawa ; Chikara Hashimoto ; Takuya Kawada ; Stijn De Saeger ; Jun'ichi Kazama ; Yiou Wang</p><p>Abstract: In this paper we explore the utility of sentiment analysis and semantic word classes for improving why-question answering on a large-scale web corpus. Our work is motivated by the observation that a why-question and its answer often follow the pattern that if something undesirable happens, the reason is also often something undesirable, and if something desirable happens, the reason is also often something desirable. To the best of our knowledge, this is the first work that introduces sentiment analysis to non-factoid question answering. We combine this simple idea with semantic word classes for ranking answers to why-questions and show that on a set of 850 why-questions our method gains 15.2% improvement in precision at the top-1 answer over a baseline state-of-the-art QA system that achieved the best performance in a shared task of Japanese non-factoid QA in NTCIR-6.</p><p>6 0.12861124 <a title="135-tfidf-6" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>7 0.12847617 <a title="135-tfidf-7" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>8 0.11787061 <a title="135-tfidf-8" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>9 0.11029822 <a title="135-tfidf-9" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>10 0.10001162 <a title="135-tfidf-10" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>11 0.090959303 <a title="135-tfidf-11" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>12 0.090837836 <a title="135-tfidf-12" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>13 0.090320803 <a title="135-tfidf-13" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>14 0.082876168 <a title="135-tfidf-14" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>15 0.076606423 <a title="135-tfidf-15" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>16 0.07471288 <a title="135-tfidf-16" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>17 0.073802188 <a title="135-tfidf-17" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<p>18 0.071609311 <a title="135-tfidf-18" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>19 0.06471438 <a title="135-tfidf-19" href="./emnlp-2012-Answering_Opinion_Questions_on_Products_by_Exploiting_Hierarchical_Organization_of_Consumer_Reviews.html">20 emnlp-2012-Answering Opinion Questions on Products by Exploiting Hierarchical Organization of Consumer Reviews</a></p>
<p>20 0.063220762 <a title="135-tfidf-20" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.246), (1, 0.103), (2, -0.541), (3, 0.125), (4, 0.382), (5, -0.109), (6, 0.037), (7, 0.026), (8, -0.116), (9, -0.13), (10, 0.056), (11, -0.086), (12, 0.014), (13, -0.016), (14, 0.024), (15, 0.052), (16, 0.012), (17, 0.006), (18, 0.009), (19, -0.005), (20, -0.061), (21, -0.044), (22, 0.012), (23, 0.02), (24, -0.068), (25, 0.067), (26, -0.029), (27, -0.048), (28, -0.036), (29, -0.048), (30, 0.022), (31, -0.016), (32, 0.016), (33, -0.014), (34, -0.009), (35, 0.034), (36, -0.007), (37, -0.021), (38, -0.022), (39, 0.081), (40, -0.028), (41, -0.025), (42, 0.013), (43, -0.018), (44, -0.014), (45, 0.024), (46, -0.018), (47, 0.024), (48, -0.041), (49, 0.033)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.94583738 <a title="135-lsi-1" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>2 0.9073441 <a title="135-lsi-2" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>Author: Aurelien Max ; Houda Bouamor ; Anne Vilnat</p><p>Abstract: This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given.</p><p>3 0.89733618 <a title="135-lsi-3" href="./emnlp-2012-Enlarging_Paraphrase_Collections_through_Generalization_and_Instantiation.html">39 emnlp-2012-Enlarging Paraphrase Collections through Generalization and Instantiation</a></p>
<p>Author: Atsushi Fujita ; Pierre Isabelle ; Roland Kuhn</p><p>Abstract: This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances. Unlike existing methods, ours uses both bilingual parallel and monolingual corpora. While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases. We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora. In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are ofreasonable quality. Remaining noise can be further reduced by filtering seed paraphrases.</p><p>4 0.52608836 <a title="135-lsi-4" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>Author: Michael Roth ; Anette Frank</p><p>Abstract: Generating coherent discourse is an important aspect in natural language generation. Our aim is to learn factors that constitute coherent discourse from data, with a focus on how to realize predicate-argument structures in a model that exceeds the sentence level. We present an important subtask for this overall goal, in which we align predicates across comparable texts, admitting partial argument structure correspondence. The contribution of this work is two-fold: We first construct a large corpus resource of comparable texts, including an evaluation set with manual predicate alignments. Secondly, we present a novel approach for aligning predicates across comparable texts using graph-based clustering with Mincuts. Our method significantly outperforms other alignment techniques when applied to this novel alignment task, by a margin of at least 6.5 percentage points in F1-score.</p><p>5 0.47786352 <a title="135-lsi-5" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>Author: Pidong Wang ; Preslav Nakov ; Hwee Tou Ng</p><p>Abstract: We propose a novel, language-independent approach for improving machine translation from a resource-poor language to X by adapting a large bi-text for a related resource-rich language and X (the same target language). We assume a small bi-text for the resourcepoor language to X pair, which we use to learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language; we then adapt the former to get closer to the latter. Our experiments for Indonesian/Malay–English translation show that using the large adapted resource-rich bitext yields 6.7 BLEU points of improvement over the unadapted one and 2.6 BLEU points over the original small bi-text. Moreover, combining the small bi-text with the adapted bi-text outperforms the corresponding combinations with the unadapted bi-text by 1.5– 3 BLEU points. We also demonstrate applicability to other languages and domains.</p><p>6 0.32312784 <a title="135-lsi-6" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>7 0.2837759 <a title="135-lsi-7" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>8 0.25519419 <a title="135-lsi-8" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>9 0.2417367 <a title="135-lsi-9" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>10 0.22815469 <a title="135-lsi-10" href="./emnlp-2012-Language_Model_Rest_Costs_and_Space-Efficient_Storage.html">74 emnlp-2012-Language Model Rest Costs and Space-Efficient Storage</a></p>
<p>11 0.2274888 <a title="135-lsi-11" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>12 0.22521283 <a title="135-lsi-12" href="./emnlp-2012-PATTY%3A_A_Taxonomy_of_Relational_Patterns_with_Semantic_Types.html">103 emnlp-2012-PATTY: A Taxonomy of Relational Patterns with Semantic Types</a></p>
<p>13 0.22245112 <a title="135-lsi-13" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>14 0.21863331 <a title="135-lsi-14" href="./emnlp-2012-A_Comparison_of_Vector-based_Representations_for_Semantic_Composition.html">4 emnlp-2012-A Comparison of Vector-based Representations for Semantic Composition</a></p>
<p>15 0.2153502 <a title="135-lsi-15" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>16 0.20449406 <a title="135-lsi-16" href="./emnlp-2012-Why_Question_Answering_using_Sentiment_Analysis_and_Word_Classes.html">137 emnlp-2012-Why Question Answering using Sentiment Analysis and Word Classes</a></p>
<p>17 0.19558829 <a title="135-lsi-17" href="./emnlp-2012-Excitatory_or_Inhibitory%3A_A_New_Semantic_Orientation_Extracts_Contradiction_and_Causality_from_the_Web.html">44 emnlp-2012-Excitatory or Inhibitory: A New Semantic Orientation Extracts Contradiction and Causality from the Web</a></p>
<p>18 0.19282059 <a title="135-lsi-18" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>19 0.18589926 <a title="135-lsi-19" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>20 0.18299727 <a title="135-lsi-20" href="./emnlp-2012-Learning_Verb_Inference_Rules_from_Linguistically-Motivated_Evidence.html">80 emnlp-2012-Learning Verb Inference Rules from Linguistically-Motivated Evidence</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.025), (21, 0.038), (30, 0.065), (31, 0.041), (38, 0.045), (43, 0.013), (46, 0.012), (48, 0.033), (55, 0.043), (59, 0.104), (61, 0.077), (65, 0.292), (80, 0.02), (81, 0.012), (84, 0.011), (85, 0.053), (91, 0.014)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>1 0.86883056 <a title="135-lda-1" href="./emnlp-2012-Joint_Learning_for_Coreference_Resolution_with_Markov_Logic.html">73 emnlp-2012-Joint Learning for Coreference Resolution with Markov Logic</a></p>
<p>Author: Yang Song ; Jing Jiang ; Wayne Xin Zhao ; Sujian Li ; Houfeng Wang</p><p>Abstract: Pairwise coreference resolution models must merge pairwise coreference decisions to generate final outputs. Traditional merging methods adopt different strategies such as the bestfirst method and enforcing the transitivity constraint, but most of these methods are used independently of the pairwise learning methods as an isolated inference procedure at the end. We propose a joint learning model which combines pairwise classification and mention clustering with Markov logic. Experimental results show that our joint learning system outperforms independent learning systems. Our system gives a better performance than all the learning-based systems from the CoNLL-201 1shared task on the same dataset. Compared with the best system from CoNLL2011, which employs a rule-based method, our system shows competitive performance.</p><p>2 0.80587482 <a title="135-lda-2" href="./emnlp-2012-Linking_Named_Entities_to_Any_Database.html">84 emnlp-2012-Linking Named Entities to Any Database</a></p>
<p>Author: Avirup Sil ; Ernest Cronin ; Penghai Nie ; Yinfei Yang ; Ana-Maria Popescu ; Alexander Yates</p><p>Abstract: Existing techniques for disambiguating named entities in text mostly focus on Wikipedia as a target catalog of entities. Yet for many types of entities, such as restaurants and cult movies, relational databases exist that contain far more extensive information than Wikipedia. This paper introduces a new task, called Open-Database Named-Entity Disambiguation (Open-DB NED), in which a system must be able to resolve named entities to symbols in an arbitrary database, without requiring labeled data for each new database. We introduce two techniques for Open-DB NED, one based on distant supervision and the other based on domain adaptation. In experiments on two domains, one with poor coverage by Wikipedia and the other with near-perfect coverage, our Open-DB NED strategies outperform a state-of-the-art Wikipedia NED system by over 25% in accuracy.</p><p>same-paper 3 0.6978122 <a title="135-lda-3" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>Author: Michaela Regneri ; Rui Wang</p><p>Abstract: Previous work on paraphrase extraction using parallel or comparable corpora has generally not considered the documents’ discourse structure as a useful information source. We propose a novel method for collecting paraphrases relying on the sequential event order in the discourse, using multiple sequence alignment with a semantic similarity measure. We show that adding discourse information boosts the performance of sentence-level paraphrase acquisition, which consequently gives a tremendous advantage for extracting phraselevel paraphrase fragments from matched sentences. Our system beats an informed baseline by a margin of 50%.</p><p>4 0.61738282 <a title="135-lda-4" href="./emnlp-2012-Joint_Inference_for_Event_Timeline_Construction.html">72 emnlp-2012-Joint Inference for Event Timeline Construction</a></p>
<p>Author: Quang Do ; Wei Lu ; Dan Roth</p><p>Abstract: This paper addresses the task of constructing a timeline of events mentioned in a given text. To accomplish that, we present a novel representation of the temporal structure of a news article based on time intervals. We then present an algorithmic approach that jointly optimizes the temporal structure by coupling local classifiers that predict associations and temporal relations between pairs of temporal entities with global constraints. Moreover, we present ways to leverage knowledge provided by event coreference to further improve the system performance. Overall, our experiments show that the joint inference model significantly outperformed the local classifiers by 9.2% of relative improvement in F1. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system.</p><p>5 0.6090126 <a title="135-lda-5" href="./emnlp-2012-Joint_Entity_and_Event_Coreference_Resolution_across_Documents.html">71 emnlp-2012-Joint Entity and Event Coreference Resolution across Documents</a></p>
<p>Author: Heeyoung Lee ; Marta Recasens ; Angel Chang ; Mihai Surdeanu ; Dan Jurafsky</p><p>Abstract: We introduce a novel coreference resolution system that models entities and events jointly. Our iterative method cautiously constructs clusters of entity and event mentions using linear regression to model cluster merge operations. As clusters are built, information flows between entity and event clusters through features that model semantic role dependencies. Our system handles nominal and verbal events as well as entities, and our joint formulation allows information from event coreference to help entity coreference, and vice versa. In a cross-document domain with comparable documents, joint coreference resolution performs significantly better (over 3 CoNLL F1 points) than two strong baselines that resolve entities and events separately.</p><p>6 0.60372341 <a title="135-lda-6" href="./emnlp-2012-Learning-based_Multi-Sieve_Co-reference_Resolution_with_Knowledge.html">76 emnlp-2012-Learning-based Multi-Sieve Co-reference Resolution with Knowledge</a></p>
<p>7 0.57947791 <a title="135-lda-7" href="./emnlp-2012-Multi-instance_Multi-label_Learning_for_Relation_Extraction.html">93 emnlp-2012-Multi-instance Multi-label Learning for Relation Extraction</a></p>
<p>8 0.54930675 <a title="135-lda-8" href="./emnlp-2012-Monte_Carlo_MCMC%3A_Efficient_Inference_by_Approximate_Sampling.html">91 emnlp-2012-Monte Carlo MCMC: Efficient Inference by Approximate Sampling</a></p>
<p>9 0.53925478 <a title="135-lda-9" href="./emnlp-2012-Domain_Adaptation_for_Coreference_Resolution%3A_An_Adaptive_Ensemble_Approach.html">36 emnlp-2012-Domain Adaptation for Coreference Resolution: An Adaptive Ensemble Approach</a></p>
<p>10 0.52335501 <a title="135-lda-10" href="./emnlp-2012-An_Entity-Topic_Model_for_Entity_Linking.html">19 emnlp-2012-An Entity-Topic Model for Entity Linking</a></p>
<p>11 0.50849837 <a title="135-lda-11" href="./emnlp-2012-Learning_Constraints_for_Consistent_Timeline_Extraction.html">77 emnlp-2012-Learning Constraints for Consistent Timeline Extraction</a></p>
<p>12 0.50576627 <a title="135-lda-12" href="./emnlp-2012-Entity_based_QA_Retrieval.html">41 emnlp-2012-Entity based QA Retrieval</a></p>
<p>13 0.50539887 <a title="135-lda-13" href="./emnlp-2012-Reading_The_Web_with_Learned_Syntactic-Semantic_Inference_Rules.html">110 emnlp-2012-Reading The Web with Learned Syntactic-Semantic Inference Rules</a></p>
<p>14 0.50538993 <a title="135-lda-14" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>15 0.50295287 <a title="135-lda-15" href="./emnlp-2012-Generalizing_Sub-sentential_Paraphrase_Acquisition_across_Original_Signal_Type_of_Text_Pairs.html">58 emnlp-2012-Generalizing Sub-sentential Paraphrase Acquisition across Original Signal Type of Text Pairs</a></p>
<p>16 0.49899894 <a title="135-lda-16" href="./emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">13 emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<p>17 0.49807349 <a title="135-lda-17" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<p>18 0.49743566 <a title="135-lda-18" href="./emnlp-2012-Employing_Compositional_Semantics_and_Discourse_Consistency_in_Chinese_Event_Extraction.html">38 emnlp-2012-Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction</a></p>
<p>19 0.49565735 <a title="135-lda-19" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>20 0.49451438 <a title="135-lda-20" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
