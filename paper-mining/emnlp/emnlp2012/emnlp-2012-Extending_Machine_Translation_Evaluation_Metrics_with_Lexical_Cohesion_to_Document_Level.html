<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</title>
</head>

<body>
<p><a title="emnlp" href="../emnlp_home.html">emnlp</a> <a title="emnlp-2012" href="../home/emnlp2012_home.html">emnlp2012</a> <a title="emnlp-2012-50" href="#">emnlp2012-50</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</h1>
<br/><p>Source: <a title="emnlp-2012-50-pdf" href="http://aclweb.org/anthology//D/D12/D12-1097.pdf">pdf</a></p><p>Author: Billy T. M. Wong ; Chunyu Kit</p><p>Abstract: This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level. As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning. A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine. Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation. Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</p><p>Reference: <a title="emnlp-2012-50-reference" href="../emnlp2012_reference/emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('coher', 0.755), ('mt', 0.414), ('dev', 0.166), ('rc', 0.124), ('metricsm', 0.107), ('lex', 0.104), ('nakaiw', 0.103), ('ht', 0.101), ('met', 0.087), ('transl', 0.086), ('bleu', 0.078), ('adequ', 0.077), ('ratio', 0.073), ('docu', 0.066), ('correl', 0.063), ('assess', 0.06), ('discours', 0.056), ('japanes', 0.056), ('snov', 0.055), ('reit', 0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.99999911 <a title="50-tfidf-1" href="./emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>Author: Billy T. M. Wong ; Chunyu Kit</p><p>Abstract: This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level. As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning. A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine. Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation. Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</p><p>2 0.11140301 <a title="50-tfidf-2" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>Author: Mengqiu Wang ; Christopher D. Manning</p><p>Abstract: Accurate and robust metrics for automatic evaluation are key to the development of statistical machine translation (MT) systems. We first introduce a new regression model that uses a probabilistic finite state machine (pFSM) to compute weighted edit distance as predictions of translation quality. We also propose a novel pushdown automaton extension of the pFSM model for modeling word swapping and cross alignments that cannot be captured by standard edit distance models. Our models can easily incorporate a rich set of linguistic features, and automatically learn their weights, eliminating the need for ad-hoc parameter tuning. Our methods achieve state-of-the-art correlation with human judgments on two different prediction tasks across a diverse set of standard evaluations (NIST OpenMT06,08; WMT0608).</p><p>3 0.087174214 <a title="50-tfidf-3" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>Author: David Burkett ; Dan Klein</p><p>Abstract: We describe a transformation-based learning method for learning a sequence of monolingual tree transformations that improve the agreement between constituent trees and word alignments in bilingual corpora. Using the manually annotated English Chinese Translation Treebank, we show how our method automatically discovers transformations that accommodate differences in English and Chinese syntax. Furthermore, when transformations are learned on automatically generated trees and alignments from the same domain as the training data for a syntactic MT system, the transformed trees achieve a 0.9 BLEU improvement over baseline trees.</p><p>4 0.086865336 <a title="50-tfidf-4" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>Author: Lemao Liu ; Hailong Cao ; Taro Watanabe ; Tiejun Zhao ; Mo Yu ; Conghui Zhu</p><p>Abstract: In statistical machine translation, minimum error rate training (MERT) is a standard method for tuning a single weight with regard to a given development data. However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method. First, its performance is highly dependent on the choice of a development set, which may lead to an unstable performance for testing. Second, translations become inconsistent at the sentence level since tuning is performed globally on a document level. In this paper, we propose a novel local training method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We pro- pose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method.</p><p>5 0.077500112 <a title="50-tfidf-5" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>Author: Liwei Chen ; Yansong Feng ; Lei Zou ; Dongyan Zhao</p><p>Abstract: In this paper, we investigate different usages of feature representations in the web person name disambiguation task which has been suffering from the mismatch of vocabulary and lack of clues in web environments. In literature, the latter receives less attention and remains more challenging. We explore the feature space in this task and argue that collecting person specific evidences from a corpus level can provide a more reasonable and robust estimation for evaluating a feature’s importance in a given web page. This can alleviate the lack of clues where discriminative features can be reasonably weighted by taking their corpus level importance into account, not just relying on the current local context. We therefore propose a topic-based model to exploit the person specific global importance and embed it into the person name similarity. The experimental results show that the corpus level topic in- formation provides more stable evidences for discriminative features and our method outperforms the state-of-the-art systems on three WePS datasets.</p><p>6 0.065881923 <a title="50-tfidf-6" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>7 0.063278079 <a title="50-tfidf-7" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>8 0.062836431 <a title="50-tfidf-8" href="./emnlp-2012-Bilingual_Lexicon_Extraction_from_Comparable_Corpora_Using_Label_Propagation.html">25 emnlp-2012-Bilingual Lexicon Extraction from Comparable Corpora Using Label Propagation</a></p>
<p>9 0.059554853 <a title="50-tfidf-9" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>10 0.051791936 <a title="50-tfidf-10" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>11 0.049717616 <a title="50-tfidf-11" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>12 0.047560483 <a title="50-tfidf-12" href="./emnlp-2012-Using_Discourse_Information_for_Paraphrase_Extraction.html">135 emnlp-2012-Using Discourse Information for Paraphrase Extraction</a></p>
<p>13 0.047456812 <a title="50-tfidf-13" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>14 0.046612568 <a title="50-tfidf-14" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>15 0.045604561 <a title="50-tfidf-15" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>16 0.045300458 <a title="50-tfidf-16" href="./emnlp-2012-Entropy-based_Pruning_for_Phrase-based_Machine_Translation.html">42 emnlp-2012-Entropy-based Pruning for Phrase-based Machine Translation</a></p>
<p>17 0.04319666 <a title="50-tfidf-17" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>18 0.042828016 <a title="50-tfidf-18" href="./emnlp-2012-Resolving_Complex_Cases_of_Definite_Pronouns%3A_The_Winograd_Schema_Challenge.html">112 emnlp-2012-Resolving Complex Cases of Definite Pronouns: The Winograd Schema Challenge</a></p>
<p>19 0.042103697 <a title="50-tfidf-19" href="./emnlp-2012-Multiple_Aspect_Summarization_Using_Integer_Linear_Programming.html">94 emnlp-2012-Multiple Aspect Summarization Using Integer Linear Programming</a></p>
<p>20 0.041586298 <a title="50-tfidf-20" href="./emnlp-2012-Inducing_a_Discriminative_Parser_to_Optimize_Machine_Translation_Reordering.html">67 emnlp-2012-Inducing a Discriminative Parser to Optimize Machine Translation Reordering</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/emnlp2012_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.15), (1, -0.006), (2, -0.095), (3, -0.002), (4, -0.052), (5, -0.006), (6, -0.026), (7, 0.05), (8, 0.014), (9, 0.018), (10, -0.055), (11, 0.057), (12, 0.032), (13, -0.058), (14, 0.006), (15, 0.029), (16, 0.002), (17, -0.106), (18, -0.038), (19, -0.055), (20, 0.114), (21, 0.073), (22, -0.071), (23, 0.037), (24, 0.019), (25, 0.009), (26, 0.108), (27, 0.122), (28, 0.075), (29, 0.079), (30, -0.103), (31, -0.054), (32, -0.217), (33, 0.22), (34, 0.208), (35, 0.15), (36, 0.222), (37, 0.134), (38, 0.034), (39, 0.21), (40, 0.106), (41, -0.041), (42, 0.044), (43, 0.131), (44, -0.167), (45, -0.088), (46, 0.148), (47, 0.01), (48, -0.041), (49, -0.054)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.95278966 <a title="50-lsi-1" href="./emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>Author: Billy T. M. Wong ; Chunyu Kit</p><p>Abstract: This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level. As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning. A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine. Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation. Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</p><p>2 0.71214718 <a title="50-lsi-2" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>Author: Mengqiu Wang ; Christopher D. Manning</p><p>Abstract: Accurate and robust metrics for automatic evaluation are key to the development of statistical machine translation (MT) systems. We first introduce a new regression model that uses a probabilistic finite state machine (pFSM) to compute weighted edit distance as predictions of translation quality. We also propose a novel pushdown automaton extension of the pFSM model for modeling word swapping and cross alignments that cannot be captured by standard edit distance models. Our models can easily incorporate a rich set of linguistic features, and automatically learn their weights, eliminating the need for ad-hoc parameter tuning. Our methods achieve state-of-the-art correlation with human judgments on two different prediction tasks across a diverse set of standard evaluations (NIST OpenMT06,08; WMT0608).</p><p>3 0.46427363 <a title="50-lsi-3" href="./emnlp-2012-An_%22AI_readability%22_Formula_for_French_as_a_Foreign_Language.html">17 emnlp-2012-An "AI readability" Formula for French as a Foreign Language</a></p>
<p>Author: Thomas Francois ; Cedrick Fairon</p><p>Abstract: This paper present a new readability formula for French as a foreign language (FFL), which relies on 46 textual features representative of the lexical, syntactic, and semantic levels as well as some of the specificities of the FFL context. We report comparisons between several techniques for feature selection and various learning algorithms. Our best model, based on support vector machines (SVM), significantly outperforms previous FFL formulas. We also found that semantic features behave poorly in our case, in contrast with some previous readability studies on English as a first language.</p><p>4 0.42634869 <a title="50-lsi-4" href="./emnlp-2012-Locally_Training_the_Log-Linear_Model_for_SMT.html">86 emnlp-2012-Locally Training the Log-Linear Model for SMT</a></p>
<p>Author: Lemao Liu ; Hailong Cao ; Taro Watanabe ; Tiejun Zhao ; Mo Yu ; Conghui Zhu</p><p>Abstract: In statistical machine translation, minimum error rate training (MERT) is a standard method for tuning a single weight with regard to a given development data. However, due to the diversity and uneven distribution of source sentences, there are two problems suffered by this method. First, its performance is highly dependent on the choice of a development set, which may lead to an unstable performance for testing. Second, translations become inconsistent at the sentence level since tuning is performed globally on a document level. In this paper, we propose a novel local training method to address these two problems. Unlike a global training method, such as MERT, in which a single weight is learned and used for all the input sentences, we perform training and testing in one step by learning a sentencewise weight for each input sentence. We pro- pose efficient incremental training methods to put the local training into practice. In NIST Chinese-to-English translation tasks, our local training method significantly outperforms MERT with the maximal improvements up to 2.0 BLEU points, meanwhile its efficiency is comparable to that of the global method.</p><p>5 0.35042372 <a title="50-lsi-5" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>Author: Taylor Berg-Kirkpatrick ; David Burkett ; Dan Klein</p><p>Abstract: We investigate two aspects of the empirical behavior of paired significance tests for NLP systems. First, when one system appears to outperform another, how does significance level relate in practice to the magnitude of the gain, to the size of the test set, to the similarity of the systems, and so on? Is it true that for each task there is a gain which roughly implies significance? We explore these issues across a range of NLP tasks using both large collections of past systems’ outputs and variants of single systems. Next, once significance levels are computed, how well does the standard i.i.d. notion of significance hold up in practical settings where future distributions are neither independent nor identically distributed, such as across domains? We explore this question using a range of test set variations for constituency parsing.</p><p>6 0.32062653 <a title="50-lsi-6" href="./emnlp-2012-Bilingual_Lexicon_Extraction_from_Comparable_Corpora_Using_Label_Propagation.html">25 emnlp-2012-Bilingual Lexicon Extraction from Comparable Corpora Using Label Propagation</a></p>
<p>7 0.30890137 <a title="50-lsi-7" href="./emnlp-2012-Minimal_Dependency_Length_in_Realization_Ranking.html">88 emnlp-2012-Minimal Dependency Length in Realization Ranking</a></p>
<p>8 0.27698702 <a title="50-lsi-8" href="./emnlp-2012-Polarity_Inducing_Latent_Semantic_Analysis.html">107 emnlp-2012-Polarity Inducing Latent Semantic Analysis</a></p>
<p>9 0.24879064 <a title="50-lsi-9" href="./emnlp-2012-Explore_Person_Specific_Evidence_in_Web_Person_Name_Disambiguation.html">47 emnlp-2012-Explore Person Specific Evidence in Web Person Name Disambiguation</a></p>
<p>10 0.22770591 <a title="50-lsi-10" href="./emnlp-2012-Exploring_Topic_Coherence_over_Many_Models_and_Many_Topics.html">49 emnlp-2012-Exploring Topic Coherence over Many Models and Many Topics</a></p>
<p>11 0.22186841 <a title="50-lsi-11" href="./emnlp-2012-Forced_Derivation_Tree_based_Model_Training_to_Statistical_Machine_Translation.html">54 emnlp-2012-Forced Derivation Tree based Model Training to Statistical Machine Translation</a></p>
<p>12 0.20720494 <a title="50-lsi-12" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>13 0.2058399 <a title="50-lsi-13" href="./emnlp-2012-Constructing_Task-Specific_Taxonomies_for_Document_Collection_Browsing.html">30 emnlp-2012-Constructing Task-Specific Taxonomies for Document Collection Browsing</a></p>
<p>14 0.20399456 <a title="50-lsi-14" href="./emnlp-2012-Joining_Forces_Pays_Off%3A_Multilingual_Joint_Word_Sense_Disambiguation.html">69 emnlp-2012-Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation</a></p>
<p>15 0.20396309 <a title="50-lsi-15" href="./emnlp-2012-A_Novel_Discriminative_Framework_for_Sentence-Level_Discourse_Analysis.html">7 emnlp-2012-A Novel Discriminative Framework for Sentence-Level Discourse Analysis</a></p>
<p>16 0.20243886 <a title="50-lsi-16" href="./emnlp-2012-Automatically_Constructing_a_Normalisation_Dictionary_for_Microblogs.html">22 emnlp-2012-Automatically Constructing a Normalisation Dictionary for Microblogs</a></p>
<p>17 0.19436598 <a title="50-lsi-17" href="./emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">95 emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>18 0.19176486 <a title="50-lsi-18" href="./emnlp-2012-A_Coherence_Model_Based_on_Syntactic_Patterns.html">3 emnlp-2012-A Coherence Model Based on Syntactic Patterns</a></p>
<p>19 0.18733346 <a title="50-lsi-19" href="./emnlp-2012-Document-Wide_Decoding_for_Phrase-Based_Statistical_Machine_Translation.html">35 emnlp-2012-Document-Wide Decoding for Phrase-Based Statistical Machine Translation</a></p>
<p>20 0.18364953 <a title="50-lsi-20" href="./emnlp-2012-A_Statistical_Relational_Learning_Approach_to_Identifying_Evidence_Based_Medicine_Categories.html">10 emnlp-2012-A Statistical Relational Learning Approach to Identifying Evidence Based Medicine Categories</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/emnlp2012_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(9, 0.029), (21, 0.036), (30, 0.041), (31, 0.05), (38, 0.099), (48, 0.043), (55, 0.051), (59, 0.046), (61, 0.058), (72, 0.288), (80, 0.032), (82, 0.015), (85, 0.052), (91, 0.029), (97, 0.011)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.71028417 <a title="50-lda-1" href="./emnlp-2012-Extending_Machine_Translation_Evaluation_Metrics_with_Lexical_Cohesion_to_Document_Level.html">50 emnlp-2012-Extending Machine Translation Evaluation Metrics with Lexical Cohesion to Document Level</a></p>
<p>Author: Billy T. M. Wong ; Chunyu Kit</p><p>Abstract: This paper proposes the utilization of lexical cohesion to facilitate evaluation of machine translation at the document level. As a linguistic means to achieve text coherence, lexical cohesion ties sentences together into a meaningfully interwoven structure through words with the same or related meaning. A comparison between machine and human translation is conducted to illustrate one of their critical distinctions that human translators tend to use more cohesion devices than machine. Various ways to apply this feature to evaluate machinetranslated documents are presented, including one without reliance on reference translation. Experimental results show that incorporating this feature into sentence-level evaluation metrics can enhance their correlation with human judgements.</p><p>2 0.61642808 <a title="50-lda-2" href="./emnlp-2012-Framework_of_Automatic_Text_Summarization_Using_Reinforcement_Learning.html">56 emnlp-2012-Framework of Automatic Text Summarization Using Reinforcement Learning</a></p>
<p>Author: Seonggi Ryang ; Takeshi Abekawa</p><p>Abstract: We present a new approach to the problem of automatic text summarization called Automatic Summarization using Reinforcement Learning (ASRL) in this paper, which models the process of constructing a summary within the framework of reinforcement learning and attempts to optimize the given score function with the given feature representation of a summary. We demonstrate that the method of reinforcement learning can be adapted to automatic summarization problems naturally and simply, and other summarizing techniques, such as sentence compression, can be easily adapted as actions of the framework. The experimental results indicated ASRL was superior to the best performing method in DUC2004 and comparable to the state of the art ILP-style method, in terms of ROUGE scores. The results also revealed ASRL can search for sub-optimal solutions efficiently under conditions for effectively selecting features and the score function.</p><p>3 0.48573995 <a title="50-lda-3" href="./emnlp-2012-Wiki-ly_Supervised_Part-of-Speech_Tagging.html">138 emnlp-2012-Wiki-ly Supervised Part-of-Speech Tagging</a></p>
<p>Author: Shen Li ; Joao Graca ; Ben Taskar</p><p>Abstract: Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks. Use of parallel text between resource-rich and resource-poor languages is one source ofweak supervision that significantly improves accuracy. However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps. In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary. Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our . approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank.</p><p>4 0.47104713 <a title="50-lda-4" href="./emnlp-2012-Re-training_Monolingual_Parser_Bilingually_for_Syntactic_SMT.html">109 emnlp-2012-Re-training Monolingual Parser Bilingually for Syntactic SMT</a></p>
<p>Author: Shujie Liu ; Chi-Ho Li ; Mu Li ; Ming Zhou</p><p>Abstract: The training of most syntactic SMT approaches involves two essential components, word alignment and monolingual parser. In the current state of the art these two components are mutually independent, thus causing problems like lack of rule generalization, and violation of syntactic correspondence in translation rules. In this paper, we propose two ways of re-training monolingual parser with the target of maximizing the consistency between parse trees and alignment matrices. One is targeted self-training with a simple evaluation function; the other is based on training data selection from forced alignment of bilingual data. We also propose an auxiliary method for boosting alignment quality, by symmetrizing alignment matrices with respect to parse trees. The best combination of these novel methods achieves 3 Bleu point gain in an IWSLT task and more than 1 Bleu point gain in NIST tasks. 1</p><p>5 0.46586645 <a title="50-lda-5" href="./emnlp-2012-Bilingual_Lexicon_Extraction_from_Comparable_Corpora_Using_Label_Propagation.html">25 emnlp-2012-Bilingual Lexicon Extraction from Comparable Corpora Using Label Propagation</a></p>
<p>Author: Akihiro Tamura ; Taro Watanabe ; Eiichiro Sumita</p><p>Abstract: This paper proposes a novel method for lexicon extraction that extracts translation pairs from comparable corpora by using graphbased label propagation. In previous work, it was established that performance drastically decreases when the coverage of a seed lexicon is small. We resolve this problem by utilizing indirect relations with the bilingual seeds together with direct relations, in which each word is represented by a distribution of translated seeds. The seed distributions are propagated over a graph representing relations among words, and translation pairs are extracted by identifying word pairs with a high similarity in the seed distributions. We propose two types of the graphs: a co-occurrence graph, representing co-occurrence relations between words, and a similarity graph, representing context similarities between words. Evaluations using English and Japanese patent comparable corpora show that our proposed graph propagation method outperforms conventional methods. Further, the similarity graph achieved improved performance by clustering synonyms into the same translation.</p><p>6 0.46547928 <a title="50-lda-6" href="./emnlp-2012-Probabilistic_Finite_State_Machines_for_Regression-based_MT_Evaluation.html">108 emnlp-2012-Probabilistic Finite State Machines for Regression-based MT Evaluation</a></p>
<p>7 0.46444902 <a title="50-lda-7" href="./emnlp-2012-Transforming_Trees_to_Improve_Syntactic_Convergence.html">127 emnlp-2012-Transforming Trees to Improve Syntactic Convergence</a></p>
<p>8 0.46328977 <a title="50-lda-8" href="./emnlp-2012-Aligning_Predicates_across_Monolingual_Comparable_Texts_using_Graph-based_Clustering.html">16 emnlp-2012-Aligning Predicates across Monolingual Comparable Texts using Graph-based Clustering</a></p>
<p>9 0.46313176 <a title="50-lda-9" href="./emnlp-2012-An_Empirical_Investigation_of_Statistical_Significance_in_NLP.html">18 emnlp-2012-An Empirical Investigation of Statistical Significance in NLP</a></p>
<p>10 0.45867011 <a title="50-lda-10" href="./emnlp-2012-Multi-Domain_Learning%3A_When_Do_Domains_Matter%3F.html">92 emnlp-2012-Multi-Domain Learning: When Do Domains Matter?</a></p>
<p>11 0.45779738 <a title="50-lda-11" href="./emnlp-2012-A_Unified_Approach_to_Transliteration-based_Text_Input_with_Online_Spelling_Correction.html">13 emnlp-2012-A Unified Approach to Transliteration-based Text Input with Online Spelling Correction</a></p>
<p>12 0.45666739 <a title="50-lda-12" href="./emnlp-2012-Inducing_a_Discriminative_Parser_to_Optimize_Machine_Translation_Reordering.html">67 emnlp-2012-Inducing a Discriminative Parser to Optimize Machine Translation Reordering</a></p>
<p>13 0.45566893 <a title="50-lda-13" href="./emnlp-2012-N-gram-based_Tense_Models_for_Statistical_Machine_Translation.html">95 emnlp-2012-N-gram-based Tense Models for Statistical Machine Translation</a></p>
<p>14 0.45370197 <a title="50-lda-14" href="./emnlp-2012-Source_Language_Adaptation_for_Resource-Poor_Machine_Translation.html">118 emnlp-2012-Source Language Adaptation for Resource-Poor Machine Translation</a></p>
<p>15 0.45215786 <a title="50-lda-15" href="./emnlp-2012-Translation_Model_Based_Cross-Lingual_Language_Model_Adaptation%3A_from_Word_Models_to_Phrase_Models.html">128 emnlp-2012-Translation Model Based Cross-Lingual Language Model Adaptation: from Word Models to Phrase Models</a></p>
<p>16 0.44907793 <a title="50-lda-16" href="./emnlp-2012-Detecting_Subgroups_in_Online_Discussions_by_Modeling_Positive_and_Negative_Relations_among_Participants.html">32 emnlp-2012-Detecting Subgroups in Online Discussions by Modeling Positive and Negative Relations among Participants</a></p>
<p>17 0.44844979 <a title="50-lda-17" href="./emnlp-2012-A_Systematic_Comparison_of_Phrase_Table_Pruning_Techniques.html">11 emnlp-2012-A Systematic Comparison of Phrase Table Pruning Techniques</a></p>
<p>18 0.44751844 <a title="50-lda-18" href="./emnlp-2012-Learning_Lexicon_Models_from_Search_Logs_for_Query_Expansion.html">78 emnlp-2012-Learning Lexicon Models from Search Logs for Query Expansion</a></p>
<p>19 0.44737068 <a title="50-lda-19" href="./emnlp-2012-Iterative_Annotation_Transformation_with_Predict-Self_Reestimation_for_Chinese_Word_Segmentation.html">68 emnlp-2012-Iterative Annotation Transformation with Predict-Self Reestimation for Chinese Word Segmentation</a></p>
<p>20 0.44323224 <a title="50-lda-20" href="./emnlp-2012-A_Discriminative_Model_for_Query_Spelling_Correction_with_Latent_Structural_SVM.html">5 emnlp-2012-A Discriminative Model for Query Spelling Correction with Latent Structural SVM</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
