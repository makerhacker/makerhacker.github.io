<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</title>
</head>

<body>
<p><a title="nips" href="../nips_home.html">nips</a> <a title="nips-2013" href="../home/nips2013_home.html">nips2013</a> <a title="nips-2013-307" href="#">nips2013-307</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</h1>
<br/><p>Source: <a title="nips-2013-307-pdf" href="http://papers.nips.cc/paper/4999-speedup-matrix-completion-with-side-information-application-to-multi-label-learning.pdf">pdf</a></p><p>Author: Miao Xu, Rong Jin, Zhi-Hua Zhou</p><p>Abstract: In standard matrix completion theory, it is required to have at least O(n ln2 n) observed entries to perfectly recover a low-rank matrix M of size n × n, leading to a large number of observations when n is large. In many real tasks, side information in addition to the observed entries is often available. In this work, we develop a novel theory of matrix completion that explicitly explore the side information to reduce the requirement on the number of observed entries. We show that, under appropriate conditions, with the assistance of side information matrices, the number of observed entries needed for a perfect recovery of matrix M can be dramatically reduced to O(ln n). We demonstrate the effectiveness of the proposed approach for matrix completion in transductive incomplete multi-label learning. 1</p><p>Reference: <a title="nips-2013-307-reference" href="../nips2013_reference/nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning_reference.html">text</a></p><br/>
<h2>similar papers computed by tfidf model</h2><h3>tfidf for this paper:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('maxid', 0.576), ('rb', 0.416), ('ra', 0.331), ('transduc', 0.251), ('alm', 0.205), ('sid', 0.174), ('matrix', 0.172), ('incomplet', 0.138), ('entry', 0.114), ('fpca', 0.109), ('label', 0.108), ('svt', 0.106), ('complet', 0.089), ('flickr', 0.088), ('perfect', 0.085), ('recovery', 0.074), ('rra', 0.065), ('rn', 0.064), ('ln', 0.063), ('singul', 0.062)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 1.0000005 <a title="307-tfidf-1" href="./nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning.html">307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</a></p>
<p>2 0.12526788 <a title="307-tfidf-2" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>3 0.11963562 <a title="307-tfidf-3" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>4 0.10578556 <a title="307-tfidf-4" href="./nips-2013-Convex_Two-Layer_Modeling.html">75 nips-2013-Convex Two-Layer Modeling</a></p>
<p>5 0.098132528 <a title="307-tfidf-5" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>6 0.090229221 <a title="307-tfidf-6" href="./nips-2013-Exact_and_Stable_Recovery_of_Pairwise_Interaction_Tensors.html">113 nips-2013-Exact and Stable Recovery of Pairwise Interaction Tensors</a></p>
<p>7 0.086612388 <a title="307-tfidf-7" href="./nips-2013-Synthesizing_Robust_Plans_under_Incomplete_Domain_Models.html">323 nips-2013-Synthesizing Robust Plans under Incomplete Domain Models</a></p>
<p>8 0.081373692 <a title="307-tfidf-8" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>9 0.074704483 <a title="307-tfidf-9" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>10 0.074209638 <a title="307-tfidf-10" href="./nips-2013-Robust_Transfer_Principal_Component_Analysis_with_Rank_Constraints.html">285 nips-2013-Robust Transfer Principal Component Analysis with Rank Constraints</a></p>
<p>11 0.07299111 <a title="307-tfidf-11" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>12 0.071793459 <a title="307-tfidf-12" href="./nips-2013-Latent_Structured_Active_Learning.html">149 nips-2013-Latent Structured Active Learning</a></p>
<p>13 0.070731208 <a title="307-tfidf-13" href="./nips-2013-Moment-based_Uniform_Deviation_Bounds_for_%24k%24-means_and_Friends.html">197 nips-2013-Moment-based Uniform Deviation Bounds for $k$-means and Friends</a></p>
<p>14 0.068054587 <a title="307-tfidf-14" href="./nips-2013-Unsupervised_Spectral_Learning_of_Finite_State_Transducers.html">342 nips-2013-Unsupervised Spectral Learning of Finite State Transducers</a></p>
<p>15 0.065987252 <a title="307-tfidf-15" href="./nips-2013-Speeding_up_Permutation_Testing_in_Neuroimaging.html">306 nips-2013-Speeding up Permutation Testing in Neuroimaging</a></p>
<p>16 0.06536153 <a title="307-tfidf-16" href="./nips-2013-Probabilistic_Low-Rank_Matrix_Completion_with_Adaptive_Spectral_Regularization_Algorithms.html">254 nips-2013-Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms</a></p>
<p>17 0.061954383 <a title="307-tfidf-17" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>18 0.061624225 <a title="307-tfidf-18" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>19 0.061183333 <a title="307-tfidf-19" href="./nips-2013-Robust_learning_of_low-dimensional_dynamics_from_large_neural_ensembles.html">286 nips-2013-Robust learning of low-dimensional dynamics from large neural ensembles</a></p>
<p>20 0.058133449 <a title="307-tfidf-20" href="./nips-2013-Robust_Bloom_Filters_for_Large_MultiLabel_Classification_Tasks.html">279 nips-2013-Robust Bloom Filters for Large MultiLabel Classification Tasks</a></p>
<br/>
<h2>similar papers computed by <a title="lsi-model" href="../home/nips2013_lsi.html">lsi model</a></h2><h3>lsi for this paper:</h3><p>topicId topicWeight</p>
<p>[(0, 0.156), (1, 0.066), (2, 0.07), (3, -0.039), (4, 0.038), (5, 0.03), (6, -0.021), (7, 0.002), (8, -0.033), (9, 0.083), (10, -0.023), (11, 0.0), (12, 0.051), (13, -0.018), (14, -0.036), (15, -0.029), (16, -0.019), (17, -0.026), (18, 0.065), (19, 0.048), (20, -0.018), (21, 0.008), (22, 0.1), (23, 0.089), (24, -0.061), (25, -0.031), (26, -0.006), (27, 0.082), (28, -0.061), (29, -0.055), (30, 0.052), (31, 0.004), (32, -0.04), (33, -0.007), (34, 0.035), (35, -0.03), (36, -0.034), (37, -0.026), (38, 0.012), (39, 0.067), (40, 0.092), (41, 0.011), (42, -0.07), (43, -0.015), (44, -0.014), (45, 0.032), (46, -0.065), (47, -0.014), (48, -0.08), (49, -0.037)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.93567204 <a title="307-lsi-1" href="./nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning.html">307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</a></p>
<p>2 0.79556179 <a title="307-lsi-2" href="./nips-2013-Matrix_Completion_From_any_Given_Set_of_Observations.html">185 nips-2013-Matrix Completion From any Given Set of Observations</a></p>
<p>3 0.79517913 <a title="307-lsi-3" href="./nips-2013-Probabilistic_Low-Rank_Matrix_Completion_with_Adaptive_Spectral_Regularization_Algorithms.html">254 nips-2013-Probabilistic Low-Rank Matrix Completion with Adaptive Spectral Regularization Algorithms</a></p>
<p>4 0.76006132 <a title="307-lsi-4" href="./nips-2013-Unsupervised_Spectral_Learning_of_Finite_State_Transducers.html">342 nips-2013-Unsupervised Spectral Learning of Finite State Transducers</a></p>
<p>5 0.73380899 <a title="307-lsi-5" href="./nips-2013-Near-Optimal_Entrywise_Sampling_for_Data_Matrices.html">206 nips-2013-Near-Optimal Entrywise Sampling for Data Matrices</a></p>
<p>6 0.69100487 <a title="307-lsi-6" href="./nips-2013-Error-Minimizing_Estimates_and_Universal_Entry-Wise_Error_Bounds_for_Low-Rank_Matrix_Completion.html">108 nips-2013-Error-Minimizing Estimates and Universal Entry-Wise Error Bounds for Low-Rank Matrix Completion</a></p>
<p>7 0.68953198 <a title="307-lsi-7" href="./nips-2013-Low-Rank_Matrix_and_Tensor_Completion_via_Adaptive_Sampling.html">179 nips-2013-Low-Rank Matrix and Tensor Completion via Adaptive Sampling</a></p>
<p>8 0.67508596 <a title="307-lsi-8" href="./nips-2013-Matrix_factorization_with_binary_components.html">186 nips-2013-Matrix factorization with binary components</a></p>
<p>9 0.61802143 <a title="307-lsi-9" href="./nips-2013-Sketching_Structured_Matrices_for_Faster_Nonlinear_Regression.html">297 nips-2013-Sketching Structured Matrices for Faster Nonlinear Regression</a></p>
<p>10 0.61264354 <a title="307-lsi-10" href="./nips-2013-On_the_Relationship_Between_Binary_Classification%2C_Bipartite_Ranking%2C_and_Binary_Class_Probability_Estimation.html">223 nips-2013-On the Relationship Between Binary Classification, Bipartite Ranking, and Binary Class Probability Estimation</a></p>
<p>11 0.61055118 <a title="307-lsi-11" href="./nips-2013-What_do_row_and_column_marginals_reveal_about_your_dataset%3F.html">352 nips-2013-What do row and column marginals reveal about your dataset?</a></p>
<p>12 0.59932607 <a title="307-lsi-12" href="./nips-2013-Convex_Relaxations_for_Permutation_Problems.html">73 nips-2013-Convex Relaxations for Permutation Problems</a></p>
<p>13 0.5898537 <a title="307-lsi-13" href="./nips-2013-Dirty_Statistical_Models.html">91 nips-2013-Dirty Statistical Models</a></p>
<p>14 0.58073127 <a title="307-lsi-14" href="./nips-2013-Robust_Transfer_Principal_Component_Analysis_with_Rank_Constraints.html">285 nips-2013-Robust Transfer Principal Component Analysis with Rank Constraints</a></p>
<p>15 0.57092738 <a title="307-lsi-15" href="./nips-2013-Phase_Retrieval_using_Alternating_Minimization.html">247 nips-2013-Phase Retrieval using Alternating Minimization</a></p>
<p>16 0.56653637 <a title="307-lsi-16" href="./nips-2013-More_data_speeds_up_training_time_in_learning_halfspaces_over_sparse_vectors.html">199 nips-2013-More data speeds up training time in learning halfspaces over sparse vectors</a></p>
<p>17 0.56242019 <a title="307-lsi-17" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>18 0.55875927 <a title="307-lsi-18" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>19 0.55777979 <a title="307-lsi-19" href="./nips-2013-When_in_Doubt%2C_SWAP%3A_High-Dimensional_Sparse_Recovery_from_Correlated_Measurements.html">354 nips-2013-When in Doubt, SWAP: High-Dimensional Sparse Recovery from Correlated Measurements</a></p>
<p>20 0.55667675 <a title="307-lsi-20" href="./nips-2013-Graphical_Models_for_Inference_with_Missing_Data.html">134 nips-2013-Graphical Models for Inference with Missing Data</a></p>
<br/>
<h2>similar papers computed by <a title="lda-model" href="../home/nips2013_lda.html">lda model</a></h2><h3>lda for this paper:</h3><p>topicId topicWeight</p>
<p>[(20, 0.151), (25, 0.135), (37, 0.057), (70, 0.041), (78, 0.263), (80, 0.056), (86, 0.104), (87, 0.076)]</p>
<h3>similar papers list:</h3><p>simIndex simValue paperId paperTitle</p>
<p>same-paper 1 0.75759685 <a title="307-lda-1" href="./nips-2013-Speedup_Matrix_Completion_with_Side_Information%3A_Application_to_Multi-Label_Learning.html">307 nips-2013-Speedup Matrix Completion with Side Information: Application to Multi-Label Learning</a></p>
<p>2 0.75250643 <a title="307-lda-2" href="./nips-2013-A_Kernel_Test_for_Three-Variable_Interactions.html">9 nips-2013-A Kernel Test for Three-Variable Interactions</a></p>
<p>3 0.72467697 <a title="307-lda-3" href="./nips-2013-Model_Selection_for_High-Dimensional_Regression_under_the_Generalized_Irrepresentability_Condition.html">194 nips-2013-Model Selection for High-Dimensional Regression under the Generalized Irrepresentability Condition</a></p>
<p>4 0.72082686 <a title="307-lda-4" href="./nips-2013-Mixed_Optimization_for_Smooth_Functions.html">193 nips-2013-Mixed Optimization for Smooth Functions</a></p>
<p>5 0.68793654 <a title="307-lda-5" href="./nips-2013-Fantope_Projection_and_Selection%3A_A_near-optimal_convex_relaxation_of_sparse_PCA.html">116 nips-2013-Fantope Projection and Selection: A near-optimal convex relaxation of sparse PCA</a></p>
<p>6 0.68747443 <a title="307-lda-6" href="./nips-2013-Estimation%2C_Optimization%2C_and_Parallelism_when_Data_is_Sparse.html">111 nips-2013-Estimation, Optimization, and Parallelism when Data is Sparse</a></p>
<p>7 0.68640417 <a title="307-lda-7" href="./nips-2013-A_New_Convex_Relaxation_for_Tensor_Completion.html">11 nips-2013-A New Convex Relaxation for Tensor Completion</a></p>
<p>8 0.68434906 <a title="307-lda-8" href="./nips-2013-Online_Robust_PCA_via_Stochastic_Optimization.html">233 nips-2013-Online Robust PCA via Stochastic Optimization</a></p>
<p>9 0.68167132 <a title="307-lda-9" href="./nips-2013-On_Flat_versus_Hierarchical_Classification_in_Large-Scale_Taxonomies.html">216 nips-2013-On Flat versus Hierarchical Classification in Large-Scale Taxonomies</a></p>
<p>10 0.68066806 <a title="307-lda-10" href="./nips-2013-Information-theoretic_lower_bounds_for_distributed_statistical_estimation_with_communication_constraints.html">142 nips-2013-Information-theoretic lower bounds for distributed statistical estimation with communication constraints</a></p>
<p>11 0.68043417 <a title="307-lda-11" href="./nips-2013-Learning_with_Noisy_Labels.html">171 nips-2013-Learning with Noisy Labels</a></p>
<p>12 0.68028945 <a title="307-lda-12" href="./nips-2013-Provable_Subspace_Clustering%3A_When_LRR_meets_SSC.html">259 nips-2013-Provable Subspace Clustering: When LRR meets SSC</a></p>
<p>13 0.68004715 <a title="307-lda-13" href="./nips-2013-On_the_Linear_Convergence_of_the_Proximal_Gradient_Method_for_Trace_Norm_Regularization.html">222 nips-2013-On the Linear Convergence of the Proximal Gradient Method for Trace Norm Regularization</a></p>
<p>14 0.67906815 <a title="307-lda-14" href="./nips-2013-q-OCSVM%3A_A_q-Quantile_Estimator_for_High-Dimensional_Distributions.html">358 nips-2013-q-OCSVM: A q-Quantile Estimator for High-Dimensional Distributions</a></p>
<p>15 0.67802519 <a title="307-lda-15" href="./nips-2013-Trading_Computation_for_Communication%3A_Distributed_Stochastic_Dual_Coordinate_Ascent.html">333 nips-2013-Trading Computation for Communication: Distributed Stochastic Dual Coordinate Ascent</a></p>
<p>16 0.67789137 <a title="307-lda-16" href="./nips-2013-Convex_Tensor_Decomposition_via_Structured_Schatten_Norm_Regularization.html">74 nips-2013-Convex Tensor Decomposition via Structured Schatten Norm Regularization</a></p>
<p>17 0.67719454 <a title="307-lda-17" href="./nips-2013-Noise-Enhanced_Associative_Memories.html">210 nips-2013-Noise-Enhanced Associative Memories</a></p>
<p>18 0.67658031 <a title="307-lda-18" href="./nips-2013-Transportability_from_Multiple_Environments_with_Limited_Experiments.html">337 nips-2013-Transportability from Multiple Environments with Limited Experiments</a></p>
<p>19 0.67599863 <a title="307-lda-19" href="./nips-2013-%CE%A3-Optimality_for_Active_Learning_on_Gaussian_Random_Fields.html">359 nips-2013-Σ-Optimality for Active Learning on Gaussian Random Fields</a></p>
<p>20 0.6758036 <a title="307-lda-20" href="./nips-2013-Confidence_Intervals_and_Hypothesis_Testing_for_High-Dimensional_Statistical_Models.html">68 nips-2013-Confidence Intervals and Hypothesis Testing for High-Dimensional Statistical Models</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
