<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-966" href="#">high_scalability-2010-966</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-966-html" href="http://highscalability.com//blog/2010/12/31/facebook-in-20-minutes-27m-photos-102m-comments-46m-messages.html">html</a></p><p>Introduction: To celebrate the new year Facebook hasshared the resultsof a little end of the
year introspection. It has been a fecund year for Facebook:43,869,800 changed
their status to single3,025,791 changed their status to "it's
complicated"28,460,516 changed their status to in a relationship5,974,574
changed their status to engaged36,774,801 changes their status to marriedIf
these numbers are simply to large to grasp, it doesn't get any better when you
look at happens in a mere 20 minutes:Shared links: 1,000,000 Tagged photos:
1,323,000Event invites sent out: 1,484,000Wall Posts: 1,587,000 Status
updates: 1,851,000Friend requests accepted: 1,972,000Photos uploaded:
2,716,000Comments: 10,208,000Message: 4,632,000If you want to see how Facebook
supports these huge numbers take a look at a few posts.One wonders what the
new year will bring?Related ArticlesWhat the World Eatsfrom Time Magazine A
Day in the Life of an Ancient RomanA Day in the Life of Donald DuckThe
Beatles- A Day in the LifeA Day i</p><br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('status', 0.523), ('changed', 0.321), ('year', 0.26), ('day', 0.22), ('life', 0.205), ('warrior', 0.196), ('donald', 0.184), ('invites', 0.169), ('articleswhat', 0.169), ('celebrate', 0.169), ('wonders', 0.169), ('facebook', 0.158), ('grasp', 0.149), ('tagged', 0.144), ('numbers', 0.139), ('accepted', 0.137), ('mere', 0.137), ('magazine', 0.135), ('ancient', 0.132), ('uploaded', 0.109)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="966-tfidf-1" href="../high_scalability-2010/high_scalability-2010-12-31-Facebook_in_20_Minutes%3A_2.7M_Photos%2C_10.2M_Comments%2C_4.6M_Messages.html">966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</a></p>
<p>Introduction: To celebrate the new year Facebook hasshared the resultsof a little end of the
year introspection. It has been a fecund year for Facebook:43,869,800 changed
their status to single3,025,791 changed their status to "it's
complicated"28,460,516 changed their status to in a relationship5,974,574
changed their status to engaged36,774,801 changes their status to marriedIf
these numbers are simply to large to grasp, it doesn't get any better when you
look at happens in a mere 20 minutes:Shared links: 1,000,000 Tagged photos:
1,323,000Event invites sent out: 1,484,000Wall Posts: 1,587,000 Status
updates: 1,851,000Friend requests accepted: 1,972,000Photos uploaded:
2,716,000Comments: 10,208,000Message: 4,632,000If you want to see how Facebook
supports these huge numbers take a look at a few posts.One wonders what the
new year will bring?Related ArticlesWhat the World Eatsfrom Time Magazine A
Day in the Life of an Ancient RomanA Day in the Life of Donald DuckThe
Beatles- A Day in the LifeA Day i</p><p>2 0.16378513 <a title="966-tfidf-2" href="../high_scalability-2012/high_scalability-2012-01-04-How_Facebook_Handled_the_New_Year%27s_Eve_Onslaught.html">1168 high scalability-2012-01-04-How Facebook Handled the New Year's Eve Onslaught</a></p>
<p>Introduction: How does Facebook handle the massive New Year's Eve traffic spike? Thanks to
Mike Swift, in Facebook gets ready for New Year's Eve, we get a little insight
as to their method for the madness, nothing really detailed, but still
interesting.Problem SetupFacebook expects tha one billion+ photos will be
shared on New Year's eve.Facebook's 800 million users are scattered around the
world. Three quarters live outside the US. Each user is linked to an average
of 130 friends.Photos and posts must appear in less than a second. Opening a
homepage requires executing requests on a 100 different servers, and those
requests have to be ranked, sorted, and privacy-checked, and then
rendered.Different events put different stresses on different parts of
Facebook. Photo and Video Uploads - Holidays require hundreds of terabytes of
capacity News Feed - News events like big sports events and the death of Steve
Jobs drive user status updatesCoping StrategiesTry to predictthe surge in
traffic. Run checkson h</p><p>3 0.10926352 <a title="966-tfidf-3" href="../high_scalability-2008/high_scalability-2008-12-13-Strategy%3A_Facebook_Tweaks_to_Handle_6_Time_as_Many_Memcached_Requests.html">464 high scalability-2008-12-13-Strategy: Facebook Tweaks to Handle 6 Time as Many Memcached Requests</a></p>
<p>Introduction: Our latest strategy is taken from agreat post by Paul Saab of Facebook,
detailing how with changes Facebook has made to memcached they have:...been
able to scale memcached to handle 200,000 UDP requests per second with an
average latency of 173 microseconds. The total throughput achieved is 300,000
UDP requests/s, but the latency at that request rate is too high to be useful
in our system. This is an amazing increase from 50,000 UDP requests/s using
the stock version of Linux and memcached.To scale Facebook has hundreds of
thousands of TCP connections open to their memcached processes. First, this is
still amazing. It's not so long ago you could have never done this. Optimizing
connection use was always a priority because the OS simply couldn't handle
large numbers of connections or large numbers of threads or large numbers of
CPUs. To get to this point is a big accomplishment. Still, at that scale there
are problems that are often solved.Some of the problem Facebook faced and
fixed:Pe</p><p>4 0.1065268 <a title="966-tfidf-4" href="../high_scalability-2013/high_scalability-2013-01-14-MongoDB_and_GridFS_for_Inter_and_Intra_Datacenter_Data_Replication_.html">1386 high scalability-2013-01-14-MongoDB and GridFS for Inter and Intra Datacenter Data Replication </a></p>
<p>Introduction: This is a guest post byJeff Behl, VP Ops @ LogicMonitor. Jeffhas been a bit
herder for the last 20 years, architecting and overseeing the infrastructure
for a number of SaaS based companies.  Data Replication for Disaster
RecoveryAn inevitable part of disaster recovery planning is making sure
customer data exists in multiple locations.  In the case of LogicMonitor, a
SaaS-based monitoring solution for physical, virtual, and cloud environments,
we wanted copies of customer data files both within a data center and outside
of it.  The former was to protect against the loss of individual servers
within a facility, and the latter for recovery in the event of the complete
loss of a data center.Where we were:  RsyncLike most everyone who starts off
in a Linux environment, we used our trusty friend rsync to copy data around.
Rsync is tried, true and tested, and works well when the number of servers,
the amount of data, and the number of files is not horrendous.  When any of
these are no longer</p><p>5 0.10639535 <a title="966-tfidf-5" href="../high_scalability-2009/high_scalability-2009-10-13-Why_are_Facebook%2C_Digg%2C_and_Twitter_so_hard_to_scale%3F.html">721 high scalability-2009-10-13-Why are Facebook, Digg, and Twitter so hard to scale?</a></p>
<p>Introduction: Real-time social graphs (connectivity between people, places, and things).
That's why scaling Facebook is hardsays Jeff Rothschild, Vice President of
Technology at Facebook. Social networking sites like Facebook, Digg, and
Twitter are simply harder than traditional websites to scale. Why is that? Why
would social networking sites be any more difficult to scale than traditional
web sites? Let's find out.Traditional websites are easier to scale than social
networking sites for two reasons:They usually access only their own data and
common cached data.Only 1-2% of users are active on the site at one
time.Imagine a huge site like Yahoo. When you come to Yahoo they can get your
profile record with one get and that's enough to build your view of the
website for you. It's relatively straightforward to scale systems based around
single records usingdistributed hashing schemes. And since only a few percent
of the people are on the site at once it takes comparatively little RAM cache
to handle a</p><p>6 0.10064989 <a title="966-tfidf-6" href="../high_scalability-2009/high_scalability-2009-10-12-High_Performance_at_Massive_Scale_%E2%80%93__Lessons_learned_at_Facebook.html">720 high scalability-2009-10-12-High Performance at Massive Scale –  Lessons learned at Facebook</a></p>
<p>7 0.096106589 <a title="966-tfidf-7" href="../high_scalability-2012/high_scalability-2012-01-23-Facebook_Timeline%3A_Brought_to_You_by_the_Power_of_Denormalization.html">1179 high scalability-2012-01-23-Facebook Timeline: Brought to You by the Power of Denormalization</a></p>
<p>8 0.093880683 <a title="966-tfidf-8" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>9 0.093781143 <a title="966-tfidf-9" href="../high_scalability-2010/high_scalability-2010-06-22-Exploring_the_software_behind_Facebook%2C_the_world%E2%80%99s_largest_site.html">845 high scalability-2010-06-22-Exploring the software behind Facebook, the world’s largest site</a></p>
<p>10 0.090550758 <a title="966-tfidf-10" href="../high_scalability-2011/high_scalability-2011-03-14-Twitter_by_the_Numbers_-_460%2C000_New_Accounts_and_140_Million_Tweets_Per_Day.html">1004 high scalability-2011-03-14-Twitter by the Numbers - 460,000 New Accounts and 140 Million Tweets Per Day</a></p>
<p>11 0.086340815 <a title="966-tfidf-11" href="../high_scalability-2010/high_scalability-2010-08-06-Hot_Scalability_Links_for_Aug_6%2C_2010.html">873 high scalability-2010-08-06-Hot Scalability Links for Aug 6, 2010</a></p>
<p>12 0.08578971 <a title="966-tfidf-12" href="../high_scalability-2011/high_scalability-2011-09-23-The_Real_News_is_Not_that_Facebook_Serves_Up_1_Trillion_Pages_a_Month%E2%80%A6.html">1123 high scalability-2011-09-23-The Real News is Not that Facebook Serves Up 1 Trillion Pages a Month…</a></p>
<p>13 0.079322591 <a title="966-tfidf-13" href="../high_scalability-2010/high_scalability-2010-01-11-Have_We_Reached_the_End_of_Scaling%3F.html">758 high scalability-2010-01-11-Have We Reached the End of Scaling?</a></p>
<p>14 0.077339411 <a title="966-tfidf-14" href="../high_scalability-2008/high_scalability-2008-04-02-Product%3A_Supervisor_-__Monitor_and_Control_Your_Processes.html">295 high scalability-2008-04-02-Product: Supervisor -  Monitor and Control Your Processes</a></p>
<p>15 0.076125726 <a title="966-tfidf-15" href="../high_scalability-2011/high_scalability-2011-10-24-StackExchange_Architecture_Updates_-_Running_Smoothly%2C_Amazon_4x_More_Expensive.html">1131 high scalability-2011-10-24-StackExchange Architecture Updates - Running Smoothly, Amazon 4x More Expensive</a></p>
<p>16 0.07602749 <a title="966-tfidf-16" href="../high_scalability-2008/high_scalability-2008-01-01-S3_for_image_storing.html">199 high scalability-2008-01-01-S3 for image storing</a></p>
<p>17 0.075888604 <a title="966-tfidf-17" href="../high_scalability-2012/high_scalability-2012-02-21-Pixable_Architecture_-_Crawling%2C_Analyzing%2C_and_Ranking_20_Million_Photos_a_Day.html">1197 high scalability-2012-02-21-Pixable Architecture - Crawling, Analyzing, and Ranking 20 Million Photos a Day</a></p>
<p>18 0.074964963 <a title="966-tfidf-18" href="../high_scalability-2012/high_scalability-2012-07-23-State_of_the_CDN%3A_More_Traffic%2C_Stable_Prices%2C_More_Products%2C_Profits_-_Not_So_Much.html">1289 high scalability-2012-07-23-State of the CDN: More Traffic, Stable Prices, More Products, Profits - Not So Much</a></p>
<p>19 0.074302718 <a title="966-tfidf-19" href="../high_scalability-2009/high_scalability-2009-06-10-Hive_-_A_Petabyte_Scale_Data_Warehouse_using_Hadoop.html">624 high scalability-2009-06-10-Hive - A Petabyte Scale Data Warehouse using Hadoop</a></p>
<p>20 0.07284116 <a title="966-tfidf-20" href="../high_scalability-2008/high_scalability-2008-12-20-Second_Life_Architecture_-_The_Grid.html">473 high scalability-2008-12-20-Second Life Architecture - The Grid</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.08), (1, 0.043), (2, -0.02), (3, -0.011), (4, 0.041), (5, -0.055), (6, -0.051), (7, 0.06), (8, 0.033), (9, -0.008), (10, 0.016), (11, 0.04), (12, 0.056), (13, 0.024), (14, -0.03), (15, 0.06), (16, -0.004), (17, 0.002), (18, 0.015), (19, 0.051), (20, 0.039), (21, 0.053), (22, 0.051), (23, 0.006), (24, 0.023), (25, -0.058), (26, 0.02), (27, 0.008), (28, 0.049), (29, 0.008), (30, -0.04), (31, 0.003), (32, -0.011), (33, 0.022), (34, 0.01), (35, 0.037), (36, 0.037), (37, -0.067), (38, 0.013), (39, 0.001), (40, -0.026), (41, -0.009), (42, 0.023), (43, -0.007), (44, -0.047), (45, -0.017), (46, 0.001), (47, -0.005), (48, -0.006), (49, -0.038)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.98836058 <a title="966-lsi-1" href="../high_scalability-2010/high_scalability-2010-12-31-Facebook_in_20_Minutes%3A_2.7M_Photos%2C_10.2M_Comments%2C_4.6M_Messages.html">966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</a></p>
<p>Introduction: To celebrate the new year Facebook hasshared the resultsof a little end of the
year introspection. It has been a fecund year for Facebook:43,869,800 changed
their status to single3,025,791 changed their status to "it's
complicated"28,460,516 changed their status to in a relationship5,974,574
changed their status to engaged36,774,801 changes their status to marriedIf
these numbers are simply to large to grasp, it doesn't get any better when you
look at happens in a mere 20 minutes:Shared links: 1,000,000 Tagged photos:
1,323,000Event invites sent out: 1,484,000Wall Posts: 1,587,000 Status
updates: 1,851,000Friend requests accepted: 1,972,000Photos uploaded:
2,716,000Comments: 10,208,000Message: 4,632,000If you want to see how Facebook
supports these huge numbers take a look at a few posts.One wonders what the
new year will bring?Related ArticlesWhat the World Eatsfrom Time Magazine A
Day in the Life of an Ancient RomanA Day in the Life of Donald DuckThe
Beatles- A Day in the LifeA Day i</p><p>2 0.82137322 <a title="966-lsi-2" href="../high_scalability-2010/high_scalability-2010-08-02-7_Scaling_Strategies_Facebook_Used_to_Grow_to_500_Million_Users.html">870 high scalability-2010-08-02-7 Scaling Strategies Facebook Used to Grow to 500 Million Users</a></p>
<p>Introduction: Robert Johnson, a director of engineering at Facebook, celebrated Facebook's
monumental achievement of reaching 500 million users by sharing thescaling
principles that helped reach that milestone. In case you weren't suitably
impressed by the 500 million user number, Robert ratchets up the numbers game
with these impressive figures:1 million users per engineer500 million active
users100 billion hits per day50 billion photos2 trillion objects cached, with
hundreds of millions of requests per second130TB of logs every dayHow did
Facebook get to this point?People Matter Most. It's people who build and run
systems. The best tools for scaling are an engineering and operations teams
that can handle anything.Scale Horizontally. Handling exponentially growing
traffic requires spreading load arbitrarily across many machines. Using
different databases for tables like accounts and profiles only doubles
capacity. This approach hurts efficiency, but efficiency is a separate effort
from scaling, eff</p><p>3 0.8019805 <a title="966-lsi-3" href="../high_scalability-2012/high_scalability-2012-01-04-How_Facebook_Handled_the_New_Year%27s_Eve_Onslaught.html">1168 high scalability-2012-01-04-How Facebook Handled the New Year's Eve Onslaught</a></p>
<p>Introduction: How does Facebook handle the massive New Year's Eve traffic spike? Thanks to
Mike Swift, in Facebook gets ready for New Year's Eve, we get a little insight
as to their method for the madness, nothing really detailed, but still
interesting.Problem SetupFacebook expects tha one billion+ photos will be
shared on New Year's eve.Facebook's 800 million users are scattered around the
world. Three quarters live outside the US. Each user is linked to an average
of 130 friends.Photos and posts must appear in less than a second. Opening a
homepage requires executing requests on a 100 different servers, and those
requests have to be ranked, sorted, and privacy-checked, and then
rendered.Different events put different stresses on different parts of
Facebook. Photo and Video Uploads - Holidays require hundreds of terabytes of
capacity News Feed - News events like big sports events and the death of Steve
Jobs drive user status updatesCoping StrategiesTry to predictthe surge in
traffic. Run checkson h</p><p>4 0.78740257 <a title="966-lsi-4" href="../high_scalability-2009/high_scalability-2009-10-12-High_Performance_at_Massive_Scale_%E2%80%93__Lessons_learned_at_Facebook.html">720 high scalability-2009-10-12-High Performance at Massive Scale –  Lessons learned at Facebook</a></p>
<p>Introduction: Jeff Rothschild, Vice President of Technology at Facebook gave a great
presentation at UC San Diego on our favorite subject: "High Performance at
Massive Scale -  Lessons learned at Facebook". The abstract for the talk
is:Facebook has grown into one of the largest sites on the Internet today
serving over 200 billion pages per month. The nature of social data makes
engineering a site for this level of scale a particularly challenging
proposition. In this presentation, I will discuss the aspects of social data
that present challenges for scalability and will describe the the core
architectural components and design principles that Facebook has used to
address these challenges. In addition, I will discuss emerging technologies
that offer new opportunities for building cost-effective high performance web
architectures.There's a lot of interesting about this talk that we'll get into
later, but I thought you might want a head start on learning how Facebook
handles 30K+ machines, 300 million</p><p>5 0.77560031 <a title="966-lsi-5" href="../high_scalability-2014/high_scalability-2014-03-26-Oculus_Causes_a_Rift%2C_but_the_Facebook_Deal_Will_Avoid_a_Scaling_Crisis_for_Virtual_Reality.html">1619 high scalability-2014-03-26-Oculus Causes a Rift, but the Facebook Deal Will Avoid a Scaling Crisis for Virtual Reality</a></p>
<p>Introduction: Facebook has been teasing us. While many of their recentacquisitionshave been
surprising, shocking is the only word adequately describing Facebook's5 day
whirlwind acquisitionofOculus, immersive virtual reality visionaries, for a
now paltry sounding $2 billion.Thebacklashis a pandemic, jumping acrosssocial
networkswith the speed only a meme powered by the directly unaffected can
generate.For more than 30 years VR has been the dream burning in the heart of
every science fiction fan. Now that this future might finally be here,
Facebook's ownage makes it seem like a wonderful and hopeful timeline has been
choked off, killing the Metaverse before it even had a chance to begin.For the
many who voted for an open future with theirKickstarter dollars, there's a
deep and personal sense of betrayal, despite Facebook's promise to leave
Oculus alone. The intensity of the reaction is because Oculus matters to
people. It's new, it's different, it creates a better future. It's important
in a way send</p><p>6 0.77112347 <a title="966-lsi-6" href="../high_scalability-2008/high_scalability-2008-03-03-Read_This_Site_and_Ace_Your_Next_Interview%21.html">264 high scalability-2008-03-03-Read This Site and Ace Your Next Interview!</a></p>
<p>7 0.76874268 <a title="966-lsi-7" href="../high_scalability-2010/high_scalability-2010-06-22-Exploring_the_software_behind_Facebook%2C_the_world%E2%80%99s_largest_site.html">845 high scalability-2010-06-22-Exploring the software behind Facebook, the world’s largest site</a></p>
<p>8 0.74020422 <a title="966-lsi-8" href="../high_scalability-2010/high_scalability-2010-06-10-The_Four_Meta_Secrets_of_Scaling_at_Facebook.html">840 high scalability-2010-06-10-The Four Meta Secrets of Scaling at Facebook</a></p>
<p>9 0.73908037 <a title="966-lsi-9" href="../high_scalability-2012/high_scalability-2012-09-15-4_Reasons_Facebook_Dumped_HTML5_and_Went_Native.html">1323 high scalability-2012-09-15-4 Reasons Facebook Dumped HTML5 and Went Native</a></p>
<p>10 0.70981705 <a title="966-lsi-10" href="../high_scalability-2011/high_scalability-2011-09-23-The_Real_News_is_Not_that_Facebook_Serves_Up_1_Trillion_Pages_a_Month%E2%80%A6.html">1123 high scalability-2011-09-23-The Real News is Not that Facebook Serves Up 1 Trillion Pages a Month…</a></p>
<p>11 0.69741958 <a title="966-lsi-11" href="../high_scalability-2011/high_scalability-2011-07-18-Building_your_own_Facebook_Realtime_Analytics_System__.html">1081 high scalability-2011-07-18-Building your own Facebook Realtime Analytics System  </a></p>
<p>12 0.68864769 <a title="966-lsi-12" href="../high_scalability-2009/high_scalability-2009-06-10-Hive_-_A_Petabyte_Scale_Data_Warehouse_using_Hadoop.html">624 high scalability-2009-06-10-Hive - A Petabyte Scale Data Warehouse using Hadoop</a></p>
<p>13 0.67848891 <a title="966-lsi-13" href="../high_scalability-2008/high_scalability-2008-12-13-Strategy%3A_Facebook_Tweaks_to_Handle_6_Time_as_Many_Memcached_Requests.html">464 high scalability-2008-12-13-Strategy: Facebook Tweaks to Handle 6 Time as Many Memcached Requests</a></p>
<p>14 0.67083526 <a title="966-lsi-14" href="../high_scalability-2009/high_scalability-2009-04-10-Facebook%27s_Aditya_giving_presentation_on_Facebook_Architecture.html">562 high scalability-2009-04-10-Facebook's Aditya giving presentation on Facebook Architecture</a></p>
<p>15 0.66867983 <a title="966-lsi-15" href="../high_scalability-2014/high_scalability-2014-02-26-The_WhatsApp_Architecture_Facebook_Bought_For_%2419_Billion.html">1602 high scalability-2014-02-26-The WhatsApp Architecture Facebook Bought For $19 Billion</a></p>
<p>16 0.66727358 <a title="966-lsi-16" href="../high_scalability-2008/high_scalability-2008-09-03-Some_Facebook_Secrets_to_Better_Operations.html">378 high scalability-2008-09-03-Some Facebook Secrets to Better Operations</a></p>
<p>17 0.66677821 <a title="966-lsi-17" href="../high_scalability-2013/high_scalability-2013-04-23-Facebook_Secrets_of_Web_Performance.html">1444 high scalability-2013-04-23-Facebook Secrets of Web Performance</a></p>
<p>18 0.66175878 <a title="966-lsi-18" href="../high_scalability-2010/high_scalability-2010-03-10-How_FarmVille_Scales_-_The_Follow-up.html">792 high scalability-2010-03-10-How FarmVille Scales - The Follow-up</a></p>
<p>19 0.6473437 <a title="966-lsi-19" href="../high_scalability-2009/high_scalability-2009-04-10-Facebook_Chat_Architecture.html">563 high scalability-2009-04-10-Facebook Chat Architecture</a></p>
<p>20 0.64304006 <a title="966-lsi-20" href="../high_scalability-2014/high_scalability-2014-02-13-Snabb_Switch_-_Skip_the_OS_and_Get_40_million_Requests_Per_Second_in_Lua.html">1595 high scalability-2014-02-13-Snabb Switch - Skip the OS and Get 40 million Requests Per Second in Lua</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(1, 0.117), (2, 0.253), (61, 0.014), (76, 0.314), (79, 0.097), (94, 0.059)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.8755179 <a title="966-lda-1" href="../high_scalability-2010/high_scalability-2010-12-31-Facebook_in_20_Minutes%3A_2.7M_Photos%2C_10.2M_Comments%2C_4.6M_Messages.html">966 high scalability-2010-12-31-Facebook in 20 Minutes: 2.7M Photos, 10.2M Comments, 4.6M Messages</a></p>
<p>Introduction: To celebrate the new year Facebook hasshared the resultsof a little end of the
year introspection. It has been a fecund year for Facebook:43,869,800 changed
their status to single3,025,791 changed their status to "it's
complicated"28,460,516 changed their status to in a relationship5,974,574
changed their status to engaged36,774,801 changes their status to marriedIf
these numbers are simply to large to grasp, it doesn't get any better when you
look at happens in a mere 20 minutes:Shared links: 1,000,000 Tagged photos:
1,323,000Event invites sent out: 1,484,000Wall Posts: 1,587,000 Status
updates: 1,851,000Friend requests accepted: 1,972,000Photos uploaded:
2,716,000Comments: 10,208,000Message: 4,632,000If you want to see how Facebook
supports these huge numbers take a look at a few posts.One wonders what the
new year will bring?Related ArticlesWhat the World Eatsfrom Time Magazine A
Day in the Life of an Ancient RomanA Day in the Life of Donald DuckThe
Beatles- A Day in the LifeA Day i</p><p>2 0.83480185 <a title="966-lda-2" href="../high_scalability-2007/high_scalability-2007-12-02-nginx%3A_high_performance_smpt-pop-imap_proxy.html">172 high scalability-2007-12-02-nginx: high performance smpt-pop-imap proxy</a></p>
<p>Introduction: nginx is a high performance smtp/pop/imap proxy that lets you do custom
authorization and lookups and is very scalable. (just add nodes)Nginx by
default is a reverse proxy and this is what it is doing here for pop/imap
connections. It is also an excellelent reverse proxy for web
servers.Advantage: You dont have to have a speacial database or ldap schema.
Just an url to do auth and lookup with.A url that may be accessed by a unix or
a tcp socket. Write your own auth handler - according to your own policy.For
example:A user called atif tries to login with the pass testxyz.You pass this
infomation to a URL such assocket:/var/tmp/xyz.sockorhttp://auth.corp.mailserv
er.net:someport/someurlThe auth server replies with either a FAILURE such
asAuth-Status: Invalid Login or passwordor with a success such asAuth-Status:
OKAuth-Server: OneOfThe100ServersAuth-Port: optionalyAPortWe have implemented
it at our ISP and it has saves us a lot of headaches.This would work for both
imap and pop.I have no</p><p>3 0.78306293 <a title="966-lda-3" href="../high_scalability-2010/high_scalability-2010-08-30-Pomegranate_-_Storing_Billions_and_Billions_of_Tiny_Little_Files.html">889 high scalability-2010-08-30-Pomegranate - Storing Billions and Billions of Tiny Little Files</a></p>
<p>Introduction: Pomegranateis a novel distributed file system built over distributed tabular
storage that acts an awful lot like a NoSQL system. It's targeted at
increasing the performance of tiny object access in order to support
applications like online photo and micro-blog services, which require high
concurrency, high throughput, and low latency. Their tests seem to indicate it
works:We have demonstrate that file system over tabular storage performs well
for highly concurrent access. In our test cluster, we observedlinearly
increased more than100,000aggregate read and write requests served per second
(RPS). Rather than sitting atop the file system like almost every other K-V
store, Pomegranate is baked into file system. The idea is that the file system
API is common to every platform so it wouldn't require a separate API to use.
Every application could use it out of the box.The features of Pomegranate
are:It handles billions of small files efficiently, even in one directory;It
provide separate and</p><p>4 0.77501631 <a title="966-lda-4" href="../high_scalability-2011/high_scalability-2011-12-22-Architecting_Massively-Scalable_Near-Real-Time_Risk_Analysis_Solutions.html">1161 high scalability-2011-12-22-Architecting Massively-Scalable Near-Real-Time Risk Analysis Solutions</a></p>
<p>Introduction: Constructing a scalablerisk analysis solution is a fascinating architectural
challenge. If you come from Financial Services you are sure to appreciate
that. But even architects from other domains are bound to find the challenges
fascinating, and the architectural patterns of my suggested solution highly
useful in other domains.Recently I held an interesting webinar around
architecting solutions for scalable and near-real-time risk analysis solutions
based on experience gathered with Financial Services customers. Seeing the
vast interest in the webinar, I would like to share the highlights with you
here.From an architectural point of view, risk analysis is a data-intensive
and a compute-intensive process, which also has an elaborate orchestration
logic. volumes in this domain are massive and ever-increasing, together with
an ever-increasing demand to reduce response time. These trends are aggravated
by global financial regulatory reforms set following the late-2000s financial
crisis, wh</p><p>5 0.77312583 <a title="966-lda-5" href="../high_scalability-2009/high_scalability-2009-01-04-Paper%3A_MapReduce%3A_Simplified_Data_Processing_on_Large_Clusters.html">483 high scalability-2009-01-04-Paper: MapReduce: Simplified Data Processing on Large Clusters</a></p>
<p>Introduction: Update:MapReduce and PageRank Notes from Remzi Arpaci-Dusseau's Fall 2008
class. Collects interesting facts about MapReduce and PageRank. For example,
the history of the solution to searching for the term "flu" is traced through
multiple generations of technology.With Google entering the cloud space
withGoogle AppEngineand a maturingHadoopproduct, the MapReduce scaling
approach might finally become a standard programmer practice. This is the best
paper on the subject and is an excellent primer on a content-addressable
memory future.Some interesting stats from the paper: Google executes 100k
MapReduce jobs each day; more than 20 petabytes of data are processed per day;
more than 10k MapReduce programs have been implemented; machines are dual
processor with gigabit ethernet and 4-8 GB of memory.One common criticism ex-
Googlers have is that it takes months to get up and be productive in the
Google environment. Hopefully a way will be found to lower the learning curve
and make programmers</p><p>6 0.76147193 <a title="966-lda-6" href="../high_scalability-2007/high_scalability-2007-08-16-Scaling_Secret_%232%3A_Denormalizing_Your_Way_to_Speed_and_Profit.html">65 high scalability-2007-08-16-Scaling Secret #2: Denormalizing Your Way to Speed and Profit</a></p>
<p>7 0.75691533 <a title="966-lda-7" href="../high_scalability-2009/high_scalability-2009-07-29-Strategy%3A_Let_Google_and_Yahoo_Host_Your_Ajax_Library_-_For_Free.html">665 high scalability-2009-07-29-Strategy: Let Google and Yahoo Host Your Ajax Library - For Free</a></p>
<p>8 0.7409786 <a title="966-lda-8" href="../high_scalability-2011/high_scalability-2011-09-23-Stuff_The_Internet_Says_On_Scalability_For_September_23%2C_2011.html">1122 high scalability-2011-09-23-Stuff The Internet Says On Scalability For September 23, 2011</a></p>
<p>9 0.738509 <a title="966-lda-9" href="../high_scalability-2010/high_scalability-2010-04-19-The_cost_of_High_Availability_%28HA%29_with_Oracle_.html">813 high scalability-2010-04-19-The cost of High Availability (HA) with Oracle </a></p>
<p>10 0.72911119 <a title="966-lda-10" href="../high_scalability-2012/high_scalability-2012-01-23-Facebook_Timeline%3A_Brought_to_You_by_the_Power_of_Denormalization.html">1179 high scalability-2012-01-23-Facebook Timeline: Brought to You by the Power of Denormalization</a></p>
<p>11 0.72039485 <a title="966-lda-11" href="../high_scalability-2013/high_scalability-2013-12-13-Stuff_The_Internet_Says_On_Scalability_For_December_13th%2C_2013.html">1564 high scalability-2013-12-13-Stuff The Internet Says On Scalability For December 13th, 2013</a></p>
<p>12 0.71139991 <a title="966-lda-12" href="../high_scalability-2009/high_scalability-2009-09-10-When_optimizing_-_don%27t_forget_the_Java_Virtual_Machine_%28JVM%29_.html">701 high scalability-2009-09-10-When optimizing - don't forget the Java Virtual Machine (JVM) </a></p>
<p>13 0.71130019 <a title="966-lda-13" href="../high_scalability-2007/high_scalability-2007-12-07-Synchronizing_databases_in_different_geographic_locations.html">176 high scalability-2007-12-07-Synchronizing databases in different geographic locations</a></p>
<p>14 0.69156826 <a title="966-lda-14" href="../high_scalability-2012/high_scalability-2012-06-15-Stuff_The_Internet_Says_On_Scalability_For_June_15%2C_2012.html">1265 high scalability-2012-06-15-Stuff The Internet Says On Scalability For June 15, 2012</a></p>
<p>15 0.68868107 <a title="966-lda-15" href="../high_scalability-2009/high_scalability-2009-02-18-Numbers_Everyone_Should_Know.html">514 high scalability-2009-02-18-Numbers Everyone Should Know</a></p>
<p>16 0.68442774 <a title="966-lda-16" href="../high_scalability-2007/high_scalability-2007-07-16-Paper%3A_Guide_to_Cost-effective_Database_Scale-Out_using_MySQL.html">17 high scalability-2007-07-16-Paper: Guide to Cost-effective Database Scale-Out using MySQL</a></p>
<p>17 0.68089437 <a title="966-lda-17" href="../high_scalability-2010/high_scalability-2010-11-09-Facebook_Uses_Non-Stored_Procedures_to_Update_Social_Graphs.html">936 high scalability-2010-11-09-Facebook Uses Non-Stored Procedures to Update Social Graphs</a></p>
<p>18 0.6788854 <a title="966-lda-18" href="../high_scalability-2011/high_scalability-2011-09-26-17_Techniques_Used_to_Scale_Turntable.fm_and_Labmeeting_to_Millions_of_Users.html">1124 high scalability-2011-09-26-17 Techniques Used to Scale Turntable.fm and Labmeeting to Millions of Users</a></p>
<p>19 0.67729104 <a title="966-lda-19" href="../high_scalability-2009/high_scalability-2009-02-14-Scaling_Digg_and_Other_Web_Applications.html">512 high scalability-2009-02-14-Scaling Digg and Other Web Applications</a></p>
<p>20 0.67701536 <a title="966-lda-20" href="../high_scalability-2011/high_scalability-2011-07-11-ATMCash_Exploits_Virtualization_for_Security_-_Immutability_and_Reversion.html">1077 high scalability-2011-07-11-ATMCash Exploits Virtualization for Security - Immutability and Reversion</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
