<!DOCTYPE html>
<html>
<head>
<meta charset=utf-8>
<title>772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</title>
</head>

<body>
<p><a title="high_scalability" href="../high_scalability_home.html">high_scalability</a> <a title="high_scalability-2010" href="../home/high_scalability-2010_home.html">high_scalability-2010</a> <a title="high_scalability-2010-772" href="#">high_scalability-2010-772</a> knowledge-graph by maker-knowledge-mining</p><script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- maker adsense -->
<ins class="adsbygoogle"
     style="display:inline-block;width:728px;height:90px"
     data-ad-client="ca-pub-5027806277543591"
     data-ad-slot="4192012269"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>
<h1>772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</h1>
<br/><h2>meta infos for this blog</h2><p>Source: <a title="high_scalability-2010-772-html" href="http://highscalability.com//blog/2010/2/5/high-availability-principle-concurrency-control.html">html</a></p><p>Introduction: One important high availability principle is concurrency control.  The idea is
to allow only that much traffic through to your system which your system can
handle successfully.  For example: if your system is certified to handle a
concurrency of 100 then the 101st request should either timeout, be asked to
try later  or wait until one of the previous 100 requests finish.  The 101st
request should not be allowed to negatively impact the experience of the other
100 users.  Only the 101st request should be impacted.Read more here...</p><br/><h2>Summary: the most important sentenses genereted by tfidf model</h2><p>sentIndex sentText sentNum sentScore</p><p>1 The idea is to allow only that much traffic through to your system which your system can handle successfully. [sent-2, score-0.872]
</p><p>2 For example: if your system is certified to handle a concurrency of 100 then the 101st request should either timeout, be asked to try later  or wait until one of the previous 100 requests finish. [sent-3, score-2.591]
</p><p>3 The 101st request should not be allowed to negatively impact the experience of the other 100 users. [sent-4, score-1.085]
</p>
<br/>
<h2>similar blogs computed by tfidf model</h2><h3>tfidf for this blog:</h3><p>wordName wordTfidf (topN-words)</p>
<p>[('request', 0.401), ('certified', 0.359), ('concurrency', 0.333), ('timeout', 0.287), ('principle', 0.266), ('negatively', 0.224), ('allowed', 0.21), ('asked', 0.206), ('handle', 0.191), ('previous', 0.191), ('wait', 0.171), ('either', 0.158), ('impact', 0.15), ('later', 0.138), ('allow', 0.135), ('system', 0.135), ('try', 0.117), ('requests', 0.112), ('availability', 0.108), ('traffic', 0.108), ('important', 0.106), ('idea', 0.101), ('experience', 0.1), ('example', 0.093), ('one', 0.079), ('much', 0.067), ('high', 0.061)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 1.0 <a title="772-tfidf-1" href="../high_scalability-2010/high_scalability-2010-02-05-High_Availability_Principle_%3A_Concurrency_Control.html">772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</a></p>
<p>Introduction: One important high availability principle is concurrency control.  The idea is
to allow only that much traffic through to your system which your system can
handle successfully.  For example: if your system is certified to handle a
concurrency of 100 then the 101st request should either timeout, be asked to
try later  or wait until one of the previous 100 requests finish.  The 101st
request should not be allowed to negatively impact the experience of the other
100 users.  Only the 101st request should be impacted.Read more here...</p><p>2 0.16992356 <a title="772-tfidf-2" href="../high_scalability-2010/high_scalability-2010-11-22-Strategy%3A_Google_Sends_Canary_Requests_into_the_Data_Mine.html">946 high scalability-2010-11-22-Strategy: Google Sends Canary Requests into the Data Mine</a></p>
<p>Introduction: Google runs queries against thousands of in-memory index nodes in parallel and
then merges the results. One of the interesting problems with this approach,
explains Google's Jeff Dean in thislecture at Stanford, is theQuery of Death.A
query can cause a program to fail because of bugs or various other issues.
This means that a single query can take down an entire cluster of machines,
which is not good for availability and response times, as it takes quite a
while for thousands of machines to recover. Thus the Query of Death. New
queries are always coming into the system and when you are always rolling out
new software, it's impossible to completely get rid of the problem.Two
solutions:Test against logs. Google replays a month's worth of logs to see if
any of those queries kill anything. That helps, but Queries of Death may still
happen.Send a canary request. A request is sent to one machine. If the request
succeeds then it will probably succeed on all machines, so go ahead with the
quer</p><p>3 0.15200864 <a title="772-tfidf-3" href="../high_scalability-2012/high_scalability-2012-06-05-Thesis%3A_Concurrent_Programming_for_Scalable_Web_Architectures.html">1258 high scalability-2012-06-05-Thesis: Concurrent Programming for Scalable Web Architectures</a></p>
<p>Introduction: Benjamin Erb (@b_erb) from Ulm University recently published his diploma
thesis on"Concurrent Programming for Scalable Web Architectures". The thesis
provides a comprehensive survey on different concepts and techniques of
concurrency inside web architectures, including web servers, application logic
and storage backends. It incorporates research publications, hands-on reports
and also regards popular programming languages, frameworks and
databases.Abstract:Web architectures are an important asset for various large-
scale web applications, such as social networks or e-commerce sites. Being
able to handle huge numbers of users concurrently is essential, thus
scalability is one of the most important features of these architectures.
Multi-core processors, highly distributed backend architectures and new web
technologies force us to reconsider approaches for concurrent programming in
order to implement web applications and fulfil scalability demands. While
focusing on different stages of sc</p><p>4 0.15129128 <a title="772-tfidf-4" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: InTaming The Long Latency Tailwe coveredLuiz Barroso's exploration of the long
tail latency (some operations are really slow) problems generated by large
fanout architectures (a request is composed of potentially thousands of other
requests). You may have noticed there weren't a lot of solutions. That's where
a talk I attended,Achieving Rapid Response Times in Large Online
Services(slide deck), byJeff Dean, also of Google, comes in:In this talk, I'll
describe a collection of techniques and practices lowering response times in
large distributed systems whose components run on shared clusters of machines,
where pieces of these systems are subject to interference by other tasks, and
where unpredictable latency hiccups are the norm, not the exception.The goal
is to use software techniques to reduce variability given the increasing
variability in underlying hardware, the need to handle dynamic workloads on a
shared infrastructure, and the need to use large fanout architectures to
operate at</p><p>5 0.12591022 <a title="772-tfidf-5" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>Introduction: This is a guestrepostby Ron Pressler, the founder and CEO ofParallel Universe,
a Y Combinator company building advanced middleware for real-time
applications. Little's Law helps us determine the maximum request rate a
server can handle. When we apply it, we find that the dominating factor
limiting a server's capacity is not the hardware but theOS.Should we buy more
hardware if software is the problem? If not, how can we remove that software
limitation in a way that does not make the code much harder to write and
understand?Many modern web applications are composed of multiple (often
many)HTTPservices (this is often called a micro-service architecture). This
architecture has many advantages in terms of code reuse and maintainability,
scalability and fault tolerance. In this post I'd like to examine one
particular bottleneck in the approach, which hinders scalability as well as
fault tolerance, and various ways to deal with it (I am using the term
"scalability" very loosely in this post</p><p>6 0.11871307 <a title="772-tfidf-6" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>7 0.11233409 <a title="772-tfidf-7" href="../high_scalability-2009/high_scalability-2009-02-25-Relating_business%2C_systems_%26_technology_during_turbulent_time_-By_John_Zachman_.html">523 high scalability-2009-02-25-Relating business, systems & technology during turbulent time -By John Zachman </a></p>
<p>8 0.10916533 <a title="772-tfidf-8" href="../high_scalability-2009/high_scalability-2009-10-26-Facebook%27s_Memcached_Multiget_Hole%3A_More_machines_%21%3D_More_Capacity_.html">728 high scalability-2009-10-26-Facebook's Memcached Multiget Hole: More machines != More Capacity </a></p>
<p>9 0.097717121 <a title="772-tfidf-9" href="../high_scalability-2007/high_scalability-2007-08-30-Log_Everything_All_the_Time.html">77 high scalability-2007-08-30-Log Everything All the Time</a></p>
<p>10 0.097157076 <a title="772-tfidf-10" href="../high_scalability-2009/high_scalability-2009-07-27-Handle_700_Percent_More_Requests_Using_Squid_and_APC_Cache.html">662 high scalability-2009-07-27-Handle 700 Percent More Requests Using Squid and APC Cache</a></p>
<p>11 0.092589177 <a title="772-tfidf-11" href="../high_scalability-2012/high_scalability-2012-08-06-Paper%3A_High-Performance_Concurrency_Control_Mechanisms_for_Main-Memory_Databases.html">1299 high scalability-2012-08-06-Paper: High-Performance Concurrency Control Mechanisms for Main-Memory Databases</a></p>
<p>12 0.09002059 <a title="772-tfidf-12" href="../high_scalability-2012/high_scalability-2012-03-12-Google%3A_Taming_the_Long_Latency_Tail_-_When_More_Machines_Equals_Worse_Results.html">1207 high scalability-2012-03-12-Google: Taming the Long Latency Tail - When More Machines Equals Worse Results</a></p>
<p>13 0.090013504 <a title="772-tfidf-13" href="../high_scalability-2010/high_scalability-2010-02-24-Hot_Scalability_Links_for_February_24%2C_2010.html">783 high scalability-2010-02-24-Hot Scalability Links for February 24, 2010</a></p>
<p>14 0.088098399 <a title="772-tfidf-14" href="../high_scalability-2012/high_scalability-2012-10-02-An_Epic_TripAdvisor_Update%3A_Why_Not_Run_on_the_Cloud%3F_The_Grand_Experiment..html">1331 high scalability-2012-10-02-An Epic TripAdvisor Update: Why Not Run on the Cloud? The Grand Experiment.</a></p>
<p>15 0.087515213 <a title="772-tfidf-15" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>16 0.086589485 <a title="772-tfidf-16" href="../high_scalability-2008/high_scalability-2008-02-25-Any_Suggestions_for_the_Architecture_Template%3F.html">259 high scalability-2008-02-25-Any Suggestions for the Architecture Template?</a></p>
<p>17 0.086589485 <a title="772-tfidf-17" href="../high_scalability-2008/high_scalability-2008-02-25-Architecture_Template_Advice_Needed.html">260 high scalability-2008-02-25-Architecture Template Advice Needed</a></p>
<p>18 0.085051022 <a title="772-tfidf-18" href="../high_scalability-2014/high_scalability-2014-05-12-4_Architecture_Issues_When_Scaling_Web_Applications%3A_Bottlenecks%2C_Database%2C_CPU%2C_IO.html">1646 high scalability-2014-05-12-4 Architecture Issues When Scaling Web Applications: Bottlenecks, Database, CPU, IO</a></p>
<p>19 0.083015591 <a title="772-tfidf-19" href="../high_scalability-2009/high_scalability-2009-08-07-Strategy%3A_Break_Up_the_Memcache_Dog_Pile_.html">673 high scalability-2009-08-07-Strategy: Break Up the Memcache Dog Pile </a></p>
<p>20 0.078096703 <a title="772-tfidf-20" href="../high_scalability-2010/high_scalability-2010-12-20-Netflix%3A_Use_Less_Chatty_Protocols_in_the_Cloud_-_Plus_26_Fixes.html">960 high scalability-2010-12-20-Netflix: Use Less Chatty Protocols in the Cloud - Plus 26 Fixes</a></p>
<br/>
<h2>similar blogs computed by <a title="lsi-model" href="../home/high_scalability_lsi.html">lsi model</a></h2><h3>lsi for this blog:</h3><p>topicId topicWeight</p>
<p>[(0, 0.095), (1, 0.048), (2, -0.035), (3, -0.039), (4, -0.019), (5, -0.022), (6, 0.051), (7, 0.033), (8, -0.074), (9, -0.036), (10, 0.014), (11, 0.054), (12, 0.001), (13, -0.034), (14, -0.001), (15, -0.032), (16, 0.03), (17, 0.012), (18, 0.008), (19, -0.014), (20, 0.028), (21, 0.011), (22, 0.031), (23, -0.046), (24, 0.027), (25, -0.054), (26, -0.008), (27, 0.05), (28, -0.006), (29, -0.022), (30, 0.053), (31, 0.002), (32, 0.032), (33, 0.027), (34, 0.035), (35, 0.04), (36, 0.013), (37, -0.032), (38, -0.0), (39, -0.012), (40, 0.02), (41, -0.021), (42, 0.028), (43, -0.032), (44, -0.034), (45, -0.008), (46, -0.014), (47, -0.0), (48, 0.023), (49, -0.008)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95801646 <a title="772-lsi-1" href="../high_scalability-2010/high_scalability-2010-02-05-High_Availability_Principle_%3A_Concurrency_Control.html">772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</a></p>
<p>Introduction: One important high availability principle is concurrency control.  The idea is
to allow only that much traffic through to your system which your system can
handle successfully.  For example: if your system is certified to handle a
concurrency of 100 then the 101st request should either timeout, be asked to
try later  or wait until one of the previous 100 requests finish.  The 101st
request should not be allowed to negatively impact the experience of the other
100 users.  Only the 101st request should be impacted.Read more here...</p><p>2 0.75808465 <a title="772-lsi-2" href="../high_scalability-2013/high_scalability-2013-03-11-Low_Level_Scalability_Solutions_-_The_Conditioning_Collection.html">1421 high scalability-2013-03-11-Low Level Scalability Solutions - The Conditioning Collection</a></p>
<p>Introduction: We talked about 42 Monster Problems That Attack As Loads Increase. And inThe
Aggregation Collection we talked about the value of prioritizing work and
making smart queues as a way of absorbing and not reflecting traffic
spikes.Now we move on to our next batch of strategies where the theme
isconditioning, which is the idea of shaping and controlling flows of work
within your application...Use Resources Proportional To a Fixed LimitThis is
probably the most important rule for achieving scalability within an
application. What it means:Find the resource that has a fixed limit that you
know you can support. For example, a guarantee to handle a certain number of
objects in memory. So if we always use resources proportional to the number of
objects it is likely we can prevent resource exhaustion.Devise ways of tying
what you need to do to the individual resources.Some examples:Keep a list of
purchase orders with line items over $20 (or whatever). Do not keep a list of
the line items because t</p><p>3 0.75653082 <a title="772-lsi-3" href="../high_scalability-2013/high_scalability-2013-03-04-7_Life_Saving_Scalability_Defenses_Against_Load_Monster_Attacks.html">1415 high scalability-2013-03-04-7 Life Saving Scalability Defenses Against Load Monster Attacks</a></p>
<p>Introduction: We talked about42 Monster Problems That Attack As Loads Increase. Here are a
few ways you can defend yourself, secrets revealed by scaling masters across
the ages. Note that these are low level programming level moves, not large
architecture type strategies.Use Resources Proportional To a Fixed LimitThis
is probably the most important rule for achieving scalability within an
application. What it means:Find the resource that has a fixed limit that you
know you can support. For example, a guarantee to handle a certain number of
objects in memory. So if we always use resources proportional to the number of
objects it is likely we can prevent resource exhaustion.Devise ways of tying
what you need to do to the individual resources.Some examples:Keep a list of
purchase orders with line items over $20 (or whatever). Do not keep a list of
the line items because the number of items can be much larger than the number
of purchase orders. You have kept the resource usage proportional to the
number</p><p>4 0.73406094 <a title="772-lsi-4" href="../high_scalability-2012/high_scalability-2012-06-18-Google_on_Latency_Tolerant_Systems%3A_Making_a_Predictable_Whole_Out_of_Unpredictable_Parts___.html">1266 high scalability-2012-06-18-Google on Latency Tolerant Systems: Making a Predictable Whole Out of Unpredictable Parts   </a></p>
<p>Introduction: InTaming The Long Latency Tailwe coveredLuiz Barroso's exploration of the long
tail latency (some operations are really slow) problems generated by large
fanout architectures (a request is composed of potentially thousands of other
requests). You may have noticed there weren't a lot of solutions. That's where
a talk I attended,Achieving Rapid Response Times in Large Online
Services(slide deck), byJeff Dean, also of Google, comes in:In this talk, I'll
describe a collection of techniques and practices lowering response times in
large distributed systems whose components run on shared clusters of machines,
where pieces of these systems are subject to interference by other tasks, and
where unpredictable latency hiccups are the norm, not the exception.The goal
is to use software techniques to reduce variability given the increasing
variability in underlying hardware, the need to handle dynamic workloads on a
shared infrastructure, and the need to use large fanout architectures to
operate at</p><p>5 0.71464324 <a title="772-lsi-5" href="../high_scalability-2013/high_scalability-2013-02-27-42_Monster_Problems_that_Attack_as_Loads_Increase.html">1413 high scalability-2013-02-27-42 Monster Problems that Attack as Loads Increase</a></p>
<p>Introduction: For solutions take a look at:7 Life Saving Scalability Defenses Against Load
Monster Attacks.This is a look at all the bad things that can happen to your
carefully crafted program as loads increase: all hell breaks lose. Sure, you
can scale out or scale up, but you can also choose to program better. Make
your system handle larger loads. This saves money because fewer boxes are
needed and it will make the entire application more reliable and have better
response times. And it can be quite satisfying as a programmer.Large Number Of
ObjectsWe usually get into scaling problems when the number of objects gets
larger. Clearly resource usage of all types is stressed as the number of
objects grow.Continuous Failures Makes An Infinite Event StreamDuring large
network failure scenarios there is never time for the system recover. We are
in a continual state of stress.Lots of High Priority WorkFor example,
rerouting is a high priority activity. If there is a large amount of rerouting
work that can</p><p>6 0.71451557 <a title="772-lsi-6" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>7 0.71036071 <a title="772-lsi-7" href="../high_scalability-2012/high_scalability-2012-07-12-4_Strategies_for_Punching_Down_Traffic_Spikes.html">1282 high scalability-2012-07-12-4 Strategies for Punching Down Traffic Spikes</a></p>
<p>8 0.70998824 <a title="772-lsi-8" href="../high_scalability-2008/high_scalability-2008-01-10-Letting_Clients_Know_What%27s_Changed%3A_Push_Me_or_Pull_Me%3F.html">205 high scalability-2008-01-10-Letting Clients Know What's Changed: Push Me or Pull Me?</a></p>
<p>9 0.69622934 <a title="772-lsi-9" href="../high_scalability-2008/high_scalability-2008-10-08-Strategy%3A_Flickr_-_Do_the_Essential_Work_Up-front_and_Queue_the_Rest_.html">406 high scalability-2008-10-08-Strategy: Flickr - Do the Essential Work Up-front and Queue the Rest </a></p>
<p>10 0.6899628 <a title="772-lsi-10" href="../high_scalability-2013/high_scalability-2013-03-06-Low_Level_Scalability_Solutions_-_The_Aggregation_Collection.html">1418 high scalability-2013-03-06-Low Level Scalability Solutions - The Aggregation Collection</a></p>
<p>11 0.68857807 <a title="772-lsi-11" href="../high_scalability-2011/high_scalability-2011-02-01-Google_Strategy%3A_Tree_Distribution_of_Requests_and_Responses.html">981 high scalability-2011-02-01-Google Strategy: Tree Distribution of Requests and Responses</a></p>
<p>12 0.68586248 <a title="772-lsi-12" href="../high_scalability-2013/high_scalability-2013-03-25-AppBackplane_-_A_Framework_for_Supporting_Multiple_Application_Architectures.html">1429 high scalability-2013-03-25-AppBackplane - A Framework for Supporting Multiple Application Architectures</a></p>
<p>13 0.6648311 <a title="772-lsi-13" href="../high_scalability-2014/high_scalability-2014-03-31-How_WhatsApp_Grew_to_Nearly_500_Million_Users%2C_11%2C000_cores%2C_and_70_Million_Messages_a_Second.html">1622 high scalability-2014-03-31-How WhatsApp Grew to Nearly 500 Million Users, 11,000 cores, and 70 Million Messages a Second</a></p>
<p>14 0.66138262 <a title="772-lsi-14" href="../high_scalability-2013/high_scalability-2013-03-18-Beyond_Threads_and_Callbacks_-_Application_Architecture_Pros_and_Cons.html">1425 high scalability-2013-03-18-Beyond Threads and Callbacks - Application Architecture Pros and Cons</a></p>
<p>15 0.65015364 <a title="772-lsi-15" href="../high_scalability-2009/high_scalability-2009-10-26-Facebook%27s_Memcached_Multiget_Hole%3A_More_machines_%21%3D_More_Capacity_.html">728 high scalability-2009-10-26-Facebook's Memcached Multiget Hole: More machines != More Capacity </a></p>
<p>16 0.6453349 <a title="772-lsi-16" href="../high_scalability-2010/high_scalability-2010-11-15-Strategy%3A_Biggest_Performance_Impact_is_to_Reduce_the_Number_of_HTTP_Requests.html">942 high scalability-2010-11-15-Strategy: Biggest Performance Impact is to Reduce the Number of HTTP Requests</a></p>
<p>17 0.63559031 <a title="772-lsi-17" href="../high_scalability-2009/high_scalability-2009-09-10-How_to_handle_so_many_socket_connection.html">699 high scalability-2009-09-10-How to handle so many socket connection</a></p>
<p>18 0.6307686 <a title="772-lsi-18" href="../high_scalability-2011/high_scalability-2011-03-09-Google_and_Netflix_Strategy%3A_Use_Partial_Responses_to_Reduce_Request_Sizes.html">1001 high scalability-2011-03-09-Google and Netflix Strategy: Use Partial Responses to Reduce Request Sizes</a></p>
<p>19 0.62757623 <a title="772-lsi-19" href="../high_scalability-2010/high_scalability-2010-12-01-8_Commonly_Used_Scalable_System_Design_Patterns.html">951 high scalability-2010-12-01-8 Commonly Used Scalable System Design Patterns</a></p>
<p>20 0.61627609 <a title="772-lsi-20" href="../high_scalability-2007/high_scalability-2007-07-23-GoogleTalk_Architecture.html">21 high scalability-2007-07-23-GoogleTalk Architecture</a></p>
<br/>
<h2>similar blogs computed by <a title="lda-model" href="../home/high_scalability_lda.html">lda model</a></h2><h3>lda for this blog:</h3><p>topicId topicWeight</p>
<p>[(2, 0.476), (38, 0.188), (61, 0.163)]</p>
<h3>similar blogs list:</h3><p>simIndex simValue blogId blogTitle</p>
<p>same-blog 1 0.95305228 <a title="772-lda-1" href="../high_scalability-2010/high_scalability-2010-02-05-High_Availability_Principle_%3A_Concurrency_Control.html">772 high scalability-2010-02-05-High Availability Principle : Concurrency Control</a></p>
<p>Introduction: One important high availability principle is concurrency control.  The idea is
to allow only that much traffic through to your system which your system can
handle successfully.  For example: if your system is certified to handle a
concurrency of 100 then the 101st request should either timeout, be asked to
try later  or wait until one of the previous 100 requests finish.  The 101st
request should not be allowed to negatively impact the experience of the other
100 users.  Only the 101st request should be impacted.Read more here...</p><p>2 0.93019927 <a title="772-lda-2" href="../high_scalability-2007/high_scalability-2007-09-06-Product%3A_Perdition_Mail_Retrieval_Proxy.html">80 high scalability-2007-09-06-Product: Perdition Mail Retrieval Proxy</a></p>
<p>Introduction: Perditionis a fully featured POP3 and IMAP4 proxy server. It is able to handle
both SSL and non-SSL connections and redirect users to a real-server based on
a database lookup. Perdition supports modular based database access. ODBC,
MySQL, PostgreSQL, GDBM, POSIX Regular Expression and NIS modules ship with
the distribution. The API for modules is open allowing arbitrary modules to be
written to allow access to any data store.Perdition has many uses. Including,
creating large mail systems where an end-user's mailbox may be stored on one
of several hosts, integrating different mail systems together, migrating
between different email infrastructures, and bridging plain-text, SSL and TLS
services. It can also be used as part of a firewall. The use of perditon to
scale mail services beyond a single box is discussed in high capacity email.</p><p>3 0.89603269 <a title="772-lda-3" href="../high_scalability-2009/high_scalability-2009-05-08-Eight_Best_Practices_for_Building_Scalable_Systems.html">594 high scalability-2009-05-08-Eight Best Practices for Building Scalable Systems</a></p>
<p>Introduction: Wille Faler hascreated an excellent list of best practicesfor building
scalable and high performance systems. Here's a short summary of his
points:Offload the database- Avoid hitting the database, and avoid opening
transactions or connections unless you absolutely need to use them.What a
difference a cache makes- For read heavy applications caching is the easiest
way offload the database.Cache as coarse-grained objects as possible- Coarse-
grained objects save CPU and time by requiring fewer reads to assemble
objects.Don't store transient state permanently- Is it really necessary to
store your transient data in the database?Location, Location- put things close
to where they are supposed to be delivered.Constrain concurrent access to
limited resource- it's quicker to let a single thread do work and finish
rather than flooding finite resources with 200 client threads.Staged,
asynchronous processing- separate a process using asynchronicity into separate
steps mediated by queues and execut</p><p>4 0.89260614 <a title="772-lda-4" href="../high_scalability-2008/high_scalability-2008-11-02-Strategy%3A_How_to_Manage_Sessions_Using_Memcached.html">436 high scalability-2008-11-02-Strategy: How to Manage Sessions Using Memcached</a></p>
<p>Introduction: Dormandoshows an enlightened middle wayfor storing sessions in cache and the
database. Sessions are a perfect cache candidate because they are transient,
smallish, and since they are usually accessed on every page access removing
all that load from the database is a good thing. But as Dormando points out
session caches have problems. If you remove expiration times from the cache
and you run out of memory then no more logins. If a cache server fails or
needs to be upgrade then you just logged out a bunch of potentially angry
users.The middle ground Dormando proposes is using both the cache and the
database:Reads: read from the cache first, then the database. Typical cache
logic.Writes: write to memcached every time, write to the database every N
seconds (assuming the data has changed).There's a small chance of data loss,
but you've still greatly reduced the database load while providing
reliability. Nice solution.</p><p>5 0.89045262 <a title="772-lda-5" href="../high_scalability-2010/high_scalability-2010-08-12-Strategy%3A_Terminate_SSL_Connections_in_Hardware_and_Reduce_Server_Count_by_40%25.html">878 high scalability-2010-08-12-Strategy: Terminate SSL Connections in Hardware and Reduce Server Count by 40%</a></p>
<p>Introduction: This is an interesting tidbit from near the end of the Packet Pushers
podcastShow 15 - Saving the Web With Dinky Putt Putt Firewalls. The
conversation was about how SSL connections need to terminate before they can
be processed by a WAF (Web Application Firewall), which inspects HTTP for
security problems like SQL injection and cross-site scripting exploits. Much
was made that if programmers did their job better these appliances wouldn't be
necessary, but I digress.Toterminate SSLmost shops run SSL connections into
Intel based Linux boxes running Apache. This setup is convenient for
developers, but it's not optimized for SSL, so it's slow and costly. Much of
the capacity of these servers are unnecessarily consumed processing SSL.Load
balancers on the other hand have crypto cards that terminate SSL very
efficiently in hardware. Efficiently enough that if you are willing to get rid
of the general purpose Linux boxes and use your big iron load balancers, your
server count can be decreased</p><p>6 0.88649338 <a title="772-lda-6" href="../high_scalability-2012/high_scalability-2012-02-27-Zen_and_the_Art_of_Scaling_-_A_Koan_and_Epigram_Approach.html">1199 high scalability-2012-02-27-Zen and the Art of Scaling - A Koan and Epigram Approach</a></p>
<p>7 0.88632905 <a title="772-lda-7" href="../high_scalability-2007/high_scalability-2007-08-03-Running_Hadoop_MapReduce_on_Amazon_EC2_and_Amazon_S3.html">56 high scalability-2007-08-03-Running Hadoop MapReduce on Amazon EC2 and Amazon S3</a></p>
<p>8 0.88632905 <a title="772-lda-8" href="../high_scalability-2009/high_scalability-2009-04-13-Benchmark_for_keeping_data_in_browser_in_AJAX_projects.html">565 high scalability-2009-04-13-Benchmark for keeping data in browser in AJAX projects</a></p>
<p>9 0.88624483 <a title="772-lda-9" href="../high_scalability-2008/high_scalability-2008-01-10-Letting_Clients_Know_What%27s_Changed%3A_Push_Me_or_Pull_Me%3F.html">205 high scalability-2008-01-10-Letting Clients Know What's Changed: Push Me or Pull Me?</a></p>
<p>10 0.88560438 <a title="772-lda-10" href="../high_scalability-2010/high_scalability-2010-09-30-More_Troubles_with_Caching.html">911 high scalability-2010-09-30-More Troubles with Caching</a></p>
<p>11 0.8853237 <a title="772-lda-11" href="../high_scalability-2008/high_scalability-2008-01-25-Google%3A_Introduction_to_Distributed_System_Design.html">223 high scalability-2008-01-25-Google: Introduction to Distributed System Design</a></p>
<p>12 0.88344455 <a title="772-lda-12" href="../high_scalability-2009/high_scalability-2009-10-16-Paper%3A_Scaling_Online_Social_Networks_without_Pains.html">723 high scalability-2009-10-16-Paper: Scaling Online Social Networks without Pains</a></p>
<p>13 0.88335526 <a title="772-lda-13" href="../high_scalability-2011/high_scalability-2011-01-03-Stuff_The_Internet_Says_On_Scalability_For_January_3%2C_2010.html">967 high scalability-2011-01-03-Stuff The Internet Says On Scalability For January 3, 2010</a></p>
<p>14 0.88235486 <a title="772-lda-14" href="../high_scalability-2010/high_scalability-2010-06-04-Strategy%3A_Cache_Larger_Chunks_-_Cache_Hit_Rate_is_a_Bad_Indicator.html">836 high scalability-2010-06-04-Strategy: Cache Larger Chunks - Cache Hit Rate is a Bad Indicator</a></p>
<p>15 0.88101327 <a title="772-lda-15" href="../high_scalability-2011/high_scalability-2011-12-12-Netflix%3A_Developing%2C_Deploying%2C_and_Supporting_Software_According_to_the_Way_of_the_Cloud.html">1155 high scalability-2011-12-12-Netflix: Developing, Deploying, and Supporting Software According to the Way of the Cloud</a></p>
<p>16 0.88066268 <a title="772-lda-16" href="../high_scalability-2011/high_scalability-2011-09-27-Use_Instance_Caches_to_Save_Money%3A_Latency_%3D%3D_%24%24%24.html">1126 high scalability-2011-09-27-Use Instance Caches to Save Money: Latency == $$$</a></p>
<p>17 0.87940758 <a title="772-lda-17" href="../high_scalability-2010/high_scalability-2010-06-18-Paper%3A_The_Declarative_Imperative%3A_Experiences_and_Conjectures_in_Distributed_Logic.html">844 high scalability-2010-06-18-Paper: The Declarative Imperative: Experiences and Conjectures in Distributed Logic</a></p>
<p>18 0.87870282 <a title="772-lda-18" href="../high_scalability-2014/high_scalability-2014-02-05-Little%E2%80%99s_Law%2C_Scalability_and_Fault_Tolerance%3A_The_OS_is_your_bottleneck._What_you_can_do%3F.html">1591 high scalability-2014-02-05-Little’s Law, Scalability and Fault Tolerance: The OS is your bottleneck. What you can do?</a></p>
<p>19 0.87489808 <a title="772-lda-19" href="../high_scalability-2007/high_scalability-2007-10-03-Save_on_a_Load_Balancer_By_Using_Client_Side_Load_Balancing.html">109 high scalability-2007-10-03-Save on a Load Balancer By Using Client Side Load Balancing</a></p>
<p>20 0.87448144 <a title="772-lda-20" href="../high_scalability-2008/high_scalability-2008-12-01-MySQL_Database_Scale-out_and_Replication_for_High_Growth_Businesses.html">455 high scalability-2008-12-01-MySQL Database Scale-out and Replication for High Growth Businesses</a></p>
<br/><br/><br/>

<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-48522588-1', 'makerhacker.github.io');
ga('send', 'pageview');
</script>

</body>
</html>
